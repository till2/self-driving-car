{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43db25de",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d80a4c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from typing import Dict, List, Union\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "from collections import deque\n",
    "from operator import itemgetter\n",
    "\n",
    "import gym_donkeycar\n",
    "import gymnasium as gym\n",
    "import imageio\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from IPython.display import display\n",
    "from ipywidgets import HBox, VBox\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from ruamel.yaml import YAML\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.stats import norm\n",
    "from tensorboard import notebook\n",
    "from tensorboard.backend.event_processing.event_accumulator import \\\n",
    "    EventAccumulator\n",
    "from torch import distributions as dist\n",
    "from torch.distributions import Categorical, Normal\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "import gymnasium as gym\n",
    "\n",
    "# suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"gymnasium.spaces.box\") # module=\"gymnasium\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ[\"IMAGEIO_IGNORE_WARNINGS\"] = \"True\"\n",
    "\n",
    "import stable_baselines3 as sb3\n",
    "from gym_donkeycar.envs.donkey_env import DonkeyEnv\n",
    "from gymnasium import spaces\n",
    "from gymnasium.spaces import Box\n",
    "from stable_baselines3 import A2C, PPO, SAC\n",
    "from stable_baselines3.common import env_checker\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.results_plotter import load_results, ts2xy\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "\n",
    "import src\n",
    "from src.actor_critic_discrete import DiscreteActorCritic\n",
    "from src.actor_critic import ContinuousActorCritic\n",
    "from src.blocks import CategoricalStraightThrough, ConvBlock\n",
    "from src.categorical_vae import CategoricalVAE\n",
    "from src.imagination_env import make_imagination_env\n",
    "from src.mlp import MLP\n",
    "from src.preprocessing import transform\n",
    "from src.replay_buffer import ReplayBuffer\n",
    "from src.rssm import RSSM\n",
    "from src.utils import (load_config, make_env, save_image_and_reconstruction,\n",
    "                       to_np, symlog, symexp, twohot_encode, ExponentialMovingAvg,\n",
    "                       ActionExponentialMovingAvg, MetricsTracker)\n",
    "from src.vae import VAE\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Load the config\n",
    "config = load_config()\n",
    "for key in config:\n",
    "    locals()[key] = config[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1daa9ad2",
   "metadata": {},
   "source": [
    "## Create the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4d6530b",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_one_env = lambda: gym.make(\"Pendulum-v1\")\n",
    "make_time_limit_env = lambda: gym.wrappers.TimeLimit(make_one_env(), max_episode_steps=config[\"max_episode_steps\"])\n",
    "make_auto_reset_env = lambda: gym.wrappers.AutoResetWrapper(make_time_limit_env())\n",
    "\n",
    "env = gym.vector.AsyncVectorEnv([lambda: make_auto_reset_env() for i in range(n_envs)])\n",
    "\n",
    "env = gym.experimental.wrappers.RescaleActionV0(env, min_action=config[\"action_space_low\"], max_action=config[\"action_space_high\"])\n",
    "env = gym.wrappers.RecordEpisodeStatistics(env, deque_size=config[\"n_updates\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "969fdb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = make_env()\n",
    "# \n",
    "# env.reset()\n",
    "# for i in range(1000):\n",
    "#     obs, reward, terminated, truncated, info = env.step(np.random.rand(5,3)*100)\n",
    "#     done = [te or tr for te, tr in zip(terminated, truncated)]\n",
    "#     print(done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae3f4af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8352ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700abf0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff6b40a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b122502",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491ecbe2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15e3503e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing agent with 3 features and 1 actions.\n",
      "Initializing critic.\n",
      "Adding zero weight init to the output layer.\n",
      "Initializing actor.\n"
     ]
    }
   ],
   "source": [
    "# agent = ContinuousActorCritic()\n",
    "agent = DiscreteActorCritic(n_features=3, n_actions=1)\n",
    "\n",
    "# agent.load_weights(\"weights/ContinuousActorCritic_0\")\n",
    "\n",
    "# vae = VAE()\n",
    "# vae.optim = optim.Adam(vae.parameters(), lr=1e-4, weight_decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3ca322",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f777aca1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8f90f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                | 0/500000 [00:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards torch.Size([16, 5])\n",
      "log_probs torch.Size([16, 5])\n",
      "value_preds torch.Size([16, 5])\n",
      "critic_dists torch.Size([16, 5, 255])\n",
      "entropies torch.Size([16, 5])\n",
      "masks torch.Size([16, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "grad can be implicitly created only for scalar outputs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 44\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28mprint\u001b[39m(key, val\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     43\u001b[0m critic_loss, actor_loss \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mget_loss(episode_batches, last_value_pred)\n\u001b[0;32m---> 44\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcritic_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactor_loss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Log the episode metrics\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_phase \u001b[38;5;241m%\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog_interval\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/GitHub/self-driving-car/src/actor_critic_discrete.py:204\u001b[0m, in \u001b[0;36mDiscreteActorCritic.update_parameters\u001b[0;34m(self, critic_loss, actor_loss)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcritic_optim\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor_optim\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 204\u001b[0m \u001b[43mactor_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m nn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_grad_norm, norm_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor_optim\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:166\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    162\u001b[0m inputs \u001b[38;5;241m=\u001b[39m (inputs,) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m \\\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28mtuple\u001b[39m(inputs) \u001b[38;5;28;01mif\u001b[39;00m inputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m()\n\u001b[1;32m    165\u001b[0m grad_tensors_ \u001b[38;5;241m=\u001b[39m _tensor_or_tensors_to_tuple(grad_tensors, \u001b[38;5;28mlen\u001b[39m(tensors))\n\u001b[0;32m--> 166\u001b[0m grad_tensors_ \u001b[38;5;241m=\u001b[39m \u001b[43m_make_grads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_grads_batched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:67\u001b[0m, in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads, is_grads_batched)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out\u001b[38;5;241m.\u001b[39mrequires_grad:\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m out\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 67\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad can be implicitly created only for scalar outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     68\u001b[0m     new_grads\u001b[38;5;241m.\u001b[39mappend(torch\u001b[38;5;241m.\u001b[39mones_like(out, memory_format\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mpreserve_format))\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: grad can be implicitly created only for scalar outputs"
     ]
    }
   ],
   "source": [
    "# New training loop with batches for the distributional critic\n",
    "\n",
    "tracker = MetricsTracker(\n",
    "    training_metrics=[\"critic_loss\", \"actor_loss\"],\n",
    "    episode_metrics=[\"rewards\", \"log_probs\", \"value_preds\", \"critic_dists\", \"entropies\", \"masks\"],\n",
    ")\n",
    "\n",
    "for sample_phase in tqdm(range(n_updates)):\n",
    "    \n",
    "    if sample_phase == 0:\n",
    "        obs, info = env.reset(seed=42)\n",
    "        # obs = transform(torch.tensor(obs)) ### only for images\n",
    "\n",
    "    for step in range(n_steps_per_update):\n",
    "            \n",
    "        value_pred, critic_dist = agent.apply_critic(obs)\n",
    "\n",
    "        # Get an action and take an environment step\n",
    "        action, log_prob, actor_entropy = agent.get_action(obs)\n",
    "        obs, reward, terminated, truncated, info = env.step(to_np(action))\n",
    "        # obs = transform(torch.tensor(obs)) ### only for images\n",
    "        \n",
    "        # every step:\n",
    "        tracker.add(\n",
    "            episode_metrics={\n",
    "                \"rewards\": reward,\n",
    "                \"log_probs\": log_prob,\n",
    "                \"value_preds\": value_pred,\n",
    "                \"critic_dists\": critic_dist,\n",
    "                \"entropies\": actor_entropy,\n",
    "                \"masks\": np.where(terminated, 0, 1),\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    # every sample phase:\n",
    "    episode_batches = tracker.get_episode_batches() # episode_batches is a dict\n",
    "    last_value_pred, _ = agent.apply_critic(obs) # last value prediction for GAE\n",
    "\n",
    "    # Update the agent's parameters\n",
    "    # DEBUG:\n",
    "    for key, val in episode_batches.items():\n",
    "        print(key, val.shape)\n",
    "    critic_loss, actor_loss = agent.get_loss(episode_batches, last_value_pred)\n",
    "    agent.update_parameters(critic_loss, actor_loss)\n",
    "    \n",
    "    # Log the episode metrics\n",
    "    if sample_phase % config[\"log_interval\"] == 0:\n",
    "        tracker.add(\n",
    "            training_metrics={\n",
    "                \"critic_loss\": critic_loss,\n",
    "                \"actor_loss\": actor_loss,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Episode return\n",
    "        if len(env.return_queue):\n",
    "            tracker.writer.add_scalar(\"episode_return\", np.array(env.return_queue)[-1], global_step=len(env.return_queue))\n",
    "\n",
    "        # Actor and critic losses\n",
    "        tracker.log_to_tensorboard(step=sample_phase)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c37b7a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_value_pred, _ = agent.apply_critic(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e809334",
   "metadata": {},
   "outputs": [],
   "source": [
    "ep_rewards = episode_batches[\"rewards\"]\n",
    "ep_log_probs = episode_batches[\"log_probs\"]\n",
    "ep_value_preds = episode_batches[\"value_preds\"]\n",
    "batch_critic_dists = episode_batches[\"critic_dists\"]\n",
    "ep_entropies = episode_batches[\"entropies\"]\n",
    "ep_masks = episode_batches[\"masks\"]\n",
    "\n",
    "# FROM ORIGINAL:\n",
    "# append the last value pred to the value preds tensor\n",
    "last_value_pred = last_value_pred.view(1,-1).detach() # (1, B)\n",
    "ep_value_preds = torch.cat((ep_value_preds, last_value_pred), dim=0) # (SEQ_LEN+1, B)\n",
    "\n",
    "# set up tensors for the advantage calculation\n",
    "returns = torch.zeros_like(ep_rewards).to(device) # (SEQ_LEN, B)\n",
    "advantages = torch.zeros_like(ep_rewards).to(device) # (SEQ_LEN, B)\n",
    "next_advantage = torch.zeros_like(last_value_pred) # (1, B)\n",
    "\n",
    "# calculate advantages using GAE\n",
    "for t in reversed(range(len(ep_rewards))):\n",
    "    returns[t] = ep_rewards[t] + gamma * ep_masks[t] * ep_value_preds[t+1]\n",
    "    td_error = returns[t] - ep_value_preds[t]\n",
    "    advantages[t] = next_advantage = td_error + gamma * lam * ep_masks[t] * next_advantage\n",
    "\n",
    "# categorical crossentropy (should be fine, I checked.)\n",
    "twohot_returns = torch.stack([twohot_encode(r) for r in returns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19009ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([17, 5])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ep_value_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8154310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_value_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc5e80cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 5])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advantages.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d642ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# two-hot encode returns\n",
    "# twohot_returns = torch.stack([twohot_encode(r) for r in returns])  # (SEQ_LEN, B, NUM_BUCKETS)\n",
    "# twohot_returns = twohot_returns.permute(1, 0, 2)  # (B, SEQ_LEN, NUM_BUCKETS)\n",
    "# \n",
    "# # compute critic loss\n",
    "# batch_critic_dists = batch_critic_dists.permute(1, 0, 2)  # (B, SEQ_LEN, NUM_BUCKETS)\n",
    "# critic_loss = -torch.sum(twohot_returns * torch.log(batch_critic_dists), dim=(1, 2))\n",
    "# critic_loss = torch.mean(critic_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e83830cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 5, 255])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twohot_returns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "3efb615a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one sample\n",
    "twohot_returns = torch.zeros(16, 1, 255).to(config[\"device\"])\n",
    "\n",
    "for i in range(16):\n",
    "    twohot_returns[i,0,30] = 0.83\n",
    "    twohot_returns[i,0,31] = 0.17\n",
    "\n",
    "torch.manual_seed(0)\n",
    "batch_critic_dists = torch.rand(16, 1, 255).to(config[\"device\"])\n",
    "batch_critic_dists = F.softmax(batch_critic_dists, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "fd412dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch of samples\n",
    "twohot_returns = torch.zeros(16, 7, 255).to(config[\"device\"])\n",
    "for i in range(16):\n",
    "    twohot_returns[i,:,30] = 0.83 * torch.ones(7).to(config[\"device\"])\n",
    "    twohot_returns[i,:,31] = 0.17 * torch.ones(7).to(config[\"device\"])\n",
    "\n",
    "batch_critic_dists = torch.ones(16, 7, 255).to(config[\"device\"])\n",
    "batch_critic_dists = F.softmax(batch_critic_dists, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "75404f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = agent._calculate_critic_loss(twohot_returns, batch_critic_dists)\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "6fa38563",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [176], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m89.5558\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628a61ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "1846314c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(88.6602, device='cuda:0')"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ORIGINAL:\n",
    "\n",
    "critic_loss = - twohot_returns[:,0,:].detach() @ torch.log(batch_critic_dists[:,0,:]).T\n",
    "critic_loss = torch.sum(torch.diag(critic_loss))\n",
    "critic_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97611428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solut = 88.0143"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b0458ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 16, 255])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = twohot_returns.permute(1, 0, 2)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "df9b627c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 16, 255])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = batch_critic_dists.permute(1, 0, 2)\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7903ebba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([88.6126, 88.9002, 88.6646, 88.8494, 88.8574], device='cuda:0',\n",
       "       grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "critic_loss = -torch.sum(a * torch.log(b), dim=(1, 2))\n",
    "critic_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b6731b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2deb0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f177b7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d777a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.scatter_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e6860fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function Tensor.scatter_add_>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(1).scatter_add_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4311121e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ep_rewards = episode_batches[\"rewards\"]\n",
    "ep_log_probs = episode_batches[\"log_probs\"]\n",
    "ep_value_preds = episode_batches[\"value_preds\"]\n",
    "batch_critic_dists = episode_batches[\"critic_dists\"]\n",
    "ep_entropies = episode_batches[\"entropies\"]\n",
    "ep_masks = episode_batches[\"masks\"]\n",
    "last_value_pred = torch.randn(5).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "195e8346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 5])\n",
      "torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "print(ep_rewards.shape)\n",
    "print(last_value_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "836581ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_value_pred = last_value_pred.unsqueeze(0).detach() # (1, B)\n",
    "ep_value_preds = torch.cat((ep_value_preds, last_value_pred), dim=0) # (SEQ_LEN+1, B)\n",
    "\n",
    "# set up tensors for the advantage calculation\n",
    "returns = torch.zeros_like(ep_rewards).to(device) # (SEQ_LEN, B)\n",
    "advantages = torch.zeros_like(ep_rewards).to(device) # (SEQ_LEN, B)\n",
    "next_advantage = torch.zeros_like(last_value_pred) # (1, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5dffe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "46bfb4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate advantages using GAE\n",
    "for t in reversed(range(len(ep_rewards))):\n",
    "    returns[t] = ep_rewards[t] + gamma * ep_masks[t] * ep_value_preds[t+1]\n",
    "    td_error = returns[t] - ep_value_preds[t]\n",
    "    advantages[t] = next_advantage = td_error + gamma * lam * ep_masks[t] * next_advantage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0995b600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 5])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advantages.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "95946dc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 5])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3d74261d",
   "metadata": {},
   "outputs": [],
   "source": [
    "twohot_returns = torch.stack([twohot_encode(r) for r in returns]) # (SEQ_LEN, B, NUM_BUCKETS)\n",
    "critic_loss = -torch.sum(twohot_returns.detach() * torch.log(batch_critic_dists), dim=(0, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5345b540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "critic_loss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed8fda7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "39ed38fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "1D tensors expected, but got 3D and 3D tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [91], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtwohot_returns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_critic_dists\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: 1D tensors expected, but got 3D and 3D tensors"
     ]
    }
   ],
   "source": [
    "torch.dot(twohot_returns.detach(), torch.log(batch_critic_dists).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d97d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "critic_loss = torch.sum(torch.diag(critic_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f77460a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 5, 255])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twohot_returns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "db259b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 5, 255])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_critic_dists.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e5b65f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 5])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor_loss = -(ep_log_probs * advantages.detach()).mean() - ent_coef * ep_entropies\n",
    "actor_loss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "247dbe91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 5])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ep_log_probs * advantages).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "01514a63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 5, 255])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twohot_returns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e920e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c295b519",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55194e4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec6ef51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0cddbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc45352",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6f1a14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b753e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a4abb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c99e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in episode_batches.items():\n",
    "    print(key, val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12135eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_batches[\"rewards\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b58485",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
