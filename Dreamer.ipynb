{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b1c5dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/till/.local/lib/python3.10/site-packages/gymnasium/envs/registration.py:498: UserWarning: \u001b[33mWARN: Overriding environment GymV26Environment-v0 already in registry.\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import gym_donkeycar\n",
    "\n",
    "import os\n",
    "from ruamel.yaml import YAML\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import HBox, VBox\n",
    "from IPython.display import display\n",
    "from tqdm import tqdm\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch import distributions as dist\n",
    "from torch.distributions import Normal, Categorical\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "from tensorboard import notebook\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Set the environment variable to suppress TensorFlow warning\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "from networks.utils import to_np, load_config\n",
    "\n",
    "# custom classes and functions\n",
    "from networks.blocks import ConvBlock, CategoricalStraightThrough\n",
    "from networks.rssm import RSSM\n",
    "from networks.mlp import MLP\n",
    "from networks.categorical_vae import CategoricalVAE\n",
    "from preprocessing import grayscale_transform as transform\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7cd6cd",
   "metadata": {},
   "source": [
    "## Load Hyperparameters from YAML config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "084afb15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'device': device(type='cuda', index=0), 'A': 3, 'Z': 1024, 'debug': False, 'logdir': 'logs/', 'seed': 0, 'precision': 32, 'size': [128, 128], 'grayscale': True, 'toy_env': True, 'n_episodes': 5000, 'max_episode_steps': 100, 'env_id': 'donkey-minimonaco-track-v0', 'max_grad_norm': 100, 'batch_size': 8, 'H': 512, 'num_categoricals': 32, 'num_classes': 32, 'mlp_n_layers': 3, 'mlp_hidden_dims': 256, 'action_clip_min': -1, 'action_clip_max': 1}\n"
     ]
    }
   ],
   "source": [
    "config = load_config()\n",
    "\n",
    "for key in config:\n",
    "    locals()[key] = config[key]\n",
    "\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239558a5",
   "metadata": {},
   "source": [
    "## Init Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ad7382",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724e9f59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cda9f099",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing encoder:\n",
      "- adding ConvBlock((1, 32))                   ==> output shape: (32, 64, 64) ==> prod: 131072\n",
      "- adding ConvBlock((32, 64))                   ==> output shape: (64, 32, 32) ==> prod: 65536\n",
      "- adding ConvBlock((64, 128))                   ==> output shape: (128, 16, 16) ==> prod: 32768\n",
      "- adding ConvBlock((128, 256))                   ==> output shape: (256, 8, 8) ==> prod: 16384\n",
      "- adding ConvBlock((256, 64))                   ==> output shape: (64, 4, 4) ==> prod: 1024\n",
      "- adding Flatten()\n",
      "- adding Reshape: (*,1024) => (*,32,32)\n",
      "\n",
      "Initializing decoder:\n",
      "- adding Reshape: (*,1024) => (*,64,4,4)\n",
      "- adding transpose ConvBlock(64, 64)                   ==> output shape: (64, 8, 8) ==> prod: 4096\n",
      "- adding transpose ConvBlock(64, 256)                   ==> output shape: (256, 16, 16) ==> prod: 65536\n",
      "- adding transpose ConvBlock(256, 128)                   ==> output shape: (128, 32, 32) ==> prod: 131072\n",
      "- adding transpose ConvBlock(128, 64)                   ==> output shape: (64, 64, 64) ==> prod: 262144\n",
      "- adding transpose ConvBlock(64, 1)                   ==> output shape: (1, 128, 128) ==> prod: 16384\n"
     ]
    }
   ],
   "source": [
    "rssm = RSSM().to(device)\n",
    "\n",
    "rssm_optim = optim.Adam(\n",
    "    rssm.parameters(), \n",
    "    lr=1e-4,\n",
    "\n",
    "    # l2 regularizer\n",
    "    weight_decay=1e-6, \n",
    ")\n",
    "\n",
    "value_net = MLP(input_dims=Z, output_dims=1).to(device) # state (H+Z) -> 1\n",
    "policy_net = MLP(input_dims=Z, output_dims=A, out_type=\"gaussian\").to(device) # state (H+Z) -> A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227027bc",
   "metadata": {},
   "source": [
    "## Imagine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2b9371a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 31.87it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" training loop \"\"\"\n",
    "\n",
    "imagine = True\n",
    "\n",
    "rssm.train()\n",
    "\n",
    "# Create the environment\n",
    "if toy_env:\n",
    "    assert A==3\n",
    "    env = gym.make(\"CarRacing-v2\", max_episode_steps=100, render_mode=\"rgb_array\") # rgb_array/human # 50 steps\n",
    "else:\n",
    "    assert A==2\n",
    "    sim_config = {\n",
    "        \"exe_path\" : \"/home/till/Desktop/Thesis/donkeycar_sim/DonkeySimLinux/donkey_sim.x86_64\",\n",
    "        \"port\" : 9091\n",
    "    }\n",
    "    env = gym.make(\n",
    "        \"GymV21Environment-v0\", \n",
    "        env_id=env_id,\n",
    "        max_episode_steps=max_episode_steps,\n",
    "        make_kwargs={\n",
    "            \"conf\": sim_config\n",
    "        })\n",
    "\n",
    "try:\n",
    "    for episode in tqdm(range(5)):\n",
    "\n",
    "        # Get the initial state\n",
    "        obs, info = env.reset()\n",
    "\n",
    "        # Reset the RNN's hidden state\n",
    "        h = torch.zeros(rssm.num_rnn_layers, 1, H, device=device) # seq_len, B, H\n",
    "\n",
    "        # Add a new loss for the current episode and initialize it to 0\n",
    "        episode_length = 0\n",
    "\n",
    "        # Play one episode\n",
    "        done = False\n",
    "        while not done:\n",
    "\n",
    "            \"\"\" IMAGINE ONE EPISODE \"\"\"\n",
    "            \n",
    "            if episode_length == 0:\n",
    "                x = transform(obs).view(-1, 1, 128, 128)\n",
    "                z = rssm.vae.encode(x).flatten(start_dim=1, end_dim=2)\n",
    "            \n",
    "            else:\n",
    "                # predict z and generate the true stochastic latent variable z with the encoder\n",
    "                z_prior = rssm.dynamics_mlp(h).view(-1, num_categoricals, num_classes) # (1,32,32) for the softmax\n",
    "                z_prior = F.softmax(z_prior, -1).flatten(start_dim=1, end_dim=2) # (1, 1024)\n",
    "                z = z_prior            \n",
    "            \n",
    "            action_mean, action_var = policy_net(z)\n",
    "            action = torch.normal(mean=action_mean, std=torch.sqrt(action_var)) # Ax1 vector\n",
    "            action = torch.clip(action, action_clip_min, action_clip_max)\n",
    "            \n",
    "            v = value_net(z)\n",
    "\n",
    "            # predict one step using the RSSM and apply the actor-critic\n",
    "            h, reward_pred, continue_prob, continue_pred, x_pred = rssm.step(action, h, z)\n",
    "\n",
    "            episode_length += 1\n",
    "            done = 1 - continue_pred\n",
    "            #if episode_length == 10:\n",
    "            #    done = True\n",
    "\n",
    "            plt.imsave(f\"reconstructions/episode_{episode}_step_{episode_length}_imagination.png\", to_np(x_pred[0][0]), cmap=\"gray\")\n",
    "\n",
    "    env.close()\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    \"\"\" Clean handling for interrupts to stop training early \"\"\"\n",
    "    print(\"Stopping training.\")\n",
    "    # Delete the last loss if the training was stopped early\n",
    "    # so that the list only consists of floats\n",
    "    for key in episode_losses:\n",
    "        if isinstance(episode_losses[key][-1], torch.Tensor):\n",
    "            episode_losses[key] = episode_losses[key][:-1]\n",
    "\n",
    "    # Close the TensorBoard writer and the gym environment\n",
    "    writer.close()\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5534e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d0bf4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "856cb39a",
   "metadata": {},
   "source": [
    "## Training loop\n",
    "\n",
    "Notes:\n",
    "- currently taking random actions (not the output of the actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd076d3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\" training loop \"\"\"\n",
    "\n",
    "rssm.train()\n",
    "\n",
    "# Create the environment\n",
    "if toy_env:\n",
    "    assert A==3\n",
    "    env = gym.make(\"CarRacing-v2\", max_episode_steps=100, render_mode=\"rgb_array\") # rgb_array/human # 50 steps\n",
    "else:\n",
    "    assert A==2\n",
    "    sim_config = {\n",
    "        \"exe_path\" : \"/home/till/Desktop/Thesis/donkeycar_sim/DonkeySimLinux/donkey_sim.x86_64\",\n",
    "        \"port\" : 9091\n",
    "    }\n",
    "    env = gym.make(\n",
    "        \"GymV21Environment-v0\", \n",
    "        env_id=env_id,\n",
    "        max_episode_steps=max_episode_steps,\n",
    "        make_kwargs={\n",
    "            \"conf\": sim_config\n",
    "        })\n",
    "\n",
    "# Logging\n",
    "log_dir = \"logs/\"\n",
    "writer = SummaryWriter(log_dir)\n",
    "notebook.start(f\"--logdir={log_dir}\")\n",
    "\n",
    "episode_losses = { # for loss plots\n",
    "    \"episode_loss\": [],\n",
    "    \"episode_image_loss\": [],\n",
    "    \"episode_reward_loss\": [],\n",
    "    \"episode_continue_loss\": [],\n",
    "    \"episode_dyn_loss\": [],\n",
    "    \"episode_rep_loss\": [],\n",
    "}\n",
    "\n",
    "try:\n",
    "    for episode in tqdm(range(n_episodes)):\n",
    "\n",
    "        # Get the initial state\n",
    "        obs, info = env.reset()\n",
    "\n",
    "        # Reset the RNN's hidden state\n",
    "        h = torch.zeros(rssm.num_rnn_layers, 1, H, device=device) # seq_len, B, H\n",
    "\n",
    "        # Add a new loss for the current episode and initialize it to 0\n",
    "        episode_length = 0\n",
    "        for key in episode_losses:\n",
    "            episode_losses[key].append(torch.tensor(0, device=device, dtype=torch.float32))\n",
    "\n",
    "        # Play one episode\n",
    "        done = False\n",
    "        while not done:\n",
    "\n",
    "            x = transform(obs).view(-1, 1, 128, 128)\n",
    "\n",
    "            \"\"\" WORLD MODEL LEARNING \"\"\"\n",
    "\n",
    "            # predict z and generate the true stochastic latent variable z with the encoder\n",
    "            z_prior = rssm.dynamics_mlp(h).view(-1, num_categoricals, num_classes) # (1,32,32) for the softmax\n",
    "            z_prior = F.softmax(z_prior, -1).flatten(start_dim=1, end_dim=2) # (1, 1024)\n",
    "            z = rssm.vae.encode(x).flatten(start_dim=1, end_dim=2)\n",
    "\n",
    "            # apply external actor and critic nets on z\n",
    "            action_mean, action_var = policy_net(z)\n",
    "            action = torch.normal(mean=action_mean, std=torch.sqrt(action_var)) # # Ax1 vector\n",
    "            action = torch.clip(action, action_clip_min, action_clip_max)\n",
    "\n",
    "            v = value_net(z)\n",
    "\n",
    "            # predict one step using the RSSM and apply the actor-critic\n",
    "            h, reward_pred, continue_prob, continue_pred, x_pred = rssm.step(action, h, z)\n",
    "\n",
    "            # choose and execute an action\n",
    "            next_obs, reward, terminated, truncated, info = env.step(to_np(action.squeeze()))        \n",
    "\n",
    "            done = terminated or truncated\n",
    "            obs = next_obs\n",
    "\n",
    "            # calculate the loss\n",
    "            continue_target = torch.tensor(1 - done, device=device, dtype=torch.float32)\n",
    "            reward = torch.tensor(reward, device=device, dtype=torch.float32)\n",
    "            losses = rssm.get_losses(x, x_pred, reward, reward_pred, \n",
    "                                     continue_target, continue_prob, z_prior, z)\n",
    "\n",
    "            # Add loss for the current step to the episode loss\n",
    "            episode_length += 1\n",
    "            for key in losses:\n",
    "                episode_losses[\"episode_\" + key][-1] += losses[key]\n",
    "\n",
    "        # Calculate the mean loss of the episode\n",
    "        for key in episode_losses:\n",
    "            episode_losses[key][-1] /= episode_length\n",
    "\n",
    "        # update the world model at the end of an episode using the mean loss of the episode\n",
    "        rssm_optim.zero_grad()\n",
    "        episode_losses[\"episode_loss\"][-1].backward()\n",
    "        nn.utils.clip_grad_norm_(rssm.vae.parameters(), max_norm=100.0, norm_type=2)  \n",
    "        rssm_optim.step()\n",
    "\n",
    "        # Detach the losses to save memory and log them in TensorBoard\n",
    "        for key in episode_losses:\n",
    "            episode_losses[key][-1] = episode_losses[key][-1].detach().item()\n",
    "            writer.add_scalar(key, episode_losses[key][-1], global_step=episode)\n",
    "        \n",
    "        # save original image and reconstruction\n",
    "        if episode % 10 == 0:\n",
    "            plt.imsave(f\"reconstructions/episode_{episode}_original.png\", to_np(x[0][0]), cmap=\"gray\")\n",
    "            plt.imsave(f\"reconstructions/episode_{episode}_reconstruction.png\", to_np(x_pred[0][0]), cmap=\"gray\")\n",
    "\n",
    "    env.close()\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    \"\"\" Clean handling for interrupts to stop training early \"\"\"\n",
    "    print(\"Stopping training.\")\n",
    "    # Delete the last loss if the training was stopped early\n",
    "    # so that the list only consists of floats\n",
    "    for key in episode_losses:\n",
    "        if isinstance(episode_losses[key][-1], torch.Tensor):\n",
    "            episode_losses[key] = episode_losses[key][:-1]\n",
    "\n",
    "    # Close the TensorBoard writer and the gym environment\n",
    "    writer.close()\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd862849",
   "metadata": {},
   "outputs": [],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779ec3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8335fef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU memory consumption:\n",
    "# 10 steps -> 6504MiB\n",
    "# 50 steps -> 19990MiB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e74d14",
   "metadata": {},
   "source": [
    "## Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0703ff02",
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_length = max(1, int(len(episode_losses[\"episode_loss\"])/20))\n",
    "\n",
    "fig, axs = plt.subplots(ncols=3, nrows=2, figsize=(3*5, 2*5))\n",
    "\n",
    "# Iterate over the keys and plot the losses\n",
    "for i, key in enumerate(episode_losses.keys()):\n",
    "    row = i // 3\n",
    "    col = i % 3\n",
    "\n",
    "    axs[row, col].set_title(key)\n",
    "    losses = episode_losses[key]\n",
    "    losses_moving_average = (\n",
    "        np.convolve(\n",
    "            np.array(losses).flatten(), np.ones(rolling_length), mode=\"valid\"\n",
    "        )\n",
    "        / rolling_length\n",
    "    )\n",
    "    axs[row, col].plot(range(len(losses)), losses, label=key)\n",
    "    axs[row, col].plot(range(len(losses_moving_average)), losses_moving_average, label=\"moving average\")\n",
    "    axs[row, col].legend(loc=\"upper right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3354e868",
   "metadata": {},
   "source": [
    "## Test area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f6ffa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71f928a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0125831e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" save reconstructions for one episode \"\"\"\n",
    "\n",
    "save_one_episode = False\n",
    "\n",
    "\n",
    "if save_one_episode:\n",
    "    rssm.eval()\n",
    "\n",
    "    # Create the environment\n",
    "    if toy_env:\n",
    "        assert A==3\n",
    "        env = gym.make(\"CarRacing-v2\", max_episode_steps=150, render_mode=\"rgb_array\") # rgb_array/human # 50 steps\n",
    "    else:\n",
    "        assert A==2\n",
    "        sim_config = {\n",
    "            \"exe_path\" : \"/home/till/Desktop/Thesis/donkeycar_sim/DonkeySimLinux/donkey_sim.x86_64\",\n",
    "            \"port\" : 9091\n",
    "        }\n",
    "        env = gym.make(\n",
    "            \"GymV21Environment-v0\", \n",
    "            env_id=env_id,\n",
    "            max_episode_steps=max_episode_steps,\n",
    "            make_kwargs={\n",
    "                \"conf\": sim_config\n",
    "            })\n",
    "\n",
    "\n",
    "    try:\n",
    "        for episode in tqdm(range(1)):\n",
    "\n",
    "            # Get the initial state\n",
    "            obs, info = env.reset()\n",
    "\n",
    "            # Reset the RNN's hidden state\n",
    "            h = torch.zeros(rssm.num_rnn_layers, 1, H, device=device) # seq_len, B, H\n",
    "\n",
    "            # Add a new loss for the current episode and initialize it to 0\n",
    "            episode_length = 0\n",
    "\n",
    "            # Play one episode\n",
    "            done = False\n",
    "            while not done:\n",
    "\n",
    "                x = transform(obs).view(-1, 1, 128, 128)\n",
    "\n",
    "                \"\"\" WORLD MODEL LEARNING \"\"\"\n",
    "\n",
    "                # predict z and generate the true stochastic latent variable z with the encoder\n",
    "                z_prior = rssm.dynamics_mlp(h).view(-1, num_categoricals, num_classes) # (1,32,32) for the softmax\n",
    "                z_prior = F.softmax(z_prior, -1).flatten(start_dim=1, end_dim=2) # (1, 1024)\n",
    "                z = rssm.vae.encode(x).flatten(start_dim=1, end_dim=2)\n",
    "\n",
    "                # apply external actor and critic nets on z\n",
    "                action = torch.tensor([(np.random.rand() - 0.5)/3, (np.random.rand() + 0.5)/3], device=device).unsqueeze(dim=0) # policy_net(z) # Ax1 vector\n",
    "                v = value_net(z)\n",
    "\n",
    "                # predict one step using the RSSM and apply the actor-critic\n",
    "                h, reward_pred, continue_prob, continue_pred, x_pred = rssm.step(action, h, z)\n",
    "\n",
    "                # choose and execute an action\n",
    "                next_obs, reward, terminated, truncated, info = env.step(to_np(action.squeeze()))        \n",
    "\n",
    "                done = terminated or truncated\n",
    "                obs = next_obs\n",
    "\n",
    "                # calculate the loss\n",
    "                continue_target = torch.tensor(1 - done, device=device, dtype=torch.float32)\n",
    "                reward = torch.tensor(reward, device=device, dtype=torch.float32)\n",
    "\n",
    "                # TODO: z_prior, z_posterior\n",
    "                z_prior = torch.tensor(0, device=device, dtype=torch.float32)\n",
    "                z_posterior = torch.tensor(0, device=device, dtype=torch.float32)\n",
    "\n",
    "                plt.imsave(f\"reconstructions/{episode_length}.png\", to_np(x_pred[0][0]), cmap=\"gray\")\n",
    "                episode_length += 1\n",
    "\n",
    "        env.close()\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        \"\"\" Clean handling for interrupts to stop training early \"\"\"\n",
    "        print(\"Stopping training.\")\n",
    "        # Delete the last loss if the training was stopped early\n",
    "        # so that the list only consists of floats\n",
    "        for key in episode_losses:\n",
    "            if isinstance(episode_losses[key][-1], torch.Tensor):\n",
    "                episode_losses[key] = episode_losses[key][:-1]\n",
    "\n",
    "        # Close the TensorBoard writer and the gym environment\n",
    "        writer.close()\n",
    "        env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6952d981",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
