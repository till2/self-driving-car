{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b1c5dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "from collections import deque\n",
    "from operator import itemgetter\n",
    "\n",
    "import gym_donkeycar\n",
    "import gymnasium as gym\n",
    "import imageio\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from IPython.display import display\n",
    "from ipywidgets import HBox, VBox\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from ruamel.yaml import YAML\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.stats import norm\n",
    "from tensorboard import notebook\n",
    "from tensorboard.backend.event_processing.event_accumulator import \\\n",
    "    EventAccumulator\n",
    "from torch import distributions as dist\n",
    "from torch.distributions import Categorical, Normal\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "import gym.spaces as gym_spaces\n",
    "import gymnasium as gym  # overwrite OpenAI gym\n",
    "\n",
    "# suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"gymnasium.spaces.box\") # module=\"gymnasium\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ[\"IMAGEIO_IGNORE_WARNINGS\"] = \"True\"\n",
    "\n",
    "import stable_baselines3 as sb3\n",
    "from gym_donkeycar.envs.donkey_env import DonkeyEnv\n",
    "from gymnasium import spaces\n",
    "from gymnasium.spaces import Box\n",
    "from stable_baselines3 import A2C, PPO, SAC\n",
    "from stable_baselines3.common import env_checker\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.results_plotter import load_results, ts2xy\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "\n",
    "from src.actor_critic_discrete import DiscreteActorCritic\n",
    "from src.actor_critic_dreamer import ActorCriticDreamer\n",
    "from src.actor_critic import ContinuousActorCritic\n",
    "from src.blocks import CategoricalStraightThrough, ConvBlock\n",
    "from src.categorical_vae import CategoricalVAE\n",
    "from src.imagination_env import make_imagination_env\n",
    "from src.mlp import MLP\n",
    "from src.preprocessing import transform\n",
    "from src.replay_buffer import ReplayBuffer\n",
    "from src.rssm import RSSM\n",
    "from src.utils import (load_config, make_env, save_image_and_reconstruction,\n",
    "                       to_np, symlog, symexp, twohot_encode, ExponentialMovingAvg,\n",
    "                       ActionExponentialMovingAvg, MetricsTracker)\n",
    "from src.vae import VAE\n",
    "\n",
    "from typing import Dict, List, Union\n",
    "from __future__ import annotations\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Load the config\n",
    "config = load_config()\n",
    "for key in config:\n",
    "    locals()[key] = config[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239558a5",
   "metadata": {},
   "source": [
    "## Init the RSSM (including all networks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cda9f099",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing encoder:\n",
      "- adding ConvBlock((3, 64))                   ==> output shape: (64, 32, 32) ==> prod: 65536\n",
      "- adding ConvBlock((64, 128))                   ==> output shape: (128, 16, 16) ==> prod: 32768\n",
      "- adding ConvBlock((128, 256))                   ==> output shape: (256, 8, 8) ==> prod: 16384\n",
      "- adding ConvBlock((256, 512))                   ==> output shape: (512, 4, 4) ==> prod: 8192\n",
      "- adding ConvBlock((512, 256))                   ==> output shape: (256, 2, 2) ==> prod: 1024\n",
      "- adding Flatten()\n",
      "- adding Reshape: (*,1024) => (*,32,32)\n",
      "\n",
      "Initializing decoder:\n",
      "- adding Reshape: (*,1024) => (*,256,2,2)\n",
      "- adding transpose ConvBlock(256, 256)                   ==> output shape: (256, 4, 4) ==> prod: 4096\n",
      "- adding transpose ConvBlock(256, 512)                   ==> output shape: (512, 8, 8) ==> prod: 32768\n",
      "- adding transpose ConvBlock(512, 256)                   ==> output shape: (256, 16, 16) ==> prod: 65536\n",
      "- adding transpose ConvBlock(256, 128)                   ==> output shape: (128, 32, 32) ==> prod: 131072\n",
      "- adding transpose ConvBlock(128, 3)                   ==> output shape: (3, 64, 64) ==> prod: 12288\n",
      "Adding zero weight init to the output layer.\n"
     ]
    }
   ],
   "source": [
    "rssm = RSSM().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229f8133",
   "metadata": {},
   "source": [
    "## Create the imagination environment for training the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9a08c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = ReplayBuffer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec4e9cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding a TimeLimit wrapper with 16 max imagination episode steps.\n",
      "Adding an AutoReset wrapper.\n",
      "Adding a RescaleActionV0 wrapper. Low: [-1. -1. -1.], High: [1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "imagination_env = make_imagination_env(rssm, replay_buffer, render_mode=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a93b68d",
   "metadata": {},
   "source": [
    "## Init the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe1ee1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = PPO(\n",
    "    policy=\"MlpPolicy\",\n",
    "    env=imagination_env,\n",
    "    verbose=verbose,\n",
    "    tensorboard_log=log_dir,\n",
    "    gamma=gamma,\n",
    "    gae_lambda=lam,\n",
    "    ent_coef=ent_coef,\n",
    ")\n",
    "\n",
    "# agent = DiscreteActorCritic()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856cb39a",
   "metadata": {},
   "source": [
    "## Training loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cd076d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#\"\"\" training loop \"\"\"\n",
    "#\n",
    "#rssm.load_weights(\"weights/RSSM_1.70111713\")\n",
    "#rssm.train()\n",
    "#\n",
    "## Create the environment\n",
    "#env = make_env()\n",
    "#\n",
    "## Logging\n",
    "#writer = SummaryWriter(log_dir)\n",
    "#if config[\"show_inline_tensorboard\"]:\n",
    "#    notebook.start(f\"--logdir={log_dir}\")\n",
    "#\n",
    "#episode_return = []\n",
    "#episode_losses = { # for loss plots\n",
    "#    \"episode_loss\": [],\n",
    "#    \"episode_image_loss\": [],\n",
    "#    \"episode_reward_loss\": [],\n",
    "#    \"episode_continue_loss\": [],\n",
    "#    \"episode_dyn_loss\": [],\n",
    "#    \"episode_rep_loss\": [],\n",
    "#}\n",
    "#\n",
    "#best_running_loss = np.inf # used for saving the best rssm model\n",
    "#\n",
    "#try:\n",
    "#    for episode in tqdm(range(start_episode, n_seed_episodes + n_training_episodes)):\n",
    "#\n",
    "#        if verbose:\n",
    "#            print(\"EPISODE:\", episode)\n",
    "#        \n",
    "#        # Get the initial state\n",
    "#        obs, info = env.reset()\n",
    "#\n",
    "#        # Reset the RNN's hidden state\n",
    "#        h = torch.zeros(rssm.num_rnn_layers, 1, H, device=device) # seq_len, B, H\n",
    "#\n",
    "#        # Add a new loss for the current episode and initialize it to 0\n",
    "#        episode_length = 0\n",
    "#        episode_return.append(0)\n",
    "#        for key in episode_losses:\n",
    "#            episode_losses[key].append(torch.tensor(0, device=device, dtype=torch.float32))\n",
    "#\n",
    "#        # Play one episode\n",
    "#        done = False\n",
    "#        while not done:\n",
    "#\n",
    "#            # preprocess the observation and add it to the replay buffer\n",
    "#            x = transform(obs).view(-1, 1 if grayscale else 3, *size) # (B, 3, 128, 128)\n",
    "#            replay_buffer.push(x)\n",
    "#\n",
    "#            \"\"\" WORLD MODEL LEARNING \"\"\"\n",
    "#\n",
    "#            # predict z and generate the true stochastic latent variable z with the encoder\n",
    "#            z_prior = rssm.dynamics_mlp(h).view(-1, num_categoricals, num_classes) # (1,32,32) for the softmax\n",
    "#            z_prior = F.softmax(z_prior, -1).flatten(start_dim=1, end_dim=2) # (1, 1024)\n",
    "#            z = rssm.vae.encode(x).flatten(start_dim=1, end_dim=2)\n",
    "#            state = to_np(torch.cat((h.flatten().detach(), z.flatten().detach()), dim=0))\n",
    "#            \n",
    "#            # get random action for the first seed episodes\n",
    "#            # and in training mode get the action from the actor\n",
    "#            if episode < n_seed_episodes:\n",
    "#                action = env.action_space.sample()\n",
    "#            else:\n",
    "#                action, _ = agent.predict(state, deterministic=False)\n",
    "#\n",
    "#            # predict one step using the RSSM\n",
    "#            h, reward_pred, continue_prob, continue_pred, x_pred = rssm.step(action, h, z)\n",
    "#\n",
    "#            # take an environment step with the action\n",
    "#            obs, reward, terminated, truncated, info = env.step(action.squeeze())\n",
    "#            done = terminated or truncated\n",
    "#            \n",
    "#            # Add the reward to the episode return\n",
    "#            episode_return[-1] += reward\n",
    "#\n",
    "#            # calculate the loss\n",
    "#            continue_target = torch.tensor(1 - done, device=device, dtype=torch.float32)\n",
    "#            reward = torch.tensor(reward, device=device, dtype=torch.float32)\n",
    "#            losses = rssm.get_losses(x, x_pred, reward, reward_pred, \n",
    "#                                     continue_target, continue_prob, z_prior, z)\n",
    "#\n",
    "#            # Add the loss for the current step to the episode loss\n",
    "#            episode_length += 1\n",
    "#            for key in losses:\n",
    "#                episode_losses[\"episode_\" + key][-1] += losses[key]\n",
    "#\n",
    "#        # Calculate the mean loss of the episode\n",
    "#        for key in episode_losses:\n",
    "#            episode_losses[key][-1] /= episode_length\n",
    "#\n",
    "#        # update the world model at the end of an episode using the mean loss of the episode\n",
    "#        rssm.optim.zero_grad()\n",
    "#        episode_losses[\"episode_loss\"][-1].backward()\n",
    "#        nn.utils.clip_grad_norm_(rssm.vae.parameters(), max_norm=max_grad_norm, norm_type=2)  \n",
    "#        rssm.optim.step()\n",
    "#\n",
    "#        # Log the episode return\n",
    "#        writer.add_scalar(\"episode_return\", episode_return[-1], global_step=episode)\n",
    "#        \n",
    "#        # Detach the losses to save memory and log them in TensorBoard\n",
    "#        for key in episode_losses:\n",
    "#            episode_losses[key][-1] = episode_losses[key][-1].detach().item()\n",
    "#            writer.add_scalar(key, episode_losses[key][-1], global_step=episode)\n",
    "#        \n",
    "#        # save original image and reconstruction\n",
    "#        if episode % 10 == 0:\n",
    "#            save_image_and_reconstruction(x, x_pred, episode)\n",
    "#        \n",
    "#        # save the rssm model with the best running loss\n",
    "#        running_loss = np.mean(episode_losses[\"episode_loss\"][-10:])\n",
    "#        if episode > 0 and episode % 10 == 0 and running_loss < best_running_loss:\n",
    "#            best_running_loss = running_loss\n",
    "#            \n",
    "#            # save the rssm and agent\n",
    "#            rssm.save_weights(filename=f\"RSSM_{best_running_loss:.8f}\")\n",
    "#            agent.save(f\"weights/{agent.__class__.__name__}_agent\")\n",
    "#        \n",
    "#        \"\"\" RL AGENT LEARNING (IN THE WORLD MODEL) \"\"\"\n",
    "#        if episode >= n_seed_episodes:\n",
    "#            if verbose:\n",
    "#                print(\"AGENT IS LEARNING\")\n",
    "#            agent.learn(\n",
    "#                total_timesteps=imagination_timesteps_per_model_update,\n",
    "#                progress_bar=imagination_progress_bar,\n",
    "#                reset_num_timesteps=False\n",
    "#            )\n",
    "#\n",
    "#    env.close()\n",
    "#\n",
    "#except KeyboardInterrupt:\n",
    "#    \"\"\" Clean handling for interrupts to stop training early \"\"\"\n",
    "#    print(\"Stopping training.\")\n",
    "#    # Delete the last loss if the training was stopped early\n",
    "#    # so that the list only consists of floats\n",
    "#    for key in episode_losses:\n",
    "#        if isinstance(episode_losses[key][-1], torch.Tensor):\n",
    "#            episode_losses[key] = episode_losses[key][:-1]\n",
    "#\n",
    "#    # Close the TensorBoard writer and the gym environment\n",
    "#    writer.close()\n",
    "#    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cd3ff2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d484df2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21e554f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a71737c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940f283a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02b307a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259ac062",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bff31322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making a toy env.\n",
      "Making 1 vectorized envs.\n",
      "Adding a Gymnasium RecordEpisodeStatistics wrapper.\n",
      "Adding a TimeLimit wrapper with 1000 max episode steps.\n",
      "Adding an AutoReset wrapper.\n",
      "Adding a RescaleActionV0 wrapper. Low: [-1. -1. -1.], High: [1. 1. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                | 0/501000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                    | 1/501000 [00:01<242:20:39,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                    | 2/501000 [00:02<143:58:59,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                    | 3/501000 [00:02<113:17:48,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                     | 4/501000 [00:03<99:37:38,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                     | 5/501000 [00:03<92:18:38,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                     | 6/501000 [00:04<89:26:35,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                     | 7/501000 [00:05<84:58:42,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                     | 8/501000 [00:05<82:50:32,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                     | 9/501000 [00:06<81:33:40,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                    | 10/501000 [00:06<80:48:13,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                    | 11/501000 [00:07<86:26:50,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                    | 12/501000 [00:08<83:24:05,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                    | 13/501000 [00:08<81:34:03,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                    | 14/501000 [00:09<79:58:35,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                    | 15/501000 [00:09<80:09:29,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                    | 16/501000 [00:10<81:28:47,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                    | 17/501000 [00:10<79:46:02,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                    | 18/501000 [00:11<78:50:43,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                    | 19/501000 [00:11<77:40:18,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                    | 20/501000 [00:12<77:01:22,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                    | 21/501000 [00:13<79:24:03,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                    | 22/501000 [00:13<78:08:35,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                    | 23/501000 [00:14<78:33:08,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                    | 24/501000 [00:14<78:37:52,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                    | 25/501000 [00:15<78:44:17,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                    | 26/501000 [00:16<80:24:58,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                    | 27/501000 [00:16<79:22:12,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                    | 28/501000 [00:17<79:06:09,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                    | 29/501000 [00:17<78:44:08,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                    | 30/501000 [00:18<78:35:10,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                    | 31/501000 [00:18<79:58:27,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                    | 32/501000 [00:19<79:47:46,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                    | 33/501000 [00:19<79:30:17,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                    | 34/501000 [00:20<79:34:52,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                    | 35/501000 [00:21<79:30:36,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                    | 36/501000 [00:21<83:56:52,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                    | 37/501000 [00:22<82:55:54,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                    | 38/501000 [00:22<81:40:09,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                    | 39/501000 [00:23<80:10:21,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                    | 40/501000 [00:24<79:55:20,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                    | 40/501000 [00:24<85:42:14,  1.62it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 106\u001b[0m\n\u001b[1;32m     96\u001b[0m episode_losses \u001b[38;5;241m=\u001b[39m tracker\u001b[38;5;241m.\u001b[39mget_episode_batches(reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m# episode_losses is a dict\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# update the world model at the end of an episode using the mean loss of the episode\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m### rssm.optim.zero_grad()\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m### episode_losses[\"episode_loss\"][-1].backward()\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m# NEW:\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;66;03m# per episode:\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m \u001b[43mrssm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepisode_losses\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mloss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# Log the episode return\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m### writer.add_scalar(\"episode_return\", episode_return[-1], global_step=episode)\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;66;03m# NEW: do this later. at the end in env return queue\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m###     rssm.save_weights(filename=f\"RSSM_{best_running_loss:.8f}\")\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m###     agent.save(f\"weights/{agent.__class__.__name__}_agent\")\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m\"\"\" RL AGENT LEARNING (IN THE WORLD MODEL) \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/GitHub/self-driving-car/src/rssm.py:111\u001b[0m, in \u001b[0;36mRSSM.update_parameters\u001b[0;34m(self, loss)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_parameters\u001b[39m(\u001b[38;5;28mself\u001b[39m, loss):\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 111\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m     nn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_grad_norm, norm_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# New dreamer training loop with batches for the distributional critic\n",
    "# (and later: add manual actor-critic training in imagination env. and delete sb3).\n",
    "\n",
    "### rssm.load_weights(\"weights/RSSM_1.70111713\")\n",
    "### rssm.train()\n",
    "\n",
    "# Create the environment\n",
    "env = make_env()\n",
    "\n",
    "# Logging\n",
    "### writer = SummaryWriter(log_dir)\n",
    "### if config[\"show_inline_tensorboard\"]:\n",
    "###     notebook.start(f\"--logdir={log_dir}\")\n",
    "### episode_return = []\n",
    "### episode_losses = { # for loss plots\n",
    "###     \"episode_loss\": [],\n",
    "###     \"episode_image_loss\": [],\n",
    "###     \"episode_reward_loss\": [],\n",
    "###     \"episode_continue_loss\": [],\n",
    "###     \"episode_dyn_loss\": [],\n",
    "###     \"episode_rep_loss\": [],\n",
    "### }\n",
    "### best_running_loss = np.inf # used for saving the best rssm model\n",
    "\n",
    "tracker = MetricsTracker(\n",
    "    # log the mean loss for the training metrics\n",
    "    training_metrics=[\"loss\", \"image_loss\", \"reward_loss\", \"continue_loss\", \"dyn_loss\", \"rep_loss\", \"rewards\"],\n",
    "    \n",
    "    # loss per step\n",
    "    episode_metrics=[\"loss\", \"image_loss\", \"reward_loss\", \"continue_loss\", \"dyn_loss\", \"rep_loss\", \"rewards\"],\n",
    ")\n",
    "\n",
    "for sample_phase in tqdm(range(start_phase, n_seed_phases + n_model_updates)):\n",
    "    \n",
    "    # Reset the RNN's hidden state\n",
    "    h = torch.zeros(rssm.num_rnn_layers, 1, H, device=device, dtype=torch.float32) # seq_len, B, H\n",
    "    \n",
    "    if sample_phase == start_phase:\n",
    "        \n",
    "        # Get the first obs\n",
    "        obs, info = env.reset(seed=42)\n",
    "        x = transform(obs).view(-1, 1 if grayscale else 3, *size) # (B, 3, 128, 128)\n",
    "        replay_buffer.push(x)\n",
    "    \n",
    "    for step in range(n_steps_per_model_update):\n",
    "    \n",
    "        \"\"\" WORLD MODEL LEARNING \"\"\"\n",
    "\n",
    "        # predict z and generate the true stochastic latent variable z with the encoder\n",
    "        z_prior = rssm.dynamics_mlp(h).view(-1, num_categoricals, num_classes) # (1,32,32) for the softmax\n",
    "        z_prior = F.softmax(z_prior, -1).flatten(start_dim=1, end_dim=2) # (1, 1024)\n",
    "        z = rssm.vae.encode(x).flatten(start_dim=1, end_dim=2)\n",
    "        state = to_np(torch.cat((h.flatten().detach(), z.flatten().detach()), dim=0))\n",
    "\n",
    "        # get random action for the first seed sample phases\n",
    "        # and in training mode get the action from the actor\n",
    "        if sample_phase < n_seed_phases:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            action, _ = agent.predict(state, deterministic=False)\n",
    "\n",
    "        # predict one step using the RSSM\n",
    "        h, reward_pred, continue_prob, continue_pred, x_pred = rssm.step(action, h, z)\n",
    "\n",
    "        # take an environment step with the action\n",
    "        obs, reward, terminated, truncated, info = env.step(action.squeeze())\n",
    "\n",
    "        # Add the reward to the episode return\n",
    "        ### episode_return[-1] += reward\n",
    "        tracker.add(\n",
    "            episode_metrics={\n",
    "                \"rewards\": reward,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # calculate the loss\n",
    "        continue_target = torch.tensor(1 - (terminated or truncated), device=device, dtype=torch.float32)\n",
    "        reward = torch.tensor(reward, device=device, dtype=torch.float32)\n",
    "        losses = rssm.get_losses(x, x_pred, reward, reward_pred, \n",
    "                                 continue_target, continue_prob, z_prior, z)\n",
    "\n",
    "        # Add the loss for the current step to the episode loss\n",
    "        ### episode_length += 1\n",
    "        ### for key in losses:\n",
    "        ###     episode_losses[\"episode_\" + key][-1] += losses[key]\n",
    "        tracker.add(\n",
    "            episode_metrics=losses # losses is a dict with batches for all episode metrics\n",
    "        )\n",
    "\n",
    "    # Calculate the mean loss of the episode\n",
    "    ### for key in episode_losses:\n",
    "    ###     episode_losses[key][-1] /= episode_length\n",
    "    \n",
    "    # NEW: get the mean loss and log it\n",
    "    episode_losses = tracker.get_episode_batches(reduction=\"mean\") # episode_losses is a dict\n",
    "\n",
    "    # update the world model at the end of an episode using the mean loss of the episode\n",
    "    ### rssm.optim.zero_grad()\n",
    "    ### episode_losses[\"episode_loss\"][-1].backward()\n",
    "    ### nn.utils.clip_grad_norm_(rssm.vae.parameters(), max_norm=max_grad_norm, norm_type=2)  \n",
    "    ### rssm.optim.step()\n",
    "    \n",
    "    # NEW:\n",
    "    # per episode:\n",
    "    rssm.update_parameters(episode_losses[\"loss\"])\n",
    "\n",
    "    # Log the episode return\n",
    "    ### writer.add_scalar(\"episode_return\", episode_return[-1], global_step=episode)\n",
    "    # NEW: do this later. at the end in env return queue\n",
    "\n",
    "    # Detach the losses to save memory and log them in TensorBoard\n",
    "    ### for key in episode_losses:\n",
    "    ###     episode_losses[key][-1] = episode_losses[key][-1].detach().item()\n",
    "    ###     writer.add_scalar(key, episode_losses[key][-1], global_step=episode)\n",
    "    \n",
    "    # NEW:\n",
    "    # per episode:\n",
    "    # save the rssm model with the best running loss\n",
    "    ### running_loss = np.mean(episode_losses[\"episode_loss\"][-10:])\n",
    "    ### if episode > 0 and episode % 10 == 0 and running_loss < best_running_loss:\n",
    "    ###     best_running_loss = running_loss\n",
    "    ### \n",
    "    ###     # save the rssm and agent\n",
    "    ###     rssm.save_weights(filename=f\"RSSM_{best_running_loss:.8f}\")\n",
    "    ###     agent.save(f\"weights/{agent.__class__.__name__}_agent\")\n",
    "\n",
    "    \"\"\" RL AGENT LEARNING (IN THE WORLD MODEL) \"\"\"\n",
    "    if verbose and sample_phase == n_seed_phases:\n",
    "        print(\"The agent starts learning.\")\n",
    "            \n",
    "    if sample_phase >= n_seed_phases:\n",
    "        agent.learn(\n",
    "            total_timesteps=imagination_timesteps_per_model_update,\n",
    "            progress_bar=imagination_progress_bar,\n",
    "            reset_num_timesteps=False\n",
    "        )\n",
    "    \n",
    "    # every couple episodes:\n",
    "    if sample_phase % config[\"log_interval\"] == 0:\n",
    "        \n",
    "        # log mean episode losses\n",
    "        tracker.add(\n",
    "            training_metrics=episode_losses\n",
    "        )\n",
    "        \n",
    "        # Episode return\n",
    "        if len(env.return_queue):\n",
    "            tracker.writer.add_scalar(\"episode_return\", np.array(env.return_queue)[-1], global_step=len(env.return_queue))\n",
    "            \n",
    "        # TODO Later: actor and critic losses\n",
    "\n",
    "        # save original image and reconstruction\n",
    "        save_image_and_reconstruction(x, x_pred, sample_phase)\n",
    "\n",
    "env.close()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c14715",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a3a48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "# - training loop\n",
    "# except KeyboardInterrupt:\n",
    "#     \"\"\" Clean handling for interrupts to stop training early \"\"\"\n",
    "#     print(\"Stopping training.\")\n",
    "#     # Delete the last loss if the training was stopped early\n",
    "#     # so that the list only consists of floats\n",
    "#     for key in episode_losses:\n",
    "#         if isinstance(episode_losses[key][-1], torch.Tensor):\n",
    "#             episode_losses[key] = episode_losses[key][:-1]\n",
    "# \n",
    "#     # Close the TensorBoard writer and the gym environment\n",
    "#     writer.close()\n",
    "#     env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ad0c48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d96d812",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a2fb86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42fb0f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7ebb9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90979190",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ea7a23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82409e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55e74d14",
   "metadata": {},
   "source": [
    "## Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0703ff02",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results = False\n",
    "\n",
    "if plot_results:\n",
    "    rolling_length = max(1, int(len(episode_losses[\"episode_loss\"])/20))\n",
    "\n",
    "    fig, axs = plt.subplots(ncols=3, nrows=2, figsize=(3*5, 2*5))\n",
    "\n",
    "    # Iterate over the keys and plot the losses\n",
    "    for i, key in enumerate(episode_losses.keys()):\n",
    "        row = i // 3\n",
    "        col = i % 3\n",
    "\n",
    "        axs[row, col].set_title(key)\n",
    "        losses = episode_losses[key]\n",
    "        losses_moving_average = (\n",
    "            np.convolve(\n",
    "                np.array(losses).flatten(), np.ones(rolling_length), mode=\"valid\"\n",
    "            )\n",
    "            / rolling_length\n",
    "        )\n",
    "        axs[row, col].plot(range(len(losses)), losses, label=key)\n",
    "        axs[row, col].plot(range(len(losses_moving_average)), losses_moving_average, label=\"moving average\")\n",
    "        axs[row, col].legend(loc=\"upper right\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d0fd15",
   "metadata": {},
   "source": [
    "## Showcase the trained agent playing in latent imagination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f62546",
   "metadata": {},
   "outputs": [],
   "source": [
    "showcase_agent = False\n",
    "\n",
    "if showcase_agent:\n",
    "    \n",
    "    showcase_rewards = []\n",
    "    imagination_env.render_mode = \"gif\"\n",
    "    obs, info = imagination_env.reset()\n",
    "    \n",
    "    for i in range(500):\n",
    "        \n",
    "        # apply the RL agent in eval mode to get an action\n",
    "        state = to_np(torch.cat((h.flatten().detach(), z.flatten().detach()), dim=0))\n",
    "        action, _ = agent.predict(state, deterministic=False)\n",
    "        # action = imagination_env.action_space.sample()\n",
    "        \n",
    "        obs, reward, terminated, truncated, info = imagination_env.step(action)\n",
    "        showcase_rewards.append(reward)\n",
    "        imagination_env.render()\n",
    "        \n",
    "        if terminated or truncated:\n",
    "            break\n",
    "        \n",
    "    imagination_env.close()\n",
    "    imagination_env.render_mode = None\n",
    "\n",
    "    plt.plot(showcase_rewards)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e073982",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3354e868",
   "metadata": {},
   "source": [
    "## Test area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cb6387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tensorboard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35914cfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f70fa43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bdcc84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
