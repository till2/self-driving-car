{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b1c5dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from typing import Dict, List, Union\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "from collections import deque\n",
    "from operator import itemgetter\n",
    "\n",
    "import gym_donkeycar\n",
    "import gymnasium as gym\n",
    "import imageio\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from IPython.display import display\n",
    "from ipywidgets import HBox, VBox\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from ruamel.yaml import YAML\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.stats import norm\n",
    "from tensorboard import notebook\n",
    "from tensorboard.backend.event_processing.event_accumulator import \\\n",
    "    EventAccumulator\n",
    "from torch import distributions as dist\n",
    "from torch.distributions import Categorical, Normal\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "import gymnasium as gym\n",
    "\n",
    "# suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"gymnasium.spaces.box\") # module=\"gymnasium\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ[\"IMAGEIO_IGNORE_WARNINGS\"] = \"True\"\n",
    "\n",
    "import stable_baselines3 as sb3\n",
    "from gym_donkeycar.envs.donkey_env import DonkeyEnv\n",
    "from gymnasium import spaces\n",
    "from gymnasium.spaces import Box\n",
    "from stable_baselines3 import A2C, PPO, SAC\n",
    "from stable_baselines3.common import env_checker\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.results_plotter import load_results, ts2xy\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "\n",
    "import src\n",
    "from src.actor_critic_discrete import DiscreteActorCritic\n",
    "from src.actor_critic import ContinuousActorCritic\n",
    "from src.blocks import CategoricalStraightThrough, ConvBlock\n",
    "from src.categorical_vae import CategoricalVAE\n",
    "from src.imagination_env import make_imagination_env\n",
    "from src.mlp import MLP\n",
    "from src.preprocessing import transform\n",
    "from src.replay_buffer import ReplayBuffer\n",
    "from src.rssm import RSSM\n",
    "from src.utils import (load_config, make_env, save_image_and_reconstruction,\n",
    "                       to_np, symlog, symexp, twohot_encode, ExponentialMovingAvg,\n",
    "                       ActionExponentialMovingAvg, MetricsTracker)\n",
    "from src.vae import VAE\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Load the config\n",
    "config = load_config()\n",
    "for key in config:\n",
    "    locals()[key] = config[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239558a5",
   "metadata": {},
   "source": [
    "## Init the RSSM (including all networks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cda9f099",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing encoder:\n",
      "- adding ConvBlock((3, 64))                   ==> output shape: (64, 32, 32) ==> prod: 65536\n",
      "- adding ConvBlock((64, 128))                   ==> output shape: (128, 16, 16) ==> prod: 32768\n",
      "- adding ConvBlock((128, 256))                   ==> output shape: (256, 8, 8) ==> prod: 16384\n",
      "- adding ConvBlock((256, 512))                   ==> output shape: (512, 4, 4) ==> prod: 8192\n",
      "- adding ConvBlock((512, 256))                   ==> output shape: (256, 2, 2) ==> prod: 1024\n",
      "- adding Flatten()\n",
      "- adding Reshape: (*,1024) => (*,32,32)\n",
      "\n",
      "Initializing decoder:\n",
      "- adding Reshape: (*,1024) => (*,256,2,2)\n",
      "- adding transpose ConvBlock(256, 256)                   ==> output shape: (256, 4, 4) ==> prod: 4096\n",
      "- adding transpose ConvBlock(256, 512)                   ==> output shape: (512, 8, 8) ==> prod: 32768\n",
      "- adding transpose ConvBlock(512, 256)                   ==> output shape: (256, 16, 16) ==> prod: 65536\n",
      "- adding transpose ConvBlock(256, 128)                   ==> output shape: (128, 32, 32) ==> prod: 131072\n",
      "- adding transpose ConvBlock(128, 3)                   ==> output shape: (3, 64, 64) ==> prod: 12288\n",
      "\n",
      "Initializing dynamics_mlp.\n",
      "\n",
      "Initializing reward_mlp.\n",
      "Adding zero weight init to the output layer.\n",
      "\n",
      "Initializing continue_mlp.\n"
     ]
    }
   ],
   "source": [
    "rssm = RSSM()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56fd60e",
   "metadata": {},
   "source": [
    "TODO:\n",
    "\n",
    "required:\n",
    "- use discrete actor critic agent [WIP ]\n",
    "- distributional reward_predictor [ ]\n",
    "\n",
    "optional:\n",
    "(- output batches with rssm)\n",
    "(- train on vector env with batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229f8133",
   "metadata": {},
   "source": [
    "## Create the imagination environment for training the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9a08c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = ReplayBuffer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec4e9cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding a TimeLimit wrapper with 16 max imagination episode steps.\n",
      "Adding an AutoReset wrapper.\n",
      "Adding a RescaleActionV0 wrapper. Low: [-1. -1. -1.], High: [1. 1. 1.]\n",
      "Adding a Gymnasium RecordEpisodeStatistics wrapper.\n"
     ]
    }
   ],
   "source": [
    "imagination_env = make_imagination_env(rssm, replay_buffer, render_mode=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a93b68d",
   "metadata": {},
   "source": [
    "## Init the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe1ee1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing agent with 1536 features and 3 actions.\n",
      "Initializing critic.\n",
      "Adding zero weight init to the output layer.\n",
      "Initializing actor.\n",
      "Adding zero weight init to the output layer.\n"
     ]
    }
   ],
   "source": [
    "# agent = PPO(\n",
    "#     policy=\"MlpPolicy\",\n",
    "#     env=imagination_env,\n",
    "#     verbose=verbose,\n",
    "#     tensorboard_log=log_dir,\n",
    "#     gamma=gamma,\n",
    "#     gae_lambda=lam,\n",
    "#     ent_coef=ent_coef,\n",
    "# )\n",
    "\n",
    "agent = DiscreteActorCritic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705a7a7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcae4900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1536])\n",
      "torch.Size([32, 1536])\n"
     ]
    }
   ],
   "source": [
    "sample_instance = torch.randn(config[\"H\"] + config[\"Z\"]).to(config[\"device\"]) # torch.Size([1536])\n",
    "sample_batch = torch.randn(32, config[\"H\"] + config[\"Z\"]).to(config[\"device\"]) # torch.Size([32, 1536])\n",
    "\n",
    "print(sample_instance.shape)\n",
    "print(sample_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "672c8e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af9ae06c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action = torch.randn(batch_size, config[\"A\"]).to(config[\"device\"]) # torch.Size([3])\n",
    "action.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e8ae331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 512])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = torch.randn(batch_size, config[\"H\"]).to(config[\"device\"]) # torch.Size([512])\n",
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10c8fde4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1024])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.randn(batch_size, config[\"Z\"]).to(config[\"device\"]) # torch.Size([1024]) = 32*32\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96e3dca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "h, reward_pred, continue_prob, continue_pred, x_reconstruction = rssm.step(action, h, z)\n",
    "print(h.shape)\n",
    "print(reward_pred.shape)\n",
    "print(continue_prob.shape)\n",
    "print(continue_pred.shape)\n",
    "print(x_reconstruction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dddcc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27455aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02b6516",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a59fc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d75d589",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833a4b30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60016e18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e225e265",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5061107",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1396668c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b05696",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae902e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5697097a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c802872",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "856cb39a",
   "metadata": {},
   "source": [
    "## Training loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6367c5ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ae41bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent_tracker = MetricsTracker(\n",
    "#     training_metrics=[\"critic_loss\", \"actor_loss\"],\n",
    "#     episode_metrics=[\"rewards\", \"log_probs\", \"value_preds\", \"critic_dists\", \"entropies\", \"masks\"],\n",
    "# )\n",
    "# \n",
    "# for imagination_phase in range(agent_update_phases_per_model_update):\n",
    "#     \n",
    "#     if imagination_phase == 0:\n",
    "#         dream_obs, dream_info = imagination_env.reset(seed=42)\n",
    "#         dream_obs = torch.tensor(dream_obs).to(device)\n",
    "#     \n",
    "#     for step in range(imagination_steps_per_agent_update):\n",
    "#         \n",
    "#         value_pred, critic_dist = agent.apply_critic(dream_obs)\n",
    "# \n",
    "#         # Get an action and take an environment step\n",
    "#         action, log_prob, actor_entropy = agent.get_action(dream_obs)\n",
    "#         dream_obs, reward, terminated, truncated, info = imagination_env.step(to_np(action))\n",
    "#         \n",
    "#         # Transform the next obs\n",
    "#         dream_obs = torch.Tensor(dream_obs).to(device)\n",
    "#         \n",
    "#         # every step:\n",
    "#         agent_tracker.add(\n",
    "#             episode_metrics={\n",
    "#                 \"rewards\": reward,\n",
    "#                 \"log_probs\": log_prob,\n",
    "#                 \"value_preds\": value_pred,\n",
    "#                 \"critic_dists\": critic_dist,\n",
    "#                 \"entropies\": actor_entropy,\n",
    "#                 \"masks\": torch.tensor(0.0 if terminated else 1.0),\n",
    "#             }\n",
    "#         )\n",
    "#     \n",
    "#     # every imagination phase:\n",
    "#     episode_batches = agent_tracker.get_episode_batches() # episode_batches is a dict\n",
    "#     last_value_pred, _ = agent.apply_critic(dream_obs) # last value prediction for GAE\n",
    "# \n",
    "#     # Update the agent's parameters\n",
    "#     critic_loss, actor_loss = agent.get_loss(episode_batches, last_value_pred)\n",
    "#     agent.update_parameters(critic_loss, actor_loss)\n",
    "#     \n",
    "#     # Only for the last imagined episode: Log the episode metrics\n",
    "#     if imagination_phase == agent_update_phases_per_model_update - 1:\n",
    "# \n",
    "#         agent_tracker.add(\n",
    "#             training_metrics={\n",
    "#                 \"critic_loss\": critic_loss,\n",
    "#                 \"actor_loss\": actor_loss,\n",
    "#             }\n",
    "#         )\n",
    "#     \n",
    "#         # Episode return\n",
    "#         if len(imagination_env.return_queue):\n",
    "#             agent_tracker.writer.add_scalar(\"dream_episode_return\", np.array(imagination_env.return_queue)[-1], global_step=sample_phase)\n",
    "#     \n",
    "#         # Actor and critic losses\n",
    "#         agent_tracker.log_to_tensorboard(step=sample_phase)\n",
    "#     \n",
    "#         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "bff31322",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating environment with properties:\n",
      "- type: toy env\n",
      "- adding a TimeLimit wrapper with 1000 max episode steps\n",
      "- adding an AutoReset wrapper\n",
      "- making a AsyncVectorEnv with 5 envs\n",
      "- adding a RescaleActionV0 wrapper Low: -1, High: 1\n",
      "- adding a Gymnasium RecordEpisodeStatistics wrapper\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                  | 0/7812 [00:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMAGINATION PHASE: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'flatten'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [103], line 127\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIMAGINATION PHASE:\u001b[39m\u001b[38;5;124m\"\u001b[39m, imagination_phase) \u001b[38;5;66;03m# debug\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m imagination_phase \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 127\u001b[0m     dream_obs, dream_info \u001b[38;5;241m=\u001b[39m \u001b[43mimagination_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m     dream_obs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(dream_obs)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(imagination_steps_per_agent_update):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gymnasium/wrappers/record_episode_statistics.py:73\u001b[0m, in \u001b[0;36mRecordEpisodeStatistics.reset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;124;03m\"\"\"Resets the environment using kwargs and resets the episode returns and lengths.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     obs, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepisode_start_times \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfull(\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs, time\u001b[38;5;241m.\u001b[39mperf_counter(), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32\n\u001b[1;32m     76\u001b[0m     )\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepisode_returns \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gymnasium/core.py:414\u001b[0m, in \u001b[0;36mWrapper.reset\u001b[0;34m(self, seed, options)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset\u001b[39m(\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, seed: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, options: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    412\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[WrapperObsType, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;124;03m\"\"\"Uses the :meth:`reset` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 414\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gymnasium/core.py:414\u001b[0m, in \u001b[0;36mWrapper.reset\u001b[0;34m(self, seed, options)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset\u001b[39m(\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, seed: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, options: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    412\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[WrapperObsType, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;124;03m\"\"\"Uses the :meth:`reset` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 414\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gymnasium/core.py:414\u001b[0m, in \u001b[0;36mWrapper.reset\u001b[0;34m(self, seed, options)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset\u001b[39m(\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, seed: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, options: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    412\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[WrapperObsType, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;124;03m\"\"\"Uses the :meth:`reset` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 414\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gymnasium/wrappers/time_limit.py:75\u001b[0m, in \u001b[0;36mTimeLimit.reset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;03m\"\"\"Resets the environment with :param:`**kwargs` and sets the number of steps elapsed to zero.\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \n\u001b[1;32m     68\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m    The reset environment\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/GitHub/self-driving-car/src/imagination_env.py:124\u001b[0m, in \u001b[0;36mImaginationEnv.reset\u001b[0;34m(self, seed, options)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimages \u001b[38;5;241m=\u001b[39m [img]\n\u001b[1;32m    122\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrssm\u001b[38;5;241m.\u001b[39mvae\u001b[38;5;241m.\u001b[39mencode(x)\n\u001b[0;32m--> 124\u001b[0m observation \u001b[38;5;241m=\u001b[39m to_np(torch\u001b[38;5;241m.\u001b[39mcat((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh\u001b[38;5;241m.\u001b[39mflatten(), \u001b[43mz\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m()), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m    126\u001b[0m info \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m observation, info\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'flatten'"
     ]
    }
   ],
   "source": [
    "# New dreamer training loop with batches for the distributional critic\n",
    "# (and later: add manual actor-critic training in imagination env. and delete sb3).\n",
    "# add batches to rssm\n",
    "\n",
    "### rssm.load_weights(\"weights/RSSM_1.70111713\")\n",
    "### rssm.train()\n",
    "\n",
    "# Create the environment\n",
    "env = make_env()\n",
    "batch_size = config[\"n_envs\"]\n",
    "\n",
    "# World Model Logging\n",
    "model_tracker = MetricsTracker(\n",
    "    # Log the mean loss for the training metrics\n",
    "    training_metrics=[\"loss\", \"image_loss\", \"reward_loss\", \"continue_loss\", \"dyn_loss\", \"rep_loss\", \"rewards\"],\n",
    "    \n",
    "    # Loss per step\n",
    "    episode_metrics=[\"loss\", \"image_loss\", \"reward_loss\", \"continue_loss\", \"dyn_loss\", \"rep_loss\", \"rewards\"],\n",
    ")\n",
    "\n",
    "# Agent Logging\n",
    "agent_tracker = MetricsTracker(\n",
    "    training_metrics=[\"critic_loss\", \"actor_loss\"],\n",
    "    episode_metrics=[\"rewards\", \"log_probs\", \"value_preds\", \"critic_dists\", \"entropies\", \"masks\"],\n",
    ")\n",
    "\n",
    "\n",
    "for sample_phase in tqdm(range(start_phase, n_seed_phases + n_model_updates)):\n",
    "    \n",
    "    # Reset the RNN's hidden state\n",
    "    ### h = torch.zeros(rssm.num_rnn_layers, 1, H, device=device, dtype=torch.float32) # seq_len, B, H\n",
    "    # NEW:\n",
    "    # - init in rssm.step (if h is not given)\n",
    "    \n",
    "    if sample_phase == start_phase:\n",
    "        \n",
    "        # Get the first obs\n",
    "        obs, info = env.reset(seed=42)\n",
    "        x = transform(torch.tensor(obs)) # => (B,C,H,W)\n",
    "        replay_buffer.push(x)\n",
    "        \n",
    "        # NEW:\n",
    "        step_dict = rssm.pre_step(x=x)\n",
    "    \n",
    "    for step in range(n_steps_per_model_update):\n",
    "    \n",
    "        \"\"\" WORLD MODEL LEARNING \"\"\"\n",
    "\n",
    "        # Get real z and z prediction, also get state\n",
    "        ###z_prior = rssm.dynamics_mlp(h).view(-1, num_categoricals, num_classes) # (1,32,32) for the softmax\n",
    "        ###z_prior = F.softmax(z_prior, -1).flatten(start_dim=1, end_dim=2) # (1, 1024)\n",
    "        ###z = rssm.vae.encode(x).flatten(start_dim=1, end_dim=2)\n",
    "        ###state = to_np(torch.cat((h.flatten().detach(), z.flatten().detach()), dim=0))\n",
    "\n",
    "        # Predict one step using the world model (for training it)\n",
    "        ### h, reward_pred, continue_prob, continue_pred, x_pred = rssm.step(action, h, z)\n",
    "        # NEW:\n",
    "        h = step_dict[\"h\"]\n",
    "        step_dict = rssm.pre_step(h, x)\n",
    "        assert h.shape == torch.Size([batch_size, H])\n",
    "        assert x.shape == torch.Size([batch_size, 1 if grayscale else 3, *size])\n",
    "        \n",
    "        #for key, val in step_dict.items():\n",
    "        #    print(f\"{key} shape:\", val.shape)\n",
    "        \n",
    "        # Get action (random in init phases, otherwise from agent)\n",
    "        if sample_phase < n_seed_phases:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            assert step_dict[\"state\"].shape == torch.Size([batch_size, H+Z])\n",
    "            action, _, _ = agent.get_action(step_dict[\"state\"])\n",
    "        \n",
    "        # Update the world model state\n",
    "        h = step_dict[\"h\"]\n",
    "        z = step_dict[\"z\"]\n",
    "        h = rssm.step(action, h, z)\n",
    "\n",
    "        # Take an environment step with the action\n",
    "        obs, reward, terminated, truncated, info = env.step(to_np(action))\n",
    "        x = transform(torch.tensor(obs)) # => (B,C,H,W)\n",
    "        replay_buffer.push(x)\n",
    "\n",
    "        # Calculate the world model loss\n",
    "        ### continue_target = torch.tensor(1 - (terminated | truncated), device=device, dtype=torch.float32)\n",
    "        ### reward = torch.tensor(reward, device=device, dtype=torch.float32)\n",
    "        ###losses = rssm.get_losses(x, x_pred, reward, reward_pred, \n",
    "        ###                         continue_target, continue_prob, z_prior, z)\n",
    "        # NEW:\n",
    "        step_dict[\"continue_target\"] = continue_target = torch.tensor(1 - (terminated | truncated), device=device, dtype=torch.float32)\n",
    "        step_dict[\"reward_target\"] = reward = torch.tensor(reward, device=device, dtype=torch.float32)\n",
    "        \n",
    "        losses = rssm.get_losses(step_dict)\n",
    "\n",
    "        # Track the losses\n",
    "        model_tracker.add(\n",
    "            episode_metrics=losses # losses is a dict with batches for all episode metrics\n",
    "        )\n",
    "        # Track the reward for the episode return\n",
    "        model_tracker.add(\n",
    "            episode_metrics={\n",
    "                \"rewards\": reward,\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    # Get mean loss and update world model\n",
    "    episode_losses = model_tracker.get_episode_batches(reduction=\"mean\") # episode_losses is a dict\n",
    "    rssm.update_parameters(episode_losses[\"loss\"])\n",
    "\n",
    "    \n",
    "    \"\"\" RL AGENT LEARNING (IN THE WORLD MODEL) \"\"\"\n",
    "    if verbose and sample_phase == n_seed_phases:\n",
    "        print(\"The agent starts learning.\")\n",
    "\n",
    "        \n",
    "    if sample_phase >= n_seed_phases:\n",
    "        ### agent.learn(\n",
    "        ###     total_timesteps=imagination_steps_per_model_update,\n",
    "        ###     progress_bar=imagination_progress_bar,\n",
    "        ###     reset_num_timesteps=False\n",
    "        ### )\n",
    "        \n",
    "        # NEW: discrete actor critic\n",
    "        for imagination_phase in range(agent_update_phases_per_model_update):\n",
    "            print(\"IMAGINATION PHASE:\", imagination_phase) # debug\n",
    "            \n",
    "            if imagination_phase == 0:\n",
    "                dream_obs, dream_info = imagination_env.reset(seed=42)\n",
    "                dream_obs = torch.tensor(dream_obs).to(device)\n",
    "\n",
    "            for step in range(imagination_steps_per_agent_update):\n",
    "\n",
    "                value_pred, critic_dist = agent.apply_critic(dream_obs)\n",
    "\n",
    "                # Get an action and take an environment step\n",
    "                action, log_prob, actor_entropy = agent.get_action(dream_obs)\n",
    "                dream_obs, reward, terminated, truncated, info = imagination_env.step(to_np(action))\n",
    "\n",
    "                # Transform the next obs\n",
    "                dream_obs = torch.Tensor(dream_obs).to(device)\n",
    "\n",
    "                # every step:\n",
    "                agent_tracker.add(\n",
    "                    episode_metrics={\n",
    "                        \"rewards\": reward,\n",
    "                        \"log_probs\": log_prob,\n",
    "                        \"value_preds\": value_pred,\n",
    "                        \"critic_dists\": critic_dist,\n",
    "                        \"entropies\": actor_entropy,\n",
    "                        \"masks\": torch.tensor(0.0 if terminated else 1.0),\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            # every imagination phase:\n",
    "            episode_batches = agent_tracker.get_episode_batches() # episode_batches is a dict\n",
    "            last_value_pred, _ = agent.apply_critic(dream_obs) # last value prediction for GAE\n",
    "\n",
    "            # Update the agent's parameters\n",
    "            critic_loss, actor_loss = agent.get_loss(episode_batches, last_value_pred)\n",
    "            agent.update_parameters(critic_loss, actor_loss)\n",
    "\n",
    "            # Only for the last imagined episode: Log the episode metrics\n",
    "            print(imagination_phase, agent_update_phases_per_model_update-1)\n",
    "            if imagination_phase == agent_update_phases_per_model_update - 1:\n",
    "                print(\"HI\")\n",
    "\n",
    "                agent_tracker.add(\n",
    "                    training_metrics={\n",
    "                        \"critic_loss\": critic_loss,\n",
    "                        \"actor_loss\": actor_loss,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "                # Episode return\n",
    "                if len(imagination_env.return_queue):\n",
    "                    agent_tracker.writer.add_scalar(\"dream_episode_return\", np.array(imagination_env.return_queue)[-1], global_step=sample_phase)\n",
    "\n",
    "                # Actor and critic losses\n",
    "                agent_tracker.log_to_tensorboard(step=sample_phase)\n",
    "\n",
    "    \n",
    "    # Every couple episodes:\n",
    "    if sample_phase % config[\"log_interval\"] == 0:\n",
    "        \n",
    "        # Log: mean episode losses\n",
    "        model_tracker.add(\n",
    "            training_metrics=episode_losses\n",
    "        )\n",
    "        \n",
    "        # Log: episode return\n",
    "        if len(env.return_queue):\n",
    "            model_tracker.writer.add_scalar(\"episode_return\", np.array(env.return_queue)[-1], global_step=len(env.return_queue))\n",
    "        \n",
    "        # Tensorboard\n",
    "        model_tracker.log_to_tensorboard(step=sample_phase)\n",
    "        \n",
    "        # TODO Later: actor and critic losses\n",
    "\n",
    "        # Save original image and reconstruction\n",
    "        save_image_and_reconstruction(x, x_pred, sample_phase)\n",
    "\n",
    "env.close()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b0e2db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f9e743",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54397fd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a5a714",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87c217d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d3042e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c559628f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70683628",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4e1352",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9086f8dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bbd4f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b8b585",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09793cc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f14ec7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c922367e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "a7b67bc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 64, 64])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_dict[\"x\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "558d9e2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_dict[\"reward_target\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6ee982",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_dict[\"reward_target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "78b9ab3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 7\n",
    "h = torch.randn(batch_size, config[\"H\"]).to(config[\"device\"])\n",
    "x = torch.randn(batch_size, 3, 64, 64).to(config[\"device\"]) #  (B, C, H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "93e4c36a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 64])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape[2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "df51d097",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "number of dims don't match in permute",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [66], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m torch\u001b[38;5;241m.\u001b[39mtensor(env\u001b[38;5;241m.\u001b[39mreset()[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchvision/transforms/transforms.py:94\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 94\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchvision/transforms/transforms.py:474\u001b[0m, in \u001b[0;36mLambda.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m--> 474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlambd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/GitHub/self-driving-car/src/preprocessing.py:30\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     11\u001b[0m height, width \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m\"\"\" \u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03mScales to [0,1], resizes to [H_new,W_new] and optionally grayscales a batch of images\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;03m    - (!) changes the dims to channel-first!\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     28\u001b[0m transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;66;03m#transforms.ToTensor(), # devides by 255 to scale the input to the range [0,1]\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mLambda(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m), \u001b[38;5;66;03m# => (B,C,H,W)\u001b[39;00m\n\u001b[1;32m     31\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mLambda(\u001b[38;5;28;01mlambda\u001b[39;00m x: x \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255\u001b[39m),\n\u001b[1;32m     32\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mLambda(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mto(device)),\n\u001b[1;32m     33\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mResize((height, width)),\n\u001b[1;32m     34\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mGrayscale() \u001b[38;5;28;01mif\u001b[39;00m grayscale \u001b[38;5;28;01melse\u001b[39;00m transforms\u001b[38;5;241m.\u001b[39mLambda(\u001b[38;5;28;01mlambda\u001b[39;00m x: x),\n\u001b[1;32m     35\u001b[0m ])\n",
      "\u001b[0;31mRuntimeError\u001b[0m: number of dims don't match in permute"
     ]
    }
   ],
   "source": [
    "torch.tensor(env.reset()[0][0]).shape\n",
    "transform(torch.tensor(env.reset()[0][0])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395f5161",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "690d9572",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
       "        grad_fn=<CatBackward0>),\n",
       " 'h': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'),\n",
       " 'z': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
       "        grad_fn=<ReshapeAliasBackward0>),\n",
       " 'z_pred': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
       "        grad_fn=<ReshapeAliasBackward0>),\n",
       " 'z_probs': tensor([[0.0257, 0.0392, 0.0229,  ..., 0.0146, 0.0152, 0.0148],\n",
       "         [0.0291, 0.0325, 0.0226,  ..., 0.0168, 0.0169, 0.0169],\n",
       "         [0.0313, 0.0304, 0.0220,  ..., 0.0168, 0.0175, 0.0170],\n",
       "         ...,\n",
       "         [0.0191, 0.1007, 0.0210,  ..., 0.0169, 0.0169, 0.0169],\n",
       "         [0.0256, 0.0389, 0.0542,  ..., 0.0517, 0.0155, 0.0179],\n",
       "         [0.0242, 0.0263, 0.0219,  ..., 0.0142, 0.0169, 0.0163]],\n",
       "        device='cuda:0', grad_fn=<ReshapeAliasBackward0>),\n",
       " 'z_pred_probs': tensor([[0.0197, 0.0177, 0.0330,  ..., 0.0189, 0.0211, 0.0377],\n",
       "         [0.0197, 0.0177, 0.0330,  ..., 0.0189, 0.0211, 0.0377],\n",
       "         [0.0197, 0.0177, 0.0330,  ..., 0.0189, 0.0211, 0.0377],\n",
       "         ...,\n",
       "         [0.0197, 0.0177, 0.0330,  ..., 0.0189, 0.0211, 0.0377],\n",
       "         [0.0197, 0.0177, 0.0330,  ..., 0.0189, 0.0211, 0.0377],\n",
       "         [0.0197, 0.0177, 0.0330,  ..., 0.0189, 0.0211, 0.0377]],\n",
       "        device='cuda:0', grad_fn=<ReshapeAliasBackward0>),\n",
       " 'reward_pred': tensor([-0.0086, -0.0086, -0.0086, -0.0086, -0.0086, -0.0086, -0.0086],\n",
       "        device='cuda:0', grad_fn=<ViewBackward0>),\n",
       " 'continue_prob': tensor([0.4893, 0.5290, 0.4239, 0.5885, 0.3936, 0.5356, 0.3580],\n",
       "        device='cuda:0', grad_fn=<ViewBackward0>),\n",
       " 'continue_pred': tensor([0., 0., 1., 0., 0., 1., 0.], device='cuda:0', grad_fn=<ViewBackward0>),\n",
       " 'x': tensor([[[[-1.5563e+00,  8.8599e-01,  2.1080e-01,  ..., -1.0293e+00,\n",
       "             1.1436e-01,  1.1504e+00],\n",
       "           [ 4.9208e-01, -7.4456e-01,  8.3246e-01,  ..., -8.2809e-01,\n",
       "            -6.6272e-01, -1.3448e+00],\n",
       "           [ 7.3857e-01, -9.7052e-01, -6.9171e-02,  ..., -8.2060e-03,\n",
       "             1.3231e+00,  1.8802e+00],\n",
       "           ...,\n",
       "           [-2.7924e+00,  1.8495e-01, -4.3040e-01,  ...,  2.2028e-01,\n",
       "             5.0409e-01, -8.9407e-01],\n",
       "           [ 1.2396e+00,  1.1790e+00, -1.6665e-01,  ...,  7.8144e-01,\n",
       "             2.9619e-01, -8.3734e-02],\n",
       "           [ 1.0811e+00,  1.0909e+00, -4.5385e-01,  ...,  1.1841e+00,\n",
       "            -1.3887e+00,  6.0403e-01]],\n",
       " \n",
       "          [[-2.1428e-01, -3.0190e-01,  1.6307e+00,  ..., -4.6195e-01,\n",
       "            -3.5699e-02, -6.3680e-01],\n",
       "           [-8.6993e-02, -8.6196e-02, -7.9297e-02,  ..., -1.0848e-01,\n",
       "             7.5356e-01,  1.5007e-01],\n",
       "           [-7.9422e-01, -6.8637e-01, -1.5308e+00,  ..., -1.2590e+00,\n",
       "            -3.3702e-01,  2.3491e-01],\n",
       "           ...,\n",
       "           [ 2.7065e-01,  2.5693e-01,  1.0701e+00,  ...,  7.1083e-01,\n",
       "             3.2929e-01,  9.4540e-02],\n",
       "           [ 2.1128e-01, -1.5418e+00,  5.2688e-01,  ...,  1.0606e+00,\n",
       "             1.3504e+00, -1.2576e+00],\n",
       "           [ 1.5232e+00,  4.8664e-01, -6.1377e-01,  ..., -8.7847e-01,\n",
       "             1.3976e+00, -6.6842e-01]],\n",
       " \n",
       "          [[-9.7427e-02, -2.7683e-01,  4.7391e-01,  ...,  4.8415e-01,\n",
       "            -1.9088e+00, -4.3381e-01],\n",
       "           [ 1.0335e+00, -1.2460e+00,  3.2792e-01,  ..., -1.2491e-01,\n",
       "            -1.8349e+00,  1.4070e+00],\n",
       "           [-1.9185e-01, -8.4922e-01, -1.7310e+00,  ..., -9.4208e-01,\n",
       "             3.1070e-01,  2.0799e-01],\n",
       "           ...,\n",
       "           [ 7.4256e-03,  7.1847e-02, -1.1577e+00,  ...,  2.9641e+00,\n",
       "            -8.4196e-01,  1.0863e+00],\n",
       "           [ 1.1571e+00,  3.6458e-01, -7.7531e-01,  ...,  5.2353e-01,\n",
       "             2.7853e-01,  1.1162e+00],\n",
       "           [ 1.5611e-01, -1.9909e-01,  1.4495e-02,  ..., -1.9466e-01,\n",
       "            -1.6516e-02,  1.3004e-01]]],\n",
       " \n",
       " \n",
       "         [[[-1.1251e-01, -1.6281e+00, -1.8472e+00,  ...,  1.2280e+00,\n",
       "             7.2827e-01,  4.5061e-01],\n",
       "           [ 4.3472e-01, -7.8003e-01, -1.5167e+00,  ...,  1.1457e+00,\n",
       "             8.2095e-01,  1.1025e+00],\n",
       "           [ 3.3436e-01,  3.3816e-01,  6.4053e-01,  ..., -1.3576e+00,\n",
       "             6.8297e-02,  2.4408e+00],\n",
       "           ...,\n",
       "           [ 6.6504e-01, -4.8972e-01, -1.1607e+00,  ..., -1.2873e+00,\n",
       "             1.2823e+00, -7.0976e-01],\n",
       "           [ 3.3280e-01,  1.1544e+00, -1.0833e+00,  ...,  3.2458e-01,\n",
       "             2.5266e-02,  1.2111e+00],\n",
       "           [ 2.2420e-01, -1.5595e-01, -6.8154e-01,  ..., -4.9151e-01,\n",
       "             1.0029e+00,  6.2296e-01]],\n",
       " \n",
       "          [[ 1.7306e+00,  1.9615e-01, -2.2528e-02,  ...,  7.7488e-01,\n",
       "             1.4398e+00,  4.2700e-01],\n",
       "           [ 4.3987e-02, -7.2545e-01, -5.5324e-02,  ...,  4.9419e-01,\n",
       "             6.1798e-01, -1.6667e-02],\n",
       "           [-1.7309e+00,  5.9632e-01, -6.7351e-01,  ...,  1.8405e+00,\n",
       "             8.3921e-01,  1.7848e-01],\n",
       "           ...,\n",
       "           [ 1.1365e-02, -1.1819e+00,  1.0497e+00,  ...,  9.9460e-01,\n",
       "            -1.6306e+00,  1.3897e+00],\n",
       "           [-1.5485e+00, -1.1650e+00,  8.3392e-01,  ..., -3.1897e-01,\n",
       "             1.1858e+00, -1.2802e+00],\n",
       "           [ 7.2524e-01, -6.4623e-01, -3.1341e-02,  ...,  4.3027e-01,\n",
       "            -1.6946e-01, -1.4707e+00]],\n",
       " \n",
       "          [[-1.2097e+00, -2.3044e-01, -9.0430e-01,  ..., -1.2984e+00,\n",
       "            -3.7930e-01,  5.3738e-01],\n",
       "           [ 2.7658e-01, -9.2564e-01,  6.1105e-01,  ...,  7.8800e-01,\n",
       "            -9.1204e-01,  1.3099e-01],\n",
       "           [-2.1847e-02, -8.1927e-02,  5.6247e-01,  ..., -7.3168e-02,\n",
       "             4.4319e-01, -1.0036e+00],\n",
       "           ...,\n",
       "           [-2.3637e-01, -6.0932e-01, -1.5685e-01,  ...,  1.5830e+00,\n",
       "             5.7013e-01,  6.2298e-01],\n",
       "           [-5.2312e-02, -5.2549e-01, -9.7589e-01,  ...,  1.0657e+00,\n",
       "            -9.1103e-02, -3.0633e-01],\n",
       "           [-2.4143e+00,  4.3512e-01,  1.1854e+00,  ...,  2.0318e+00,\n",
       "            -4.3303e-01,  7.5227e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 5.1681e-01, -1.2663e-01, -2.9038e-01,  ...,  2.1579e+00,\n",
       "             1.5399e+00,  5.4529e-02],\n",
       "           [-3.7127e-01,  1.9439e-01,  1.4145e+00,  ...,  2.0582e+00,\n",
       "             1.2038e+00, -1.7355e-01],\n",
       "           [ 5.5896e-01,  3.3242e-01,  9.3606e-01,  ...,  1.1385e-03,\n",
       "            -2.7797e-01, -4.5187e-01],\n",
       "           ...,\n",
       "           [ 7.7071e-01, -8.8531e-01,  6.1521e-01,  ...,  4.5181e-01,\n",
       "             1.4124e-01,  3.0329e-01],\n",
       "           [-8.4244e-01,  1.6014e+00,  2.5782e-01,  ..., -1.6567e+00,\n",
       "             1.8010e-01,  2.9773e+00],\n",
       "           [-4.7309e-01, -4.6771e-01,  1.3651e+00,  ..., -1.0865e+00,\n",
       "            -4.3916e-01,  1.6028e+00]],\n",
       " \n",
       "          [[ 4.8576e-03,  3.1478e-01,  1.0172e-01,  ...,  3.0442e-01,\n",
       "            -1.7857e+00, -6.0254e-01],\n",
       "           [ 2.1003e+00,  1.0649e+00, -5.9861e-01,  ..., -1.6809e+00,\n",
       "             8.8580e-01, -1.9744e+00],\n",
       "           [-3.7867e-01, -2.4596e+00,  5.9231e-01,  ...,  4.0128e-01,\n",
       "            -1.4477e-01, -4.8670e-01],\n",
       "           ...,\n",
       "           [ 7.9654e-01, -9.5564e-01,  1.0030e+00,  ...,  8.8080e-01,\n",
       "             2.4619e-01, -9.2477e-02],\n",
       "           [ 2.3311e-01, -1.0535e+00,  9.2905e-01,  ..., -2.6406e+00,\n",
       "            -8.7535e-02,  1.4677e+00],\n",
       "           [-4.8873e-01, -6.0609e-01, -1.2176e+00,  ..., -2.0080e-01,\n",
       "            -3.2102e-01, -1.2386e+00]],\n",
       " \n",
       "          [[-7.4521e-01,  7.9113e-01,  1.6008e-01,  ..., -4.1037e-01,\n",
       "            -1.7454e+00,  1.6580e+00],\n",
       "           [ 2.3296e+00,  1.6373e-01, -7.3014e-01,  ...,  1.9326e-01,\n",
       "             3.0673e-01, -1.8288e-01],\n",
       "           [-6.4437e-01, -2.8022e-01, -9.7400e-01,  ..., -6.3354e-01,\n",
       "             1.0993e+00,  4.7400e-01],\n",
       "           ...,\n",
       "           [-4.7264e-01,  1.3222e+00, -5.4683e-01,  ..., -6.9057e-01,\n",
       "            -5.8677e-01, -1.3126e+00],\n",
       "           [ 1.8664e+00,  1.3558e+00,  3.7414e-01,  ...,  2.3723e-01,\n",
       "            -7.8260e-01, -9.6782e-01],\n",
       "           [-5.9428e-01, -6.2616e-01,  8.0057e-01,  ..., -4.1479e-01,\n",
       "             1.5596e-01,  1.2041e+00]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 3.1708e-01, -4.0751e-01, -6.8255e-01,  ..., -5.0551e-02,\n",
       "             1.6429e+00, -3.8937e-01],\n",
       "           [-5.8031e-01,  6.7345e-01,  9.8206e-01,  ..., -1.1429e+00,\n",
       "            -6.9145e-01, -1.9985e+00],\n",
       "           [ 1.1966e-01,  3.8778e-01, -9.4157e-01,  ...,  2.0425e+00,\n",
       "            -2.3064e+00, -1.5586e-02],\n",
       "           ...,\n",
       "           [-4.4816e-01,  8.0880e-01, -6.7283e-02,  ...,  1.3132e+00,\n",
       "            -2.5675e-01, -9.4217e-01],\n",
       "           [ 1.4293e+00,  1.4362e+00, -2.3903e-02,  ...,  2.3450e+00,\n",
       "             1.5492e+00,  2.1385e+00],\n",
       "           [ 4.9660e-01, -5.3213e-01, -1.0186e+00,  ...,  5.8880e-01,\n",
       "             5.3050e-01, -4.0104e-02]],\n",
       " \n",
       "          [[ 3.3181e-01, -1.2026e+00, -3.6612e-01,  ...,  5.3326e-01,\n",
       "             1.4230e+00, -9.8971e-01],\n",
       "           [-2.0352e-01, -1.9773e+00,  3.5854e-01,  ..., -4.1712e-01,\n",
       "             3.3343e-01,  4.6067e-01],\n",
       "           [-1.4167e+00, -1.4068e+00, -7.4954e-02,  ..., -5.0051e-01,\n",
       "             8.9678e-01, -6.4931e-01],\n",
       "           ...,\n",
       "           [-2.0134e-01, -1.3923e-01,  1.8185e+00,  ..., -1.1431e+00,\n",
       "            -9.4233e-01, -1.0365e+00],\n",
       "           [-1.2106e+00,  1.0973e+00,  1.1589e+00,  ..., -8.2966e-01,\n",
       "            -3.5757e-02,  1.8423e-01],\n",
       "           [ 3.0678e-02, -3.6797e-01, -6.1890e-02,  ...,  1.3330e+00,\n",
       "            -3.3516e-01,  2.0123e-01]],\n",
       " \n",
       "          [[-1.4691e+00, -7.1736e-01,  1.7830e+00,  ..., -3.2244e-01,\n",
       "            -2.2899e-01,  8.6795e-01],\n",
       "           [ 1.3622e-01, -8.3316e-01,  6.7631e-01,  ..., -8.1568e-01,\n",
       "            -1.7460e+00,  6.1856e-01],\n",
       "           [-1.4437e+00,  1.7005e-01, -3.2696e-01,  ...,  1.3611e+00,\n",
       "             2.0532e-02, -5.0237e-01],\n",
       "           ...,\n",
       "           [ 9.6161e-01, -1.5588e+00,  1.7929e+00,  ..., -2.2465e+00,\n",
       "             6.9707e-02,  4.0701e-01],\n",
       "           [ 4.2434e-01, -3.1178e-01,  2.8930e+00,  ...,  4.3731e-01,\n",
       "             1.2431e+00,  4.9446e-01],\n",
       "           [ 6.3628e-01,  6.1190e-01,  8.7109e-01,  ..., -3.0506e-01,\n",
       "            -5.7531e-01, -8.6655e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 5.4760e-02,  2.0254e+00,  2.1913e+00,  ..., -1.5383e-01,\n",
       "             1.3739e+00, -5.1837e-01],\n",
       "           [ 8.2962e-01,  9.5989e-01,  1.2102e-01,  ...,  6.5317e-02,\n",
       "             1.6878e-01, -2.8593e-01],\n",
       "           [ 1.1816e+00,  7.0863e-01,  1.3521e+00,  ..., -1.2320e+00,\n",
       "             1.2221e+00,  2.1519e+00],\n",
       "           ...,\n",
       "           [ 2.0075e-01,  9.9776e-01, -5.4577e-01,  ...,  1.1695e+00,\n",
       "             6.1799e-02, -1.3204e+00],\n",
       "           [ 7.0230e-01,  4.6826e-01,  9.0239e-01,  ..., -1.9301e+00,\n",
       "            -3.4434e+00,  1.0799e+00],\n",
       "           [ 1.1489e+00,  4.5823e-01,  1.3993e+00,  ..., -1.0223e+00,\n",
       "             9.0875e-01,  3.7596e-01]],\n",
       " \n",
       "          [[-2.5982e-01,  3.0835e-02,  9.8108e-01,  ...,  3.5721e-01,\n",
       "             6.4747e-01,  8.6030e-01],\n",
       "           [-7.4720e-02, -8.7398e-01,  8.2927e-01,  ...,  4.2943e-01,\n",
       "            -1.8971e+00,  6.5885e-01],\n",
       "           [-1.4111e+00,  1.4247e+00, -8.8484e-01,  ..., -1.1177e+00,\n",
       "             4.9867e-02,  1.2912e+00],\n",
       "           ...,\n",
       "           [-2.4945e+00, -9.2583e-01, -8.7156e-01,  ...,  3.2667e-01,\n",
       "            -1.0229e+00,  1.2384e-01],\n",
       "           [ 4.0537e-01,  6.5056e-01, -1.1712e+00,  ..., -1.9234e-01,\n",
       "             5.7693e-01, -1.3055e+00],\n",
       "           [ 1.4683e+00,  6.0911e-01,  6.9213e-02,  ..., -4.9003e-01,\n",
       "             8.7551e-01,  1.4128e+00]],\n",
       " \n",
       "          [[ 4.9336e-02,  3.2513e-01, -2.1092e+00,  ...,  4.4368e-02,\n",
       "             4.6824e-01, -1.4357e+00],\n",
       "           [ 3.5445e-01,  4.5326e-01, -6.5002e-01,  ..., -1.0255e-01,\n",
       "             7.2517e-02,  8.4627e-02],\n",
       "           [ 1.8497e-01,  6.7391e-01,  6.3602e-01,  ...,  1.0203e+00,\n",
       "            -8.5943e-01,  1.3827e+00],\n",
       "           ...,\n",
       "           [-1.8329e-01,  2.5678e-01,  1.0525e-01,  ..., -8.8151e-01,\n",
       "            -7.2904e-02, -4.5450e-01],\n",
       "           [-7.3417e-01, -2.8699e-01, -1.6644e+00,  ...,  1.0838e-01,\n",
       "            -9.9322e-01, -3.0194e-01],\n",
       "           [ 1.4183e+00, -3.7072e-01,  3.7215e-01,  ...,  6.6098e-01,\n",
       "            -1.7384e+00,  8.9371e-01]]],\n",
       " \n",
       " \n",
       "         [[[-4.0691e-01, -3.9787e-02, -1.0678e+00,  ...,  5.6343e-01,\n",
       "            -1.0948e+00, -2.6848e-01],\n",
       "           [-1.8496e-01,  6.4374e-02, -1.3988e+00,  ...,  1.6230e+00,\n",
       "             2.3708e-01,  1.1784e-01],\n",
       "           [-1.4482e+00, -5.6168e-02,  3.3751e-01,  ..., -1.6463e+00,\n",
       "             1.5944e+00, -8.6532e-01],\n",
       "           ...,\n",
       "           [ 9.6168e-01, -1.8438e-01,  2.8873e-01,  ..., -9.3260e-01,\n",
       "             1.6266e-01, -9.8682e-01],\n",
       "           [-1.2358e+00,  5.8622e-01,  4.7341e-01,  ...,  9.8208e-03,\n",
       "            -1.7803e+00, -3.2437e-01],\n",
       "           [-1.0061e+00, -1.2469e+00,  1.2527e-01,  ..., -1.1315e+00,\n",
       "             1.1222e+00,  1.9867e+00]],\n",
       " \n",
       "          [[ 1.0868e+00,  1.7941e+00, -5.5077e-01,  ..., -2.7969e-01,\n",
       "             1.5939e+00, -4.9422e-01],\n",
       "           [ 5.7613e-01, -2.2093e+00,  3.3188e-01,  ..., -8.9053e-02,\n",
       "             9.5665e-02, -2.0967e-01],\n",
       "           [-1.0753e+00,  8.7183e-01, -3.2989e-01,  ..., -1.0211e+00,\n",
       "            -7.1320e-01,  4.6596e-01],\n",
       "           ...,\n",
       "           [ 7.5388e-01,  8.4166e-01, -1.1547e+00,  ..., -8.1793e-02,\n",
       "            -3.2197e-01, -4.4783e-02],\n",
       "           [-4.8724e-01,  8.5591e-02,  2.5283e-01,  ...,  1.2457e+00,\n",
       "             1.7663e-01, -2.9602e-01],\n",
       "           [-9.9446e-01,  1.7219e-01, -8.2164e-01,  ..., -7.3438e-01,\n",
       "             3.0835e-01, -1.3275e+00]],\n",
       " \n",
       "          [[ 6.6247e-01,  7.3288e-01, -1.4993e+00,  ...,  5.3159e-01,\n",
       "            -6.6907e-01, -5.0791e-01],\n",
       "           [ 7.3098e-01, -2.6681e-01,  4.0713e-01,  ...,  5.9609e-01,\n",
       "            -5.8408e-01, -7.8328e-01],\n",
       "           [-1.2367e+00, -7.1606e-01, -1.3723e+00,  ..., -1.8558e+00,\n",
       "            -1.3604e+00,  4.0662e-01],\n",
       "           ...,\n",
       "           [-1.0768e+00,  4.7843e-02,  1.0769e+00,  ...,  4.9357e-01,\n",
       "            -1.4095e-01, -4.2737e-01],\n",
       "           [-7.8599e-01,  9.0630e-02,  6.0472e-01,  ..., -3.1577e-01,\n",
       "            -1.1983e+00,  6.8075e-01],\n",
       "           [ 9.7546e-02, -3.0884e-01,  5.2537e-01,  ...,  9.8851e-01,\n",
       "            -4.9305e-01, -4.9606e-01]]]], device='cuda:0'),\n",
       " 'x_reconstruction': tensor([[[[0.4960, 0.4704, 0.5211,  ..., 0.5076, 0.4721, 0.4934],\n",
       "           [0.4745, 0.5216, 0.4978,  ..., 0.5280, 0.5046, 0.4882],\n",
       "           [0.4780, 0.4460, 0.6307,  ..., 0.5391, 0.4749, 0.4671],\n",
       "           ...,\n",
       "           [0.4879, 0.5788, 0.5420,  ..., 0.5160, 0.4617, 0.5159],\n",
       "           [0.4766, 0.4601, 0.4756,  ..., 0.4807, 0.4861, 0.4946],\n",
       "           [0.4901, 0.5139, 0.5132,  ..., 0.4960, 0.4858, 0.5064]],\n",
       " \n",
       "          [[0.4920, 0.4724, 0.5069,  ..., 0.4765, 0.4844, 0.4873],\n",
       "           [0.4720, 0.4641, 0.6617,  ..., 0.5361, 0.4855, 0.4863],\n",
       "           [0.4547, 0.8143, 0.4492,  ..., 0.4947, 0.4452, 0.4829],\n",
       "           ...,\n",
       "           [0.4762, 0.4869, 0.5108,  ..., 0.4711, 0.4926, 0.4736],\n",
       "           [0.4806, 0.5323, 0.4931,  ..., 0.4764, 0.4795, 0.4847],\n",
       "           [0.4823, 0.4811, 0.4445,  ..., 0.4998, 0.4786, 0.4870]],\n",
       " \n",
       "          [[0.4877, 0.4529, 0.5021,  ..., 0.5090, 0.4804, 0.4856],\n",
       "           [0.4603, 0.5261, 0.7245,  ..., 0.5052, 0.4685, 0.4961],\n",
       "           [0.5009, 0.5569, 0.4640,  ..., 0.5172, 0.5590, 0.4592],\n",
       "           ...,\n",
       "           [0.5087, 0.5593, 0.4504,  ..., 0.5132, 0.4845, 0.4701],\n",
       "           [0.4903, 0.4717, 0.4836,  ..., 0.4960, 0.5071, 0.4879],\n",
       "           [0.4972, 0.5038, 0.4542,  ..., 0.4993, 0.4623, 0.4807]]],\n",
       " \n",
       " \n",
       "         [[[0.4850, 0.5098, 0.4861,  ..., 0.4869, 0.4968, 0.4919],\n",
       "           [0.4851, 0.4881, 0.5053,  ..., 0.5020, 0.5159, 0.4933],\n",
       "           [0.5022, 0.4419, 0.4341,  ..., 0.4723, 0.4860, 0.5521],\n",
       "           ...,\n",
       "           [0.4983, 0.5282, 0.5242,  ..., 0.4956, 0.4783, 0.4925],\n",
       "           [0.4836, 0.4771, 0.5244,  ..., 0.4817, 0.4899, 0.4783],\n",
       "           [0.4925, 0.5303, 0.4831,  ..., 0.4861, 0.4841, 0.4995]],\n",
       " \n",
       "          [[0.4859, 0.4878, 0.4889,  ..., 0.5044, 0.4914, 0.4934],\n",
       "           [0.4963, 0.4529, 0.6371,  ..., 0.4570, 0.5022, 0.4632],\n",
       "           [0.4819, 0.6632, 0.4372,  ..., 0.5409, 0.4940, 0.4707],\n",
       "           ...,\n",
       "           [0.4798, 0.4535, 0.4826,  ..., 0.4860, 0.4810, 0.4793],\n",
       "           [0.4877, 0.5063, 0.4631,  ..., 0.4905, 0.4734, 0.4922],\n",
       "           [0.4878, 0.4942, 0.4385,  ..., 0.4906, 0.4928, 0.4781]],\n",
       " \n",
       "          [[0.4816, 0.4836, 0.4483,  ..., 0.4974, 0.4880, 0.4829],\n",
       "           [0.4831, 0.4897, 0.4324,  ..., 0.4997, 0.5241, 0.5045],\n",
       "           [0.4676, 0.6391, 0.5933,  ..., 0.4976, 0.4627, 0.4480],\n",
       "           ...,\n",
       "           [0.4993, 0.5316, 0.4598,  ..., 0.4994, 0.4903, 0.4897],\n",
       "           [0.4852, 0.4568, 0.5016,  ..., 0.4863, 0.4956, 0.4787],\n",
       "           [0.4717, 0.4958, 0.4767,  ..., 0.4834, 0.4882, 0.4779]]],\n",
       " \n",
       " \n",
       "         [[[0.4817, 0.4854, 0.4527,  ..., 0.4911, 0.4885, 0.4989],\n",
       "           [0.5661, 0.6966, 0.5045,  ..., 0.4588, 0.5343, 0.5096],\n",
       "           [0.5313, 0.4389, 0.4565,  ..., 0.4604, 0.5027, 0.4954],\n",
       "           ...,\n",
       "           [0.4972, 0.5392, 0.5050,  ..., 0.5045, 0.4835, 0.4752],\n",
       "           [0.4753, 0.4586, 0.4937,  ..., 0.4801, 0.4846, 0.4771],\n",
       "           [0.5023, 0.4947, 0.4923,  ..., 0.4825, 0.4834, 0.4947]],\n",
       " \n",
       "          [[0.4969, 0.4638, 0.4957,  ..., 0.4837, 0.4934, 0.4918],\n",
       "           [0.4804, 0.5996, 0.5180,  ..., 0.4548, 0.4659, 0.5201],\n",
       "           [0.4794, 0.6179, 0.4312,  ..., 0.5240, 0.4482, 0.5351],\n",
       "           ...,\n",
       "           [0.4689, 0.4889, 0.4830,  ..., 0.5025, 0.4813, 0.5068],\n",
       "           [0.4914, 0.4892, 0.4982,  ..., 0.5250, 0.4848, 0.4962],\n",
       "           [0.4808, 0.5473, 0.4417,  ..., 0.4873, 0.4831, 0.4860]],\n",
       " \n",
       "          [[0.4911, 0.5224, 0.4857,  ..., 0.4797, 0.4943, 0.4950],\n",
       "           [0.4639, 0.8514, 0.5259,  ..., 0.4841, 0.4519, 0.4739],\n",
       "           [0.4565, 0.5764, 0.5123,  ..., 0.4589, 0.4868, 0.4720],\n",
       "           ...,\n",
       "           [0.4945, 0.5290, 0.4338,  ..., 0.4833, 0.4743, 0.4753],\n",
       "           [0.4941, 0.4748, 0.5239,  ..., 0.4793, 0.4916, 0.4896],\n",
       "           [0.4899, 0.4714, 0.4451,  ..., 0.4758, 0.4755, 0.4874]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[0.4899, 0.4922, 0.4580,  ..., 0.4983, 0.4843, 0.5189],\n",
       "           [0.4524, 0.4848, 0.5023,  ..., 0.4413, 0.4948, 0.5043],\n",
       "           [0.5141, 0.4344, 0.4444,  ..., 0.4660, 0.4854, 0.5196],\n",
       "           ...,\n",
       "           [0.4839, 0.4663, 0.5573,  ..., 0.4830, 0.4663, 0.5064],\n",
       "           [0.4944, 0.4747, 0.5039,  ..., 0.4889, 0.4795, 0.4941],\n",
       "           [0.5012, 0.5068, 0.4900,  ..., 0.5311, 0.4687, 0.4890]],\n",
       " \n",
       "          [[0.4930, 0.4729, 0.4767,  ..., 0.4781, 0.4908, 0.4911],\n",
       "           [0.4869, 0.6081, 0.5406,  ..., 0.4790, 0.4833, 0.4717],\n",
       "           [0.4808, 0.8359, 0.4319,  ..., 0.4792, 0.4898, 0.5502],\n",
       "           ...,\n",
       "           [0.4639, 0.4536, 0.5248,  ..., 0.4633, 0.4762, 0.4871],\n",
       "           [0.5026, 0.5322, 0.4846,  ..., 0.4906, 0.4680, 0.5179],\n",
       "           [0.4986, 0.4989, 0.4414,  ..., 0.4980, 0.4832, 0.4895]],\n",
       " \n",
       "          [[0.4745, 0.4666, 0.5270,  ..., 0.4883, 0.4847, 0.4862],\n",
       "           [0.4924, 0.5771, 0.4816,  ..., 0.4695, 0.4860, 0.4852],\n",
       "           [0.4540, 0.6447, 0.4679,  ..., 0.5385, 0.4647, 0.4935],\n",
       "           ...,\n",
       "           [0.4652, 0.5419, 0.4521,  ..., 0.4939, 0.5022, 0.4867],\n",
       "           [0.4967, 0.4611, 0.4847,  ..., 0.4870, 0.4773, 0.4883],\n",
       "           [0.4776, 0.4878, 0.4991,  ..., 0.4727, 0.4692, 0.4949]]],\n",
       " \n",
       " \n",
       "         [[[0.4767, 0.5081, 0.4785,  ..., 0.4945, 0.4807, 0.4941],\n",
       "           [0.4837, 0.4310, 0.4462,  ..., 0.5459, 0.5531, 0.4781],\n",
       "           [0.4477, 0.4412, 0.4785,  ..., 0.4500, 0.4722, 0.4762],\n",
       "           ...,\n",
       "           [0.4935, 0.4612, 0.5114,  ..., 0.4908, 0.4869, 0.4863],\n",
       "           [0.4839, 0.4510, 0.4539,  ..., 0.4889, 0.4822, 0.4846],\n",
       "           [0.4997, 0.5175, 0.4972,  ..., 0.4819, 0.4845, 0.4798]],\n",
       " \n",
       "          [[0.4827, 0.4969, 0.5350,  ..., 0.4876, 0.5046, 0.4828],\n",
       "           [0.5812, 0.6812, 0.7478,  ..., 0.4452, 0.4906, 0.4588],\n",
       "           [0.4870, 0.9028, 0.4308,  ..., 0.4858, 0.4581, 0.4706],\n",
       "           ...,\n",
       "           [0.4807, 0.4752, 0.6161,  ..., 0.4893, 0.4639, 0.5051],\n",
       "           [0.4803, 0.5328, 0.5127,  ..., 0.4738, 0.4954, 0.4981],\n",
       "           [0.4966, 0.4996, 0.4551,  ..., 0.4806, 0.5146, 0.4843]],\n",
       " \n",
       "          [[0.4818, 0.4590, 0.4454,  ..., 0.4863, 0.4765, 0.4871],\n",
       "           [0.4453, 0.6300, 0.4309,  ..., 0.5911, 0.4605, 0.4807],\n",
       "           [0.4652, 0.4348, 0.4320,  ..., 0.5445, 0.5381, 0.4814],\n",
       "           ...,\n",
       "           [0.4599, 0.4943, 0.4502,  ..., 0.4830, 0.4766, 0.4699],\n",
       "           [0.4822, 0.4993, 0.4657,  ..., 0.4849, 0.5030, 0.4968],\n",
       "           [0.5012, 0.4867, 0.4673,  ..., 0.4974, 0.4733, 0.4928]]],\n",
       " \n",
       " \n",
       "         [[[0.4796, 0.4980, 0.4586,  ..., 0.4947, 0.4864, 0.4842],\n",
       "           [0.4940, 0.6611, 0.4326,  ..., 0.4757, 0.4961, 0.4984],\n",
       "           [0.5249, 0.4840, 0.4865,  ..., 0.4743, 0.4709, 0.4852],\n",
       "           ...,\n",
       "           [0.5133, 0.4584, 0.4739,  ..., 0.4691, 0.4618, 0.4827],\n",
       "           [0.4923, 0.4604, 0.5299,  ..., 0.4804, 0.4784, 0.4763],\n",
       "           [0.4962, 0.4942, 0.4928,  ..., 0.5095, 0.4824, 0.4846]],\n",
       " \n",
       "          [[0.4964, 0.4636, 0.5005,  ..., 0.4683, 0.4861, 0.4797],\n",
       "           [0.4696, 0.4344, 0.6004,  ..., 0.5062, 0.4598, 0.5017],\n",
       "           [0.5150, 0.8088, 0.4527,  ..., 0.5227, 0.4801, 0.5045],\n",
       "           ...,\n",
       "           [0.4861, 0.4712, 0.5264,  ..., 0.4739, 0.4891, 0.4966],\n",
       "           [0.4865, 0.5085, 0.5116,  ..., 0.5140, 0.4887, 0.5007],\n",
       "           [0.4885, 0.4790, 0.4662,  ..., 0.4922, 0.4898, 0.4780]],\n",
       " \n",
       "          [[0.4834, 0.4832, 0.4659,  ..., 0.4956, 0.4943, 0.4890],\n",
       "           [0.4935, 0.5089, 0.4389,  ..., 0.4873, 0.4821, 0.4719],\n",
       "           [0.4595, 0.5894, 0.5817,  ..., 0.4846, 0.4653, 0.4812],\n",
       "           ...,\n",
       "           [0.5046, 0.4749, 0.4633,  ..., 0.4814, 0.4648, 0.4787],\n",
       "           [0.5061, 0.4629, 0.4575,  ..., 0.5220, 0.4876, 0.4857],\n",
       "           [0.4811, 0.5328, 0.4778,  ..., 0.4831, 0.4827, 0.4835]]]],\n",
       "        device='cuda:0', grad_fn=<SigmoidBackward0>)}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_dict = rssm.pre_step(x=x)\n",
    "step_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e7896396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True,  True,  ...,  True,  True,  True],\n",
       "        [ True,  True,  True,  ...,  True,  True,  True],\n",
       "        [ True,  True,  True,  ...,  True,  True,  True],\n",
       "        [ True,  True,  True,  ...,  True, False,  True],\n",
       "        [ True,  True,  True,  ...,  True,  True,  True]], device='cuda:0')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_dict[\"z_pred\"] == step_dict[\"z\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5169db30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3816c365",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "fbaff2c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 512])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = torch.zeros(batch_size, H)\n",
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "946bd69e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PPO(\n",
    "policy=\"MlpPolicy\",\n",
    "env=imagination_env,\n",
    "verbose=verbose,\n",
    "tensorboard_log=log_dir,\n",
    "gamma=gamma,\n",
    "gae_lambda=lam,\n",
    "ent_coef=ent_coef).predict(state, deterministic=False)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd303c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c04d9e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "edb66562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 512])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb7823a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cd5d62a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Tensors must have same number of dimensions: got 2 and 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [47], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfloat()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Tensors must have same number of dimensions: got 2 and 3"
     ]
    }
   ],
   "source": [
    "torch.cat((action.unsqueeze(0), h, z), 1).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f2c14715",
   "metadata": {},
   "outputs": [],
   "source": [
    "CategoricalStraightThrough.forward?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a3a48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "# - training loop\n",
    "# except KeyboardInterrupt:\n",
    "#     \"\"\" Clean handling for interrupts to stop training early \"\"\"\n",
    "#     print(\"Stopping training.\")\n",
    "#     # Delete the last loss if the training was stopped early\n",
    "#     # so that the list only consists of floats\n",
    "#     for key in episode_losses:\n",
    "#         if isinstance(episode_losses[key][-1], torch.Tensor):\n",
    "#             episode_losses[key] = episode_losses[key][:-1]\n",
    "# \n",
    "#     # Close the TensorBoard writer and the gym environment\n",
    "#     writer.close()\n",
    "#     env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ad0c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#            # save the rssm and agent\n",
    "#            rssm.save_weights(filename=f\"RSSM_{best_running_loss:.8f}\")\n",
    "#            agent.save(f\"weights/{agent.__class__.__name__}_agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d96d812",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a2fb86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42fb0f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7ebb9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90979190",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ea7a23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82409e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55e74d14",
   "metadata": {},
   "source": [
    "## Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0703ff02",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results = False\n",
    "\n",
    "if plot_results:\n",
    "    rolling_length = max(1, int(len(episode_losses[\"episode_loss\"])/20))\n",
    "\n",
    "    fig, axs = plt.subplots(ncols=3, nrows=2, figsize=(3*5, 2*5))\n",
    "\n",
    "    # Iterate over the keys and plot the losses\n",
    "    for i, key in enumerate(episode_losses.keys()):\n",
    "        row = i // 3\n",
    "        col = i % 3\n",
    "\n",
    "        axs[row, col].set_title(key)\n",
    "        losses = episode_losses[key]\n",
    "        losses_moving_average = (\n",
    "            np.convolve(\n",
    "                np.array(losses).flatten(), np.ones(rolling_length), mode=\"valid\"\n",
    "            )\n",
    "            / rolling_length\n",
    "        )\n",
    "        axs[row, col].plot(range(len(losses)), losses, label=key)\n",
    "        axs[row, col].plot(range(len(losses_moving_average)), losses_moving_average, label=\"moving average\")\n",
    "        axs[row, col].legend(loc=\"upper right\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d0fd15",
   "metadata": {},
   "source": [
    "## Showcase the trained agent playing in latent imagination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f62546",
   "metadata": {},
   "outputs": [],
   "source": [
    "showcase_agent = False\n",
    "\n",
    "if showcase_agent:\n",
    "    \n",
    "    showcase_rewards = []\n",
    "    imagination_env.render_mode = \"gif\"\n",
    "    obs, info = imagination_env.reset()\n",
    "    \n",
    "    for i in range(500):\n",
    "        \n",
    "        # apply the RL agent in eval mode to get an action\n",
    "        state = to_np(torch.cat((h.flatten().detach(), z.flatten().detach()), dim=0))\n",
    "        action, _ = agent.predict(state, deterministic=False)\n",
    "        # action = imagination_env.action_space.sample()\n",
    "        \n",
    "        obs, reward, terminated, truncated, info = imagination_env.step(action)\n",
    "        showcase_rewards.append(reward)\n",
    "        imagination_env.render()\n",
    "        \n",
    "        if terminated or truncated:\n",
    "            break\n",
    "        \n",
    "    imagination_env.close()\n",
    "    imagination_env.render_mode = None\n",
    "\n",
    "    plt.plot(showcase_rewards)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e073982",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3354e868",
   "metadata": {},
   "source": [
    "## Test area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cb6387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tensorboard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35914cfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f70fa43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bdcc84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
