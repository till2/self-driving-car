{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b1c5dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from collections import deque\n",
    "from operator import itemgetter\n",
    "\n",
    "import gym_donkeycar\n",
    "import gymnasium as gym\n",
    "import imageio\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from IPython.display import display\n",
    "from ipywidgets import HBox, VBox\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from ruamel.yaml import YAML\n",
    "from tensorboard import notebook\n",
    "from tensorboard.backend.event_processing.event_accumulator import \\\n",
    "    EventAccumulator\n",
    "from torch import distributions as dist\n",
    "from torch.distributions import Categorical, Normal\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "# suppress warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ[\"IMAGEIO_IGNORE_WARNINGS\"] = \"True\"\n",
    "\n",
    "import gym.spaces as gym_spaces\n",
    "import gymnasium as gym  # overwrite OpenAI gym\n",
    "import stable_baselines3 as sb3\n",
    "from gym_donkeycar.envs.donkey_env import DonkeyEnv\n",
    "from gymnasium import spaces\n",
    "from gymnasium.spaces import Box\n",
    "from src.actor_critic import ContinuousActorCritic\n",
    "from src.blocks import CategoricalStraightThrough, ConvBlock\n",
    "from src.categorical_vae import CategoricalVAE\n",
    "from src.imagination_env import ImaginationEnv\n",
    "from src.mlp import MLP\n",
    "from src.preprocessing import grayscale_transform as transform\n",
    "from src.replay_buffer import ReplayBuffer\n",
    "from src.rssm import RSSM\n",
    "from src.utils import load_config, save_image_and_reconstruction, to_np\n",
    "from stable_baselines3 import A2C, PPO, SAC\n",
    "from stable_baselines3.common import env_checker\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.results_plotter import load_results, ts2xy\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7cd6cd",
   "metadata": {},
   "source": [
    "## Load Hyperparameters from YAML config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee8b1846",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'device': device(type='cuda', index=0), 'A': 2, 'Z': 1024, 'debug': False, 'log_dir': 'logs/', 'seed': 0, 'toy_env': False, 'exe_path': '/home/till/Desktop/Thesis/donkeycar_sim/DonkeySimLinux/donkey_sim.x86_64', 'env_id': 'donkey-minimonaco-track-v0', 'port': 9091, 'size': [128, 128], 'grayscale': False, 'n_envs': 1, 'n_episodes': 5000, 'max_episode_steps': 2000, 'max_imagination_episode_steps': 50, 'imagination_timesteps_per_model_update': 100, 'max_grad_norm': 1, 'rssm_lr': 0.0001, 'rssm_l2_regularization': 1e-06, 'batch_size': 1, 'H': 512, 'uniform_ratio': 0.01, 'buffer_size': 10000, 'activation': 'silu', 'num_categoricals': 32, 'num_classes': 32, 'channels': [32, 64, 128, 256, 256, 256], 'kernel_size': 3, 'stride': 2, 'padding': 1, 'conv_bias': False, 'entropyloss_coeff': 0.0, 'decoder_final_activation': 'sigmoid', 'pred_loss_coeff': 1.0, 'dyn_loss_coeff': 0.5, 'rep_loss_coeff': 0.1, 'free_nats': 1.0, 'num_rnn_layers': 1, 'mlp_n_layers': 3, 'mlp_hidden_dims': 256, 'store_on_cpu': True, 'gamma': 0.999, 'lam': 0.95, 'entropy_coeff': 0.01, 'critic_lr': 0.005, 'actor_lr': 0.001, 'verbose': 0, 'imagination_progress_bar': False, 'action_clip': 0.5}\n"
     ]
    }
   ],
   "source": [
    "config = load_config()\n",
    "\n",
    "for key in config:\n",
    "    locals()[key] = config[key]\n",
    "\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239558a5",
   "metadata": {},
   "source": [
    "## Init the RSSM (including all networks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cda9f099",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing encoder:\n",
      "- adding ConvBlock((3, 32))                   ==> output shape: (32, 64, 64) ==> prod: 131072\n",
      "- adding ConvBlock((32, 64))                   ==> output shape: (64, 32, 32) ==> prod: 65536\n",
      "- adding ConvBlock((64, 128))                   ==> output shape: (128, 16, 16) ==> prod: 32768\n",
      "- adding ConvBlock((128, 256))                   ==> output shape: (256, 8, 8) ==> prod: 16384\n",
      "- adding ConvBlock((256, 256))                   ==> output shape: (256, 4, 4) ==> prod: 4096\n",
      "- adding ConvBlock((256, 256))                   ==> output shape: (256, 2, 2) ==> prod: 1024\n",
      "- adding Flatten()\n",
      "- adding Reshape: (*,1024) => (*,32,32)\n",
      "\n",
      "Initializing decoder:\n",
      "- adding Reshape: (*,1024) => (*,256,2,2)\n",
      "- adding transpose ConvBlock(256, 256)                   ==> output shape: (256, 4, 4) ==> prod: 4096\n",
      "- adding transpose ConvBlock(256, 256)                   ==> output shape: (256, 8, 8) ==> prod: 16384\n",
      "- adding transpose ConvBlock(256, 256)                   ==> output shape: (256, 16, 16) ==> prod: 65536\n",
      "- adding transpose ConvBlock(256, 128)                   ==> output shape: (128, 32, 32) ==> prod: 131072\n",
      "- adding transpose ConvBlock(128, 64)                   ==> output shape: (64, 64, 64) ==> prod: 262144\n",
      "- adding transpose ConvBlock(64, 3)                   ==> output shape: (3, 128, 128) ==> prod: 49152\n"
     ]
    }
   ],
   "source": [
    "rssm = RSSM().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229f8133",
   "metadata": {},
   "source": [
    "## Create the imagination environment for training the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9a08c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = ReplayBuffer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d2d9fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagination_env = ImaginationEnv(\n",
    "    rssm,\n",
    "    replay_buffer,\n",
    "    render_mode=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a93b68d",
   "metadata": {},
   "source": [
    "## Init the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe1ee1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = A2C(\n",
    "    \"MlpPolicy\",\n",
    "    imagination_env,\n",
    "    verbose,\n",
    "    tensorboard_log=log_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c5b386",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0be431",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27fa0c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "856cb39a",
   "metadata": {},
   "source": [
    "## Training loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd076d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting DonkeyGym env\n",
      "Setting default: start_delay 5.0\n",
      "Setting default: max_cte 8.0\n",
      "Setting default: frame_skip 1\n",
      "Setting default: cam_resolution (120, 160, 3)\n",
      "Setting default: log_level 20\n",
      "Setting default: host localhost\n",
      "Setting default: steer_limit 1.0\n",
      "Setting default: throttle_min 0.0\n",
      "Setting default: throttle_max 1.0\n",
      "donkey subprocess started\n",
      "Found path: /home/till/Desktop/Thesis/donkeycar_sim/DonkeySimLinux/donkey_sim.x86_64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym_donkeycar.core.client:connecting to localhost:9091 \n",
      "/home/till/.local/lib/python3.10/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n",
      "WARNING:gym_donkeycar.envs.donkey_sim:waiting for sim to start..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading scene mini_monaco\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym_donkeycar.envs.donkey_sim:on need car config\n",
      "INFO:gym_donkeycar.envs.donkey_sim:sending car config.\n",
      "INFO:gym_donkeycar.envs.donkey_sim:sim started!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-9764d5bba2c7e861\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-9764d5bba2c7e861\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                  | 0/5000 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "\"\"\" training loop \"\"\"\n",
    "\n",
    "rssm.train()\n",
    "\n",
    "# Create the environment\n",
    "if toy_env:\n",
    "    assert A==3\n",
    "    env = gym.make(\"CarRacing-v2\", max_episode_steps=max_episode_steps, render_mode=\"rgb_array\")\n",
    "else:\n",
    "    assert A==2\n",
    "    sim_config = {\n",
    "        \"exe_path\" : config[\"exe_path\"],\n",
    "        \"port\" : config[\"port\"]\n",
    "    }\n",
    "    env = gym.make(\n",
    "        \"GymV21Environment-v0\", \n",
    "        env_id=env_id,\n",
    "        max_episode_steps=max_episode_steps,\n",
    "        make_kwargs={\n",
    "            \"conf\": sim_config\n",
    "        })\n",
    "\n",
    "# Logging\n",
    "writer = SummaryWriter(log_dir)\n",
    "notebook.start(f\"--logdir={log_dir}\")\n",
    "\n",
    "episode_losses = { # for loss plots\n",
    "    \"episode_loss\": [],\n",
    "    \"episode_image_loss\": [],\n",
    "    \"episode_reward_loss\": [],\n",
    "    \"episode_continue_loss\": [],\n",
    "    \"episode_dyn_loss\": [],\n",
    "    \"episode_rep_loss\": [],\n",
    "}\n",
    "\n",
    "try:\n",
    "    for episode in tqdm(range(n_episodes)):\n",
    "\n",
    "        # Get the initial state\n",
    "        obs, info = env.reset()\n",
    "\n",
    "        # Reset the RNN's hidden state\n",
    "        h = torch.zeros(rssm.num_rnn_layers, 1, H, device=device) # seq_len, B, H\n",
    "\n",
    "        # Add a new loss for the current episode and initialize it to 0\n",
    "        episode_length = 0\n",
    "        for key in episode_losses:\n",
    "            episode_losses[key].append(torch.tensor(0, device=device, dtype=torch.float32))\n",
    "\n",
    "        # Play one episode\n",
    "        done = False\n",
    "        while not done:\n",
    "\n",
    "            # preprocess the observation and add it to the replay buffer\n",
    "            x = transform(obs).view(-1, 1 if grayscale else 3, *size) # (B, 3, 128, 128)\n",
    "            replay_buffer.push(x)\n",
    "\n",
    "            \"\"\" WORLD MODEL LEARNING \"\"\"\n",
    "\n",
    "            # predict z and generate the true stochastic latent variable z with the encoder\n",
    "            z_prior = rssm.dynamics_mlp(h).view(-1, num_categoricals, num_classes) # (1,32,32) for the softmax\n",
    "            z_prior = F.softmax(z_prior, -1).flatten(start_dim=1, end_dim=2) # (1, 1024)\n",
    "            z = rssm.vae.encode(x).flatten(start_dim=1, end_dim=2)\n",
    "            \n",
    "            # apply the RL agent in eval mode to get an action\n",
    "            state = to_np(torch.cat((h.flatten().detach(), z.flatten().detach()), dim=0))\n",
    "            action, _ = agent.predict(state, deterministic=True)\n",
    "\n",
    "            # predict one step using the RSSM\n",
    "            h, reward_pred, continue_prob, continue_pred, x_pred = rssm.step(action, h, z)\n",
    "\n",
    "            # take an environment step with the action\n",
    "            obs, reward, terminated, truncated, info = env.step(action.squeeze())\n",
    "            done = terminated or truncated\n",
    "\n",
    "            # calculate the loss\n",
    "            continue_target = torch.tensor(1 - done, device=device, dtype=torch.float32)\n",
    "            reward = torch.tensor(reward, device=device, dtype=torch.float32)\n",
    "            losses = rssm.get_losses(x, x_pred, reward, reward_pred, \n",
    "                                     continue_target, continue_prob, z_prior, z)\n",
    "\n",
    "            # Add the loss for the current step to the episode loss\n",
    "            episode_length += 1\n",
    "            for key in losses:\n",
    "                episode_losses[\"episode_\" + key][-1] += losses[key]\n",
    "\n",
    "        # Calculate the mean loss of the episode\n",
    "        for key in episode_losses:\n",
    "            episode_losses[key][-1] /= episode_length\n",
    "\n",
    "        # update the world model at the end of an episode using the mean loss of the episode\n",
    "        rssm.optim.zero_grad()\n",
    "        episode_losses[\"episode_loss\"][-1].backward()\n",
    "        nn.utils.clip_grad_norm_(rssm.vae.parameters(), max_norm=max_grad_norm, norm_type=2)  \n",
    "        rssm.optim.step()\n",
    "\n",
    "        # Detach the losses to save memory and log them in TensorBoard\n",
    "        for key in episode_losses:\n",
    "            episode_losses[key][-1] = episode_losses[key][-1].detach().item()\n",
    "            writer.add_scalar(key, episode_losses[key][-1], global_step=episode)\n",
    "        \n",
    "        # save original image and reconstruction\n",
    "        if episode % 10 == 0:\n",
    "            save_image_and_reconstruction(x, x_pred, episode)\n",
    "        \n",
    "        \"\"\" RL AGENT LEARNING (IN THE WORLD MODEL) \"\"\"\n",
    "        agent.learn(\n",
    "            total_timesteps=imagination_timesteps_per_model_update,\n",
    "            progress_bar=imagination_progress_bar,\n",
    "            reset_num_timesteps=False\n",
    "        )\n",
    "\n",
    "    env.close()\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    \"\"\" Clean handling for interrupts to stop training early \"\"\"\n",
    "    print(\"Stopping training.\")\n",
    "    # Delete the last loss if the training was stopped early\n",
    "    # so that the list only consists of floats\n",
    "    for key in episode_losses:\n",
    "        if isinstance(episode_losses[key][-1], torch.Tensor):\n",
    "            episode_losses[key] = episode_losses[key][:-1]\n",
    "\n",
    "    # Close the TensorBoard writer and the gym environment\n",
    "    writer.close()\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e74d14",
   "metadata": {},
   "source": [
    "## Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0703ff02",
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_length = max(1, int(len(episode_losses[\"episode_loss\"])/20))\n",
    "\n",
    "fig, axs = plt.subplots(ncols=3, nrows=2, figsize=(3*5, 2*5))\n",
    "\n",
    "# Iterate over the keys and plot the losses\n",
    "for i, key in enumerate(episode_losses.keys()):\n",
    "    row = i // 3\n",
    "    col = i % 3\n",
    "\n",
    "    axs[row, col].set_title(key)\n",
    "    losses = episode_losses[key]\n",
    "    losses_moving_average = (\n",
    "        np.convolve(\n",
    "            np.array(losses).flatten(), np.ones(rolling_length), mode=\"valid\"\n",
    "        )\n",
    "        / rolling_length\n",
    "    )\n",
    "    axs[row, col].plot(range(len(losses)), losses, label=key)\n",
    "    axs[row, col].plot(range(len(losses_moving_average)), losses_moving_average, label=\"moving average\")\n",
    "    axs[row, col].legend(loc=\"upper right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d0fd15",
   "metadata": {},
   "source": [
    "## Showcase the trained agent playing in latent imagination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f62546",
   "metadata": {},
   "outputs": [],
   "source": [
    "showcase_agent = True\n",
    "\n",
    "if showcase_agent:\n",
    "    \n",
    "    imagination_env.render_mode = \"gif\"\n",
    "    obs, info = imagination_env.reset()\n",
    "    \n",
    "    for i in range(max_episode_steps):\n",
    "        \n",
    "        # apply the RL agent in eval mode to get an action\n",
    "        state = to_np(torch.cat((h.flatten().detach(), z.flatten().detach()), dim=0))\n",
    "        action, _ = agent.predict(state, deterministic=True)\n",
    "        \n",
    "        obs, reward, terminated, truncated, info = imagination_env.step(action)\n",
    "        imagination_env.render()\n",
    "        \n",
    "    imagination_env.close()\n",
    "    imagination_env.render_mode = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e073982",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87499c46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bce2d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b6c00a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff03aca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3354e868",
   "metadata": {},
   "source": [
    "## Test area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f6ffa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU memory consumption:\n",
    "# 10 steps -> 6504MiB\n",
    "# 50 steps -> 19990MiB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71f928a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6952d981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tensorboard --logdir=log_dir"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
