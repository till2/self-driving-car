{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b1c5dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import gym_donkeycar\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import HBox, VBox\n",
    "from IPython.display import display\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Normal, Categorical\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "# custom classes and functions\n",
    "import models\n",
    "from models.blocks import ConvBlock, TransposeConvBlock, ResConvBlock, CategoricalStraightThrough\n",
    "from models.mlp import MLP\n",
    "from models.autoencoder import Autoencoder\n",
    "from models.vae import VAE\n",
    "from models.categorical_vae import CategoricalVAE\n",
    "from models.sequential_categorical_vae import SeqCatVAE\n",
    "from preprocessing import grayscale_transform as transform\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa538bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d781d3",
   "metadata": {},
   "source": [
    "## Set Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8c78302",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "A = 3 # number of action dimensions (3 for toy, 2 for real sim)\n",
    "H = 512 # discrete h state \n",
    "Z = 32*32 # stochastic Zx1 state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239558a5",
   "metadata": {},
   "source": [
    "## RSSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0674a6a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2af80d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c5aaf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RSSM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RSSM, self).__init__()\n",
    "        \n",
    "        # init the VAE\n",
    "        self.vae = SeqCatVAE(H, Z, grayscale=True, vae_ent_coeff=1e-8)\n",
    "        \n",
    "        # init the RNN\n",
    "        self.num_rnn_layers = 1\n",
    "        self.rnn = nn.GRU(input_size=A+H+Z, hidden_size=H, num_layers=self.num_rnn_layers)\n",
    "        \n",
    "        # init MLPs\n",
    "        self.dynamics_mlp = MLP(input_dims=H, output_dims=Z) # H -> Z\n",
    "        self.reward_mlp = MLP(input_dims=H+Z, output_dims=1) # state (H+Z) -> 1\n",
    "        self.continue_mlp = MLP(input_dims=H+Z, output_dims=1) # state (H+Z)->1 # add sigmoid and BinaryCE  \n",
    "    \n",
    "    def step(self, action, h, z):\n",
    "\n",
    "        # concatenate the rnn_input and apply RNN to obtain the next hidden state\n",
    "        rnn_input = torch.cat((action, h.view(-1, H), z), 1)\n",
    "        _, h = self.rnn(rnn_input, h.view(-1, H))\n",
    "        \n",
    "        state = torch.cat((h.view(-1, H), z), 1)\n",
    "        \n",
    "        # predict the reward and continue flag\n",
    "        reward_pred = rssm.reward_mlp(state)\n",
    "        continue_pred = rssm.continue_mlp(state) # binary classification\n",
    "        \n",
    "        # TODO:\n",
    "        x_reconstruction = rssm.vae.decode(h, z)\n",
    "        \n",
    "        return h, reward_pred, continue_pred\n",
    "    \n",
    "    # def info(self):\n",
    "    # - look at VAE.info() \n",
    "    \n",
    "    # def print_num_params(self):\n",
    "    #     print(f\"RSSM ==> number of parameters: {sum(p.numel() for p in rssm.parameters() if p.requires_grad):_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cda9f099",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rssm = RSSM().to(device)\n",
    "\n",
    "rssm_optim = optim.Adam(\n",
    "    rssm.parameters(), \n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-5 # l2 regularization\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c0594c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_net = MLP(input_dims=Z, output_dims=1).to(device) # state (H+Z) -> 1\n",
    "policy_net = MLP(input_dims=Z, output_dims=A).to(device) # state (H+Z) -> A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856cb39a",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1cd076d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [15], line 76\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# predict z and generate the true stochastic latent variable z with the encoder\u001b[39;00m\n\u001b[1;32m     75\u001b[0m z_pred \u001b[38;5;241m=\u001b[39m rssm\u001b[38;5;241m.\u001b[39mdynamics_mlp(h)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, Z) \u001b[38;5;66;03m# B,1024 (flattened)\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[43mrssm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvae\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, Z) \u001b[38;5;66;03m# TODO: use h,x\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# apply external actor and critic nets on z\u001b[39;00m\n\u001b[1;32m     79\u001b[0m action \u001b[38;5;241m=\u001b[39m policy_net(z) \u001b[38;5;66;03m# a is a 2x1 vector\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/GitHub/self-driving-car/models/sequential_categorical_vae.py:90\u001b[0m, in \u001b[0;36mSeqCatVAE.encode\u001b[0;34m(self, h, x)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode\u001b[39m(\u001b[38;5;28mself\u001b[39m, h, x):\n\u001b[0;32m---> 90\u001b[0m     h_and_x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((h\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mH), \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m16\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m8\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m8\u001b[39m)), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     91\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder_mlp(h_and_x)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m32\u001b[39m)\n\u001b[1;32m     92\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategorical(logits)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/GitHub/self-driving-car/models/blocks.py:23\u001b[0m, in \u001b[0;36mConvBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 23\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[1;32m     25\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn(x)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py:457\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py:453\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    450\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    451\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    452\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\" vae training loop \"\"\"\n",
    "\n",
    "# create the environment\n",
    "toy_env = True\n",
    "\n",
    "if toy_env:\n",
    "    assert A==3\n",
    "    env = gym.make(\"CarRacing-v2\", max_episode_steps=400, render_mode=\"human\") # rgb_array/human\n",
    "else:\n",
    "    assert A==2\n",
    "    exe_path = \"/home/till/Desktop/Thesis/donkeycar_sim/DonkeySimLinux/donkey_sim.x86_64\"\n",
    "    port = 9091\n",
    "    config = {\n",
    "        \"exe_path\" : exe_path, \n",
    "        \"port\" : port \n",
    "    }\n",
    "    env = gym.make(\n",
    "        \"GymV21Environment-v0\", \n",
    "        env_id=\"donkey-minimonaco-track-v0\", # donkey-warehouse-v0 \n",
    "        make_kwargs={\n",
    "            \"conf\": config\n",
    "        })\n",
    "\n",
    "verbose = True\n",
    "n_episodes = 100\n",
    "vae_losses, reconstruction_losses, entropy_losses = [], [], []\n",
    "rssm.train()\n",
    "\n",
    "for episode in range(n_episodes): # tqdm\n",
    "    \n",
    "    # get the initial state\n",
    "    obs, info = env.reset()\n",
    "    \n",
    "    # reset the rnn's hidden state\n",
    "    h = torch.zeros(rssm.num_rnn_layers, 1, H, device=device) # seq_len, B, H\n",
    "    \n",
    "    # setup a minibatch of x's for training the autoencoder\n",
    "    batch_counter = 0\n",
    "    batch_tensor = torch.empty((batch_size,) + transform(obs).shape, device=device) # B,C,H,W\n",
    "    \n",
    "    # play one episode\n",
    "    done = False\n",
    "    while not done:\n",
    "             \n",
    "        # add the new x to the batch\n",
    "        x = transform(obs).view(-1, 1, 128, 128)\n",
    "        # batch_tensor[batch_counter] = transform(obs)\n",
    "        # batch_counter += 1\n",
    "        \n",
    "        \n",
    "        # TODO: h_tensor batch speichern\n",
    "        \n",
    "        # \"\"\" train networks on accumulated batch \"\"\"\n",
    "        # if batch_counter % batch_size == 0:\n",
    "        #     # reset the batch counter\n",
    "        #     batch_counter = 0\n",
    "        #     \n",
    "        #     # autoencoder forward pass with a minibatch\n",
    "        #     xhat = rssm.vae(batch_tensor) # TODO: hier brauchen wir die h_tensor batch\n",
    "        # \n",
    "        #     # get a loss and update the autoencoder\n",
    "        #     vae_loss, reconstruction_loss, weighted_entropy_loss = rssm.vae.get_loss(batch_tensor, xhat)\n",
    "        #     rssm_optim.zero_grad()\n",
    "        #     vae_loss.backward()\n",
    "        #     rssm_optim.step()\n",
    "        #     \n",
    "        #     vae_losses.append(vae_loss.item())\n",
    "        #     reconstruction_losses.append(reconstruction_loss.item())\n",
    "        #     entropy_losses.append(weighted_entropy_loss.item())\n",
    "        \n",
    "        \n",
    "        \"\"\" WORLD MODEL LEARNING \"\"\"\n",
    "        \n",
    "        # predict z and generate the true stochastic latent variable z with the encoder\n",
    "        z_pred = rssm.dynamics_mlp(h).view(-1, Z) # B,1024 (flattened)\n",
    "        z = rssm.vae.encode(h, x).view(-1, Z) # TODO: use h,x\n",
    "        \n",
    "        # apply external actor and critic nets on z\n",
    "        action = policy_net(z) # a is a 2x1 vector\n",
    "        v = value_net(z)\n",
    "        \n",
    "        # predict one step using the RSSM and apply the actor-critic\n",
    "        h, reward_pred, continue_pred = rssm.step(action, h, z)\n",
    "        \n",
    "        # choose and execute an action\n",
    "        next_obs, reward, terminated, truncated, info = env.step(action.squeeze().detach().cpu().numpy())        \n",
    "               \n",
    "        done = terminated or truncated\n",
    "        obs = next_obs\n",
    "    \n",
    "    # if verbose: \n",
    "    #     print(f\"train episode [{episode}/{n_episodes}] ===> Loss: {vae_loss.item():.3f}, ReconstructionLoss: {reconstruction_loss.item():.3f}, weighted_entropy_loss: {weighted_entropy_loss.item():.3f}\")\n",
    "        \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e74d14",
   "metadata": {},
   "source": [
    "## Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8124082",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "v cannot be empty",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(ncols\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m      5\u001b[0m axs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSequential VAE Loss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m vae_losses_moving_average \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m----> 7\u001b[0m     \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvolve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvae_losses\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrolling_length\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;241m/\u001b[39m rolling_length\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     12\u001b[0m axs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mplot(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(vae_losses)), vae_losses, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvae_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m axs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mplot(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(vae_losses_moving_average)), vae_losses_moving_average, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmoving average\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconvolve\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/numeric.py:849\u001b[0m, in \u001b[0;36mconvolve\u001b[0;34m(a, v, mode)\u001b[0m\n\u001b[1;32m    847\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma cannot be empty\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    848\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(v) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 849\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv cannot be empty\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    850\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m multiarray\u001b[38;5;241m.\u001b[39mcorrelate(a, v[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], mode)\n",
      "\u001b[0;31mValueError\u001b[0m: v cannot be empty"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rolling_length = max(1, int(len(vae_losses)/20))\n",
    "\n",
    "fig, axs = plt.subplots(ncols=3, figsize=(12, 5))\n",
    "\n",
    "axs[0].set_title(\"Sequential VAE Loss\")\n",
    "vae_losses_moving_average = (\n",
    "    np.convolve(\n",
    "        np.array(vae_losses).flatten(), np.ones(rolling_length), mode=\"valid\"\n",
    "    )\n",
    "    / rolling_length\n",
    ")\n",
    "axs[0].plot(range(len(vae_losses)), vae_losses, label=\"vae_loss\")\n",
    "axs[0].plot(range(len(vae_losses_moving_average)), vae_losses_moving_average, label=\"moving average\")\n",
    "axs[0].legend(loc=\"upper right\")\n",
    "\n",
    "\n",
    "axs[1].set_title(\"Reconstruction Loss\")\n",
    "reconstruction_losses_moving_average = (\n",
    "    np.convolve(\n",
    "        np.array(reconstruction_losses).flatten(), np.ones(rolling_length), mode=\"valid\"\n",
    "    )\n",
    "    / rolling_length\n",
    ")\n",
    "axs[1].plot(range(len(reconstruction_losses)), reconstruction_losses, label=\"reconstruction_losses\")\n",
    "axs[1].plot(range(len(reconstruction_losses_moving_average)), reconstruction_losses_moving_average, label=\"moving average\")\n",
    "axs[1].legend(loc=\"upper right\")\n",
    "\n",
    "axs[2].set_title(\"Weighted Entropy Loss\")\n",
    "entropy_losses_moving_average = (\n",
    "    np.convolve(\n",
    "        np.array(entropy_losses).flatten(), np.ones(rolling_length), mode=\"valid\"\n",
    "    )\n",
    "    / rolling_length\n",
    ")\n",
    "axs[2].plot(range(len(entropy_losses)), entropy_losses, label=\"entropy_losses\")\n",
    "axs[2].plot(range(len(entropy_losses_moving_average)), entropy_losses_moving_average, label=\"moving average\")\n",
    "axs[2].legend(loc=\"upper right\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30768921",
   "metadata": {},
   "source": [
    "# Overfitting and visualization playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d510187a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" overfit to one sample to test whether the VAE works \"\"\"\n",
    "overfit = False\n",
    "\n",
    "if overfit:\n",
    "    batch_tensor = torch.load(\"batch_tensor.pt\").to(device)\n",
    "    vae_losses, reconstruction_losses, entropy_losses = [], [], []\n",
    "    \n",
    "    for i in range(200):\n",
    "        \n",
    "        xhat = vae(batch_tensor)\n",
    "    \n",
    "        # get a loss and update the autoencoder\n",
    "        vae_loss, reconstruction_loss, entropy_loss = vae.get_loss(batch_tensor, xhat)\n",
    "        vae_optim.zero_grad()\n",
    "        vae_loss.backward()\n",
    "        vae_optim.step()\n",
    "    \n",
    "        vae_losses.append(vae_loss.item())\n",
    "        reconstruction_losses.append(reconstruction_loss.item())\n",
    "        entropy_losses.append(entropy_loss.item())\n",
    "    \n",
    "        if i % 20 == 0:\n",
    "            print(f\"[{i+1}/{200}] loss: {vae_loss.item()}, entropy loss: {entropy_loss}, lr: {get_lr(vae_optim)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0cb4c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize = False\n",
    "\n",
    "if visualize:\n",
    "    batch_tensor = torch.load(\"batch_tensor.pt\").to(device)\n",
    "    \n",
    "    \"\"\" show the observation \"\"\"\n",
    "    plt.imshow(torch.permute(batch_tensor[0].cpu(), (1,2,0)), cmap=\"gray\")\n",
    "    plt.show()\n",
    "    \n",
    "    \"\"\" show the reconstruction \"\"\"\n",
    "    rssm.vae.eval()\n",
    "    with torch.no_grad():\n",
    "        xhat = rssm.vae(batch_tensor)\n",
    "        plt.imshow(torch.permute(xhat[0].cpu(), (1,2,0)), cmap=\"gray\")\n",
    "        plt.show()\n",
    "    rssm.vae.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e54b07f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4436932",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a21c7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3915a7c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12effa50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
