{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b1c5dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import gym_donkeycar\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import HBox, VBox\n",
    "from IPython.display import display\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Normal, Categorical\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "# custom classes and functions\n",
    "import models\n",
    "from models.blocks import ConvBlock, TransposeConvBlock, ResConvBlock, CategoricalStraightThrough\n",
    "from models.mlp import MLP\n",
    "from models.autoencoder import Autoencoder\n",
    "from models.vae import VAE\n",
    "from models.categorical_vae import CategoricalVAE\n",
    "from preprocessing import grayscale_transform as transform\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa538bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf2df7b",
   "metadata": {},
   "source": [
    "## Create VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b664daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| CategoricalVAE info |\n",
      "-----------------------\n",
      "device: cuda\n",
      "number of parameters: 38_151_857\n",
      "input shape : [8, 1, 128, 128]\n",
      "hidden shape: [8, 32, 32]\n",
      "output shape: [8, 1, 128, 128]\n",
      "vae_ent_coeff: 1e-08\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "\n",
    "# VAE\n",
    "vae = CategoricalVAE(\n",
    "    greyscale=True,\n",
    "    vae_ent_coeff=1e-8\n",
    ").to(device)\n",
    "\n",
    "# VAE optimizer\n",
    "vae_optim = optim.Adam(\n",
    "    vae.parameters(), \n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-5 # l2 regularization\n",
    ")\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group[\"lr\"]\n",
    "\n",
    "# display VAE stats\n",
    "vae.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43500bee",
   "metadata": {},
   "source": [
    "## Create RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8c78302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN ==> number of parameters: 3_153_408\n"
     ]
    }
   ],
   "source": [
    "A = 3 # number of action dimensions (3 for toy, 2 for real sim)\n",
    "H = 512 # discrete h state \n",
    "Z = 32*32 # stochastic Zx1 state\n",
    "num_rnn_layers = 1\n",
    "\n",
    "rnn = nn.GRU(\n",
    "    input_size=A+H+Z,\n",
    "    hidden_size=H,\n",
    "    num_layers=num_rnn_layers\n",
    ").to(device)\n",
    "\n",
    "h = torch.zeros(num_rnn_layers, 1, H) # seq_len, B, H\n",
    "\n",
    "print(f\"RNN ==> number of parameters: {sum(p.numel() for p in rnn.parameters() if p.requires_grad):_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239558a5",
   "metadata": {},
   "source": [
    "## RSSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75b75910",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RSSM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RSSM, self).__init__()\n",
    "        \n",
    "        self.vae = CategoricalVAE(greyscale=True, vae_ent_coeff=1e-8)\n",
    "        self.rnn = nn.GRU(input_size=A+H+Z, hidden_size=H, num_layers=num_rnn_layers)\n",
    "        \n",
    "        self.dynamics_mlp = MLP(input_dims=H, output_dims=Z) # H -> Z\n",
    "        self.reward_mlp = MLP(input_dims=H+Z, output_dims=1) # state (H+Z) -> 1\n",
    "        self.continue_mlp = MLP(input_dims=H+Z, output_dims=1) # state (H+Z)->1 # add sigmoid and BinaryCE\n",
    "    \n",
    "    \n",
    "    # def forward(self, x):\n",
    "    \n",
    "    \n",
    "    def print_num_params(self):\n",
    "        print(f\"RSSM ==> number of parameters: {sum(p.numel() for p in rssm.parameters() if p.requires_grad):_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6427a66e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSSM ==> number of parameters: 43_668_147\n"
     ]
    }
   ],
   "source": [
    "rssm = RSSM().to(device)\n",
    "\n",
    "rssm_optim = optim.Adam(\n",
    "    rssm.parameters(), \n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-5 # l2 regularization\n",
    ")\n",
    "\n",
    "rssm.print_num_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4616b784",
   "metadata": {},
   "source": [
    "```py\n",
    "\n",
    "- given: h, obs (obs is given only in training mode)\n",
    "\n",
    "# predict z from h\n",
    "z_pred = dynamics_mlp(h)\n",
    "\n",
    "# get true z from encoder\n",
    "z_sample = vae.encode(obs) # returns one-hot on softmax sample\n",
    "\n",
    "state = concat(h,z)\n",
    "\n",
    "# apply actor and critic nets on state\n",
    "v = value_net(state)\n",
    "a = actor_critic(state) # a is a 2x1 vector\n",
    "\n",
    "# predict other stuff\n",
    "r = reward_mlp(state)\n",
    "c = continue_mlp(state) # binary classification\n",
    "\n",
    "# combine everything into belief state\n",
    "x = concat(a, state)\n",
    "\n",
    "\n",
    "# apply rnn\n",
    "h_new = rnn(x, h)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc178dac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04cb4a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_net = MLP(input_dims=H+Z, output_dims=1).to(device) # state (H+Z) -> 1\n",
    "policy_net = MLP(input_dims=H+Z, output_dims=A).to(device) # state (H+Z) -> A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856cb39a",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cd076d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train episode [0/100] ===> Loss: 0.930, ReconstructionLoss: 0.930, weighted_entropy_loss: -0.000, lr: 0.001\n",
      "train episode [1/100] ===> Loss: 0.932, ReconstructionLoss: 0.932, weighted_entropy_loss: -0.000, lr: 0.001\n",
      "train episode [2/100] ===> Loss: 0.926, ReconstructionLoss: 0.926, weighted_entropy_loss: -0.000, lr: 0.001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 64\u001b[0m\n\u001b[1;32m     61\u001b[0m vae_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     62\u001b[0m vae_optim\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 64\u001b[0m vae_losses\u001b[38;5;241m.\u001b[39mappend(\u001b[43mvae_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     65\u001b[0m reconstruction_losses\u001b[38;5;241m.\u001b[39mappend(reconstruction_loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m     66\u001b[0m entropy_losses\u001b[38;5;241m.\u001b[39mappend(weighted_entropy_loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\" vae training loop \"\"\"\n",
    "\n",
    "# create the environment\n",
    "toy_env = True\n",
    "\n",
    "if toy_env:\n",
    "    assert A==3\n",
    "    env = gym.make(\"CarRacing-v2\", max_episode_steps=40, render_mode=\"rgb_array\")\n",
    "else:\n",
    "    assert A==2\n",
    "    exe_path = \"/home/till/Desktop/Thesis/donkeycar_sim/DonkeySimLinux/donkey_sim.x86_64\"\n",
    "    port = 9091\n",
    "    config = {\n",
    "        \"exe_path\" : exe_path, \n",
    "        \"port\" : port \n",
    "    }\n",
    "    env = gym.make(\n",
    "        \"GymV21Environment-v0\", \n",
    "        env_id=\"donkey-minimonaco-track-v0\", # donkey-warehouse-v0 \n",
    "        make_kwargs={\n",
    "            \"conf\": config\n",
    "        })\n",
    "\n",
    "verbose = True\n",
    "n_episodes = 100\n",
    "vae_losses, reconstruction_losses, entropy_losses = [], [], []\n",
    "vae.train()\n",
    "\n",
    "for episode in range(n_episodes): # tqdm\n",
    "    \n",
    "    # get the initial state\n",
    "    obs, info = env.reset()\n",
    "    \n",
    "    # reset the rnn's hidden state\n",
    "    h = torch.zeros(num_rnn_layers, 1, H, device=device) # seq_len, B, H\n",
    "    \n",
    "    # setup a minibatch of x's for training the autoencoder\n",
    "    batch_counter = 0\n",
    "    batch_tensor = torch.empty((batch_size,) + transform(obs).shape, device=device) # B,C,H,W\n",
    "    \n",
    "    # play one episode\n",
    "    done = False\n",
    "    while not done:\n",
    "             \n",
    "        # add the new x to the batch\n",
    "        x = transform(obs).view(-1, 1, 128, 128)\n",
    "        batch_tensor[batch_counter] = transform(obs)\n",
    "        batch_counter += 1\n",
    "        \n",
    "        \"\"\" train networks on accumulated batch \"\"\"\n",
    "        if batch_counter % batch_size == 0:\n",
    "            # reset the batch counter\n",
    "            batch_counter = 0\n",
    "            \n",
    "            # autoencoder forward pass with a minibatch\n",
    "            xhat = rssm.vae(batch_tensor)\n",
    "\n",
    "            # get a loss and update the autoencoder\n",
    "            vae_loss, reconstruction_loss, weighted_entropy_loss = rssm.vae.get_loss(batch_tensor, xhat)\n",
    "            vae_optim.zero_grad()\n",
    "            vae_loss.backward()\n",
    "            vae_optim.step()\n",
    "            \n",
    "            vae_losses.append(vae_loss.item())\n",
    "            reconstruction_losses.append(reconstruction_loss.item())\n",
    "            entropy_losses.append(weighted_entropy_loss.item())\n",
    "        \n",
    "        # predict z from h\n",
    "        z_pred = rssm.dynamics_mlp(h).view(-1, Z) # B,1024 (flattened)\n",
    "        \n",
    "        # get true z from encoder\n",
    "        z = rssm.vae.encode(x).view(-1, Z) # B,1024 (flattened)\n",
    "        \n",
    "        state = torch.cat((h.view(-1, H), z), 1) # 1 (B), H+Z\n",
    "        \n",
    "        # apply actor and critic nets on state\n",
    "        v = value_net(state)\n",
    "        action = policy_net(state) # a is a 2x1 vector\n",
    "        \n",
    "        # predict other stuff\n",
    "        r = rssm.reward_mlp(state)\n",
    "        c = rssm.continue_mlp(state) # binary classification\n",
    "        \n",
    "        # combine everything and apply the rnn to get the next hidden state\n",
    "        rnn_input = torch.cat((action, state), dim=1)\n",
    "        _, h = rssm.rnn(rnn_input, h.view(-1, H))\n",
    "        \n",
    "        # choose and execute an action\n",
    "        # action = env.action_space.sample()\n",
    "        next_obs, reward, terminated, truncated, info = env.step(action.squeeze().detach().cpu().numpy())        \n",
    "               \n",
    "        done = terminated or truncated\n",
    "        obs = next_obs\n",
    "    \n",
    "    if verbose: \n",
    "        print(f\"train episode [{episode}/{n_episodes}] ===> Loss: {vae_loss.item():.3f}, ReconstructionLoss: {reconstruction_loss.item():.3f}, weighted_entropy_loss: {weighted_entropy_loss.item():.3f}, lr: {get_lr(vae_optim)}\")\n",
    "        \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e74d14",
   "metadata": {},
   "source": [
    "## Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8124082",
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_length = 1\n",
    "\n",
    "fig, axs = plt.subplots(ncols=3, figsize=(12, 5))\n",
    "\n",
    "axs[0].set_title(\"VAE Loss\")\n",
    "vae_losses_moving_average = (\n",
    "    np.convolve(\n",
    "        np.array(vae_losses).flatten(), np.ones(rolling_length), mode=\"valid\"\n",
    "    )\n",
    "    / rolling_length\n",
    ")\n",
    "axs[0].plot(range(len(vae_losses_moving_average)), vae_losses_moving_average)\n",
    "\n",
    "\n",
    "axs[1].set_title(\"Reconstruction Loss\")\n",
    "reconstruction_losses_moving_average = (\n",
    "    np.convolve(\n",
    "        np.array(reconstruction_losses).flatten(), np.ones(rolling_length), mode=\"valid\"\n",
    "    )\n",
    "    / rolling_length\n",
    ")\n",
    "axs[1].plot(range(len(reconstruction_losses_moving_average)), reconstruction_losses_moving_average)\n",
    "\n",
    "axs[2].set_title(\"Weighted Entropy Loss\")\n",
    "entropy_losses_moving_average = (\n",
    "    np.convolve(\n",
    "        np.array(entropy_losses).flatten(), np.ones(rolling_length), mode=\"valid\"\n",
    "    )\n",
    "    / rolling_length\n",
    ")\n",
    "axs[2].plot(range(len(entropy_losses_moving_average)), entropy_losses_moving_average);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07793b6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c8481d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30768921",
   "metadata": {},
   "source": [
    "# Overfitting and visualization playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d510187a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" overfit to one sample \"\"\"\n",
    "batch_tensor = torch.load(\"batch_tensor.pt\").to(device)\n",
    "vae_losses, reconstruction_losses, entropy_losses = [], [], []\n",
    "\n",
    "for i in range(200):\n",
    "    \n",
    "    xhat = vae(batch_tensor)\n",
    "\n",
    "    # get a loss and update the autoencoder\n",
    "    vae_loss, reconstruction_loss, entropy_loss = vae.get_loss(batch_tensor, xhat)\n",
    "    vae_optim.zero_grad()\n",
    "    vae_loss.backward()\n",
    "    vae_optim.step()\n",
    "\n",
    "    vae_losses.append(vae_loss.item())\n",
    "    reconstruction_losses.append(reconstruction_loss.item())\n",
    "    entropy_losses.append(entropy_loss.item())\n",
    "\n",
    "    if i % 20 == 0:\n",
    "        print(f\"[{i+1}/{200}] loss: {vae_loss.item()}, entropy loss: {entropy_loss}, lr: {get_lr(vae_optim)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cb4c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_tensor = torch.load(\"batch_tensor.pt\").to(device)\n",
    "\n",
    "\"\"\" show the observation \"\"\"\n",
    "plt.imshow(torch.permute(batch_tensor[0].cpu(), (1,2,0)), cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "\"\"\" show the reconstruction \"\"\"\n",
    "vae.eval()\n",
    "with torch.no_grad():\n",
    "    xhat = vae(batch_tensor)\n",
    "    plt.imshow(torch.permute(xhat[0].cpu(), (1,2,0)), cmap=\"gray\")\n",
    "    plt.show()\n",
    "vae.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e54b07f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
