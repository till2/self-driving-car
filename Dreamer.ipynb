{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b1c5dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import gym_donkeycar\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import HBox, VBox\n",
    "from IPython.display import display\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Normal, Categorical\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "# custom classes and functions\n",
    "import models\n",
    "from models.blocks import ConvBlock, TransposeConvBlock, ResConvBlock, CategoricalStraightThrough\n",
    "from models.mlp import MLP\n",
    "from models.autoencoder import Autoencoder\n",
    "from models.vae import VAE\n",
    "from models.categorical_vae import CategoricalVAE\n",
    "from models.sequential_categorical_vae import SeqCatVAE\n",
    "from preprocessing import grayscale_transform as transform\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa538bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d781d3",
   "metadata": {},
   "source": [
    "## Set Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8c78302",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "A = 3 # number of action dimensions (3 for toy, 2 for real sim)\n",
    "H = 512 # discrete h state \n",
    "Z = 32*32 # stochastic Zx1 state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239558a5",
   "metadata": {},
   "source": [
    "## RSSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b7bada",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0317baf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1c5aaf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RSSM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RSSM, self).__init__()\n",
    "        \n",
    "        # init the VAE\n",
    "        self.vae = SeqCatVAE(H, Z, grayscale=True, vae_ent_coeff=1e-8)\n",
    "        \n",
    "        # init the RNN\n",
    "        self.num_rnn_layers = 1\n",
    "        self.rnn = nn.GRU(input_size=A+H+Z, hidden_size=H, num_layers=self.num_rnn_layers)\n",
    "        \n",
    "        # init MLPs\n",
    "        self.dynamics_mlp = MLP(input_dims=H, output_dims=Z) # H -> Z\n",
    "        self.reward_mlp = MLP(input_dims=H+Z, output_dims=1) # state (H+Z) -> 1\n",
    "        self.continue_mlp = MLP(input_dims=H+Z, output_dims=1) # state (H+Z)->1 # add sigmoid and BinaryCE  \n",
    "    \n",
    "    def step(self, action, h, z):\n",
    "\n",
    "        # concatenate the rnn_input and apply RNN to obtain the next hidden state\n",
    "        rnn_input = torch.cat((action, h.view(-1, H), z), 1)\n",
    "        _, h = self.rnn(rnn_input, h.view(-1, H))\n",
    "        \n",
    "        state = torch.cat((h.view(-1, H), z), 1)\n",
    "        \n",
    "        # predict the reward and continue flag\n",
    "        reward_pred = rssm.reward_mlp(state)\n",
    "        continue_prob = F.sigmoid(rssm.continue_mlp(state)) # binary classification\n",
    "        continue_pred = bool(continue_prob > 0.5)\n",
    "        \n",
    "        x_reconstruction = rssm.vae.decode(h, z)\n",
    "        \n",
    "        return h, reward_pred, continue_pred\n",
    "    \n",
    "    # def info(self):\n",
    "    # - look at VAE.info() \n",
    "    \n",
    "    # def print_num_params(self):\n",
    "    #     print(f\"RSSM ==> number of parameters: {sum(p.numel() for p in rssm.parameters() if p.requires_grad):_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cda9f099",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rssm = RSSM().to(device)\n",
    "\n",
    "rssm_optim = optim.Adam(\n",
    "    rssm.parameters(), \n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-5 # l2 regularization\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c0594c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_net = MLP(input_dims=Z, output_dims=1).to(device) # state (H+Z) -> 1\n",
    "policy_net = MLP(input_dims=Z, output_dims=A).to(device) # state (H+Z) -> A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856cb39a",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cd076d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/till/.local/lib/python3.10/site-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 86\u001b[0m\n\u001b[1;32m     83\u001b[0m h, reward_pred, continue_pred \u001b[38;5;241m=\u001b[39m rssm\u001b[38;5;241m.\u001b[39mstep(action, h, z)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# choose and execute an action\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m next_obs, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(\u001b[43maction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy())        \n\u001b[1;32m     88\u001b[0m done \u001b[38;5;241m=\u001b[39m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n\u001b[1;32m     89\u001b[0m obs \u001b[38;5;241m=\u001b[39m next_obs\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\" vae training loop \"\"\"\n",
    "\n",
    "# create the environment\n",
    "toy_env = True\n",
    "\n",
    "if toy_env:\n",
    "    assert A==3\n",
    "    env = gym.make(\"CarRacing-v2\", max_episode_steps=250, render_mode=\"human\") # rgb_array/human\n",
    "else:\n",
    "    assert A==2\n",
    "    exe_path = \"/home/till/Desktop/Thesis/donkeycar_sim/DonkeySimLinux/donkey_sim.x86_64\"\n",
    "    port = 9091\n",
    "    config = {\n",
    "        \"exe_path\" : exe_path, \n",
    "        \"port\" : port \n",
    "    }\n",
    "    env = gym.make(\n",
    "        \"GymV21Environment-v0\", \n",
    "        env_id=\"donkey-minimonaco-track-v0\", # donkey-warehouse-v0 \n",
    "        make_kwargs={\n",
    "            \"conf\": config\n",
    "        })\n",
    "\n",
    "verbose = True\n",
    "n_episodes = 100\n",
    "vae_losses, reconstruction_losses, entropy_losses = [], [], []\n",
    "rssm.train()\n",
    "\n",
    "for episode in range(n_episodes): # tqdm\n",
    "    \n",
    "    # get the initial state\n",
    "    obs, info = env.reset()\n",
    "    \n",
    "    # reset the rnn's hidden state\n",
    "    h = torch.zeros(rssm.num_rnn_layers, 1, H, device=device) # seq_len, B, H\n",
    "    \n",
    "    # setup a minibatch of x's for training the autoencoder\n",
    "    batch_counter = 0\n",
    "    batch_tensor = torch.empty((batch_size,) + transform(obs).shape, device=device) # B,C,H,W\n",
    "    \n",
    "    # play one episode\n",
    "    done = False\n",
    "    while not done:\n",
    "             \n",
    "        # add the new x to the batch\n",
    "        x = transform(obs).view(-1, 1, 128, 128)\n",
    "        # batch_tensor[batch_counter] = transform(obs)\n",
    "        # batch_counter += 1\n",
    "        \n",
    "        \n",
    "        # TODO: sequence batch mit inputs x, actions a, rewards r, continue c\n",
    "        \n",
    "        # \"\"\" train networks on accumulated batch \"\"\"\n",
    "        # if batch_counter % batch_size == 0:\n",
    "        #     # reset the batch counter\n",
    "        #     batch_counter = 0\n",
    "        #     \n",
    "        #     # autoencoder forward pass with a minibatch\n",
    "        #     xhat = rssm.vae(batch_tensor) # TODO: hier brauchen wir die h_tensor batch\n",
    "        # \n",
    "        #     # get a loss and update the autoencoder\n",
    "        #     vae_loss, reconstruction_loss, weighted_entropy_loss = rssm.vae.get_loss(batch_tensor, xhat)\n",
    "        #     rssm_optim.zero_grad()\n",
    "        #     vae_loss.backward()\n",
    "        #     rssm_optim.step()\n",
    "        #     \n",
    "        #     vae_losses.append(vae_loss.item())\n",
    "        #     reconstruction_losses.append(reconstruction_loss.item())\n",
    "        #     entropy_losses.append(weighted_entropy_loss.item())\n",
    "        \n",
    "        \n",
    "        \"\"\" WORLD MODEL LEARNING \"\"\"\n",
    "        \n",
    "        # predict z and generate the true stochastic latent variable z with the encoder\n",
    "        z_pred = rssm.dynamics_mlp(h).view(-1, Z) # B,1024 (flattened)\n",
    "        z = rssm.vae.encode(h, x).view(-1, Z) # TODO: use h,x\n",
    "        \n",
    "        # apply external actor and critic nets on z\n",
    "        action = policy_net(z) # a is a 2x1 vector\n",
    "        v = value_net(z)\n",
    "        \n",
    "        # predict one step using the RSSM and apply the actor-critic\n",
    "        h, reward_pred, continue_pred = rssm.step(action, h, z)\n",
    "        \n",
    "        # choose and execute an action\n",
    "        next_obs, reward, terminated, truncated, info = env.step(action.squeeze().detach().cpu().numpy())        \n",
    "               \n",
    "        done = terminated or truncated\n",
    "        obs = next_obs\n",
    "    \n",
    "    # if verbose: \n",
    "    #     print(f\"train episode [{episode}/{n_episodes}] ===> Loss: {vae_loss.item():.3f}, ReconstructionLoss: {reconstruction_loss.item():.3f}, weighted_entropy_loss: {weighted_entropy_loss.item():.3f}\")\n",
    "        \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e74d14",
   "metadata": {},
   "source": [
    "## Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8124082",
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_length = max(1, int(len(vae_losses)/20))\n",
    "\n",
    "fig, axs = plt.subplots(ncols=3, figsize=(12, 5))\n",
    "\n",
    "axs[0].set_title(\"Sequential VAE Loss\")\n",
    "vae_losses_moving_average = (\n",
    "    np.convolve(\n",
    "        np.array(vae_losses).flatten(), np.ones(rolling_length), mode=\"valid\"\n",
    "    )\n",
    "    / rolling_length\n",
    ")\n",
    "axs[0].plot(range(len(vae_losses)), vae_losses, label=\"vae_loss\")\n",
    "axs[0].plot(range(len(vae_losses_moving_average)), vae_losses_moving_average, label=\"moving average\")\n",
    "axs[0].legend(loc=\"upper right\")\n",
    "\n",
    "\n",
    "axs[1].set_title(\"Reconstruction Loss\")\n",
    "reconstruction_losses_moving_average = (\n",
    "    np.convolve(\n",
    "        np.array(reconstruction_losses).flatten(), np.ones(rolling_length), mode=\"valid\"\n",
    "    )\n",
    "    / rolling_length\n",
    ")\n",
    "axs[1].plot(range(len(reconstruction_losses)), reconstruction_losses, label=\"reconstruction_losses\")\n",
    "axs[1].plot(range(len(reconstruction_losses_moving_average)), reconstruction_losses_moving_average, label=\"moving average\")\n",
    "axs[1].legend(loc=\"upper right\")\n",
    "\n",
    "axs[2].set_title(\"Weighted Entropy Loss\")\n",
    "entropy_losses_moving_average = (\n",
    "    np.convolve(\n",
    "        np.array(entropy_losses).flatten(), np.ones(rolling_length), mode=\"valid\"\n",
    "    )\n",
    "    / rolling_length\n",
    ")\n",
    "axs[2].plot(range(len(entropy_losses)), entropy_losses, label=\"entropy_losses\")\n",
    "axs[2].plot(range(len(entropy_losses_moving_average)), entropy_losses_moving_average, label=\"moving average\")\n",
    "axs[2].legend(loc=\"upper right\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30768921",
   "metadata": {},
   "source": [
    "# Overfitting and visualization playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d510187a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" overfit to one sample to test whether the VAE works \"\"\"\n",
    "overfit = False\n",
    "\n",
    "if overfit:\n",
    "    batch_tensor = torch.load(\"batch_tensor.pt\").to(device)\n",
    "    vae_losses, reconstruction_losses, entropy_losses = [], [], []\n",
    "    \n",
    "    for i in range(200):\n",
    "        \n",
    "        xhat = vae(batch_tensor)\n",
    "    \n",
    "        # get a loss and update the autoencoder\n",
    "        vae_loss, reconstruction_loss, entropy_loss = vae.get_loss(batch_tensor, xhat)\n",
    "        vae_optim.zero_grad()\n",
    "        vae_loss.backward()\n",
    "        vae_optim.step()\n",
    "    \n",
    "        vae_losses.append(vae_loss.item())\n",
    "        reconstruction_losses.append(reconstruction_loss.item())\n",
    "        entropy_losses.append(entropy_loss.item())\n",
    "    \n",
    "        if i % 20 == 0:\n",
    "            print(f\"[{i+1}/{200}] loss: {vae_loss.item()}, entropy loss: {entropy_loss}, lr: {get_lr(vae_optim)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cb4c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize = False\n",
    "\n",
    "if visualize:\n",
    "    batch_tensor = torch.load(\"batch_tensor.pt\").to(device)\n",
    "    \n",
    "    \"\"\" show the observation \"\"\"\n",
    "    plt.imshow(torch.permute(batch_tensor[0].cpu(), (1,2,0)), cmap=\"gray\")\n",
    "    plt.show()\n",
    "    \n",
    "    \"\"\" show the reconstruction \"\"\"\n",
    "    rssm.vae.eval()\n",
    "    with torch.no_grad():\n",
    "        xhat = rssm.vae(batch_tensor)\n",
    "        plt.imshow(torch.permute(xhat[0].cpu(), (1,2,0)), cmap=\"gray\")\n",
    "        plt.show()\n",
    "    rssm.vae.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e54b07f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2656be04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59afc726",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde54db5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71eab848",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
