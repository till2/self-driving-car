{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43db25de",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d80a4c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "from collections import deque\n",
    "from operator import itemgetter\n",
    "\n",
    "import gym_donkeycar\n",
    "import gymnasium as gym\n",
    "import imageio\n",
    "import ipywidgets as widgets\n",
    "import logging\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from IPython.display import display\n",
    "from ipywidgets import HBox, VBox\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from ruamel.yaml import YAML\n",
    "from tensorboard import notebook\n",
    "from tensorboard.backend.event_processing.event_accumulator import \\\n",
    "    EventAccumulator\n",
    "from torch import distributions as dist\n",
    "from torch.distributions import Categorical, Normal\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "# suppress warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ[\"IMAGEIO_IGNORE_WARNINGS\"] = \"True\"\n",
    "\n",
    "import gym.spaces as gym_spaces\n",
    "import gymnasium as gym  # overwrite OpenAI gym\n",
    "import stable_baselines3 as sb3\n",
    "from gym_donkeycar.envs.donkey_env import DonkeyEnv\n",
    "from gymnasium import spaces\n",
    "from gymnasium.spaces import Box\n",
    "from src.actor_critic import ContinuousActorCritic\n",
    "from src.blocks import CategoricalStraightThrough, ConvBlock\n",
    "from src.categorical_vae import CategoricalVAE\n",
    "from src.imagination_env import ImaginationEnv\n",
    "from src.mlp import MLP\n",
    "from src.preprocessing import grayscale_transform as transform\n",
    "from src.replay_buffer import ReplayBuffer\n",
    "from src.rssm import RSSM\n",
    "from src.utils import load_config, save_image_and_reconstruction, to_np, make_env\n",
    "from stable_baselines3 import A2C, PPO, SAC\n",
    "from stable_baselines3.common import env_checker\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.results_plotter import load_results, ts2xy\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545b8cec",
   "metadata": {},
   "source": [
    "## Load the config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cddca1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'device': device(type='cuda', index=0), 'A': 2, 'Z': 1024, 'debug': False, 'show_inline_tensorboard': False, 'log_dir': 'logs/', 'seed': 0, 'exe_path': '/home/till/Desktop/Thesis/donkeycar_sim/DonkeySimLinux/donkey_sim.x86_64', 'env_id': 'donkey-minimonaco-track-v0', 'port': 9091, 'frame_skip': 2, 'max_cte': 4.0, 'body_style': 'f1', 'body_rgb': [255, 255, 255], 'car_name': 'RL-Racer', 'font_size': 30, 'toy_env': False, 'vectorized': True, 'monitor': False, 'n_envs': 2, 'size': [64, 64], 'grayscale': False, 'start_episode': 1000, 'n_seed_episodes': 1000, 'n_training_episodes': 5000, 'max_episode_steps': 1000, 'max_imagination_episode_steps': 15, 'imagination_timesteps_per_model_update': 200, 'max_grad_norm': 1, 'rssm_lr': 0.0001, 'rssm_l2_regularization': 1e-06, 'batch_size': 1, 'H': 512, 'uniform_ratio': 0.01, 'buffer_size': 50000, 'activation': 'silu', 'num_categoricals': 32, 'num_classes': 32, 'channels': [64, 128, 256, 512, 256], 'kernel_size': 3, 'stride': 2, 'padding': 1, 'conv_bias': False, 'entropyloss_coeff': 0.0, 'decoder_final_activation': 'sigmoid', 'pred_loss_coeff': 1.0, 'dyn_loss_coeff': 0.5, 'rep_loss_coeff': 0.1, 'free_nats': 1.0, 'num_rnn_layers': 1, 'mlp_n_layers': 3, 'mlp_hidden_dims': 256, 'store_on_cpu': True, 'gamma': 0.997, 'lam': 0.95, 'ent_coef': 0.01, 'verbose': 1, 'imagination_progress_bar': True, 'action_clip': 0.5}\n"
     ]
    }
   ],
   "source": [
    "config = load_config()\n",
    "\n",
    "for key in config:\n",
    "    locals()[key] = config[key]\n",
    "\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1daa9ad2",
   "metadata": {},
   "source": [
    "## Create the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fef45ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making a real sim env.\n",
      "Making 2 vectorized envs.\n",
      "starting DonkeyGym env\n",
      "donkey subprocess started\n",
      "Found path: /home/till/Desktop/Thesis/donkeycar_sim/DonkeySimLinux/donkey_sim.x86_64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym_donkeycar.core.client:connecting to localhost:9091 \n",
      "/home/till/.local/lib/python3.10/site-packages/gym/logger.py:34: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize(\"%s: %s\" % (\"WARN\", msg % args), \"yellow\"))\n",
      "WARNING:gym_donkeycar.envs.donkey_sim:waiting for sim to start..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading scene mini_monaco\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym_donkeycar.envs.donkey_sim:on need car config\n",
      "INFO:gym_donkeycar.envs.donkey_sim:sending car config.\n",
      "INFO:gym_donkeycar.envs.donkey_sim:sim started!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting DonkeyGym env\n",
      "donkey subprocess started\n",
      "Found path: /home/till/Desktop/Thesis/donkeycar_sim/DonkeySimLinux/donkey_sim.x86_64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym_donkeycar.core.client:connecting to localhost:9091 \n",
      "INFO:gym_donkeycar.envs.donkey_sim:on need car config\n",
      "INFO:gym_donkeycar.envs.donkey_sim:sending car config.\n",
      "INFO:gym_donkeycar.envs.donkey_sim:sim started!\n"
     ]
    }
   ],
   "source": [
    "env = make_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb107ed",
   "metadata": {},
   "source": [
    "## Train an agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e58af9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Logging to baseline_logs/PPO_8\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 43.5     |\n",
      "|    ep_rew_mean     | 9.68     |\n",
      "| time/              |          |\n",
      "|    fps             | 24       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 170      |\n",
      "|    total_timesteps | 4096     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 46.5        |\n",
      "|    ep_rew_mean          | 11.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 24          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 331         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014259405 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.84       |\n",
      "|    explained_variance   | -0.0153     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.517       |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    std                  | 0.993       |\n",
      "|    value_loss           | 2.1         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 3.88 seconds\n"
     ]
    }
   ],
   "source": [
    "train_agent = True\n",
    "\n",
    "if train_agent:\n",
    "    \n",
    "    agent = PPO(\n",
    "        \"CnnPolicy\",\n",
    "        env,\n",
    "        verbose=1,\n",
    "        tensorboard_log=\"baseline_logs/\"\n",
    "    )\n",
    "    agent.learn(total_timesteps=500_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52c163b",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_agent = False\n",
    "\n",
    "if save_agent:\n",
    "    # agent.save(\"baseline_weights/SAC_500k\")\n",
    "    # agent.save_replay_buffer(\"baseline_weights/SAC_500k_replay_buffer\")\n",
    "    \n",
    "    agent.save(\"baseline_weights/AGENT_NAME_FILLER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540c36f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_agent = False\n",
    "\n",
    "if load_agent:\n",
    "    \n",
    "    # create the agent\n",
    "    eval_agent = A2C(\n",
    "        \"CnnPolicy\", \n",
    "        env,\n",
    "        #buffer_size=0,\n",
    "        verbose=1, \n",
    "        # tensorboard_log=\"baseline_logs/\"\n",
    "    )\n",
    "    \n",
    "    # load the agent\n",
    "    eval_agent.load(\"baseline_weights/A2C_500k\")\n",
    "    # eval_agent.load_replay_buffer(\"baseline_weights/SAC_500k_replay_buffer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8b4bc7",
   "metadata": {},
   "source": [
    "## Trained Policy Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137fc77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_trained_policy = True\n",
    "\n",
    "# CURRENTLY SELECTING RANDOM ACTIONS TO TEST THE PLOTTING.\n",
    "\n",
    "if evaluate_trained_policy:\n",
    "    n_trials = 30\n",
    "\n",
    "    sim_config = {\n",
    "     \"exe_path\" : \"/home/till/Desktop/Thesis/donkeycar_sim/DonkeySimLinux/donkey_sim.x86_64\",\n",
    "     \"port\" : 9091,\n",
    "    }\n",
    "    env = gym.make(\n",
    "        \"GymV21Environment-v0\",\n",
    "        env_id=env_id,\n",
    "        max_episode_steps=1500,\n",
    "        make_kwargs={\n",
    "         \"conf\": sim_config\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # create the agent\n",
    "    eval_agent = SAC(\n",
    "        \"CnnPolicy\", \n",
    "        env,\n",
    "        buffer_size=0,\n",
    "        verbose=1, \n",
    "        # tensorboard_log=\"baseline_logs/\"\n",
    "    )\n",
    "\n",
    "    # load the agent\n",
    "    # eval_agent.load(\"baseline_weights/SAC_500k\")\n",
    "\n",
    "    episode_rewards = []\n",
    "    episode_lengths = []\n",
    "\n",
    "    for i in range(n_trials):\n",
    "        print(\"Starting eval episode\", i)\n",
    "        episode_reward = 0.0\n",
    "        episode_length = 0\n",
    "\n",
    "        obs, info = env.reset()\n",
    "        done = False\n",
    "        while not done:\n",
    "            action = eval_agent.predict(obs, deterministic=True)\n",
    "            obs, reward, terminated, truncated, info = env.step([np.random.rand(), np.random.rand()])\n",
    "            episode_reward += reward\n",
    "            episode_length += 1\n",
    "            done = terminated or truncated\n",
    "\n",
    "        episode_rewards.append(episode_reward)\n",
    "        episode_lengths.append(episode_length)\n",
    "\n",
    "    # episode_rewards, episode_lengths = evaluate_policy(eval_agent, env, n_eval_episodes=30, return_episode_rewards=True, deterministic=True)\n",
    "    print(f\"mean_reward={np.mean(episode_rewards):.3f} +/- {np.std(episode_rewards):.3f}\")\n",
    "    print(f\"mean_length={np.mean(episode_lengths):.3f} +/- {np.std(episode_lengths):.3f}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff356bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bcf1c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dfc0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_files = False\n",
    "\n",
    "if save_files:\n",
    "\n",
    "    with open(\"baseline_eval/RANDOM_AGENT_episode_rewards.npy\", 'wb') as f:\n",
    "        np.save(f, episode_rewards)\n",
    "\n",
    "    with open(\"baseline_eval/RANDOM_AGENT_episode_lengths.npy\", 'wb') as f:\n",
    "        np.save(f, episode_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cb8275",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d74259",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"Random Agent\": {\n",
    "        \"episode_rewards\": np.load(\"baseline_eval/RANDOM_AGENT_episode_rewards.npy\"),\n",
    "        \"episode_lengths\": np.load(\"baseline_eval/RANDOM_AGENT_episode_lengths.npy\"),\n",
    "    },\n",
    "    \n",
    "    \"Random Agent 2\": {\n",
    "        \"episode_rewards\": np.load(\"baseline_eval/RANDOM_AGENT_episode_rewards.npy\") * 2,\n",
    "        \"episode_lengths\": np.load(\"baseline_eval/RANDOM_AGENT_episode_lengths.npy\") * 10 - 100, \n",
    "    },\n",
    "    \n",
    "    \"Random Agent 3\": {\n",
    "        \"episode_rewards\": np.load(\"baseline_eval/RANDOM_AGENT_episode_rewards.npy\") * 1.5,\n",
    "        \"episode_lengths\": np.load(\"baseline_eval/RANDOM_AGENT_episode_lengths.npy\") * 1.5, \n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64f575f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bootstrap_samples = 2000\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "for key in data.keys():\n",
    "    \n",
    "    episode_rewards = data[key][\"episode_rewards\"]\n",
    "    episode_lengths = data[key][\"episode_lengths\"]\n",
    "    \n",
    "    bootstrap_rewards = []\n",
    "    bootstrap_lengths = []\n",
    "\n",
    "    for _ in range(num_bootstrap_samples):\n",
    "        # bootstrap sampling for episode rewards\n",
    "        bootstrap_rewards_sample = np.random.choice(episode_rewards, size=len(episode_rewards), replace=True)\n",
    "        bootstrap_rewards.append(np.mean(bootstrap_rewards_sample))\n",
    "\n",
    "        # bootstrap sampling for episode lengths\n",
    "        bootstrap_lengths_sample = np.random.choice(episode_lengths, size=len(episode_lengths), replace=True)\n",
    "        bootstrap_lengths.append(np.mean(bootstrap_lengths_sample))\n",
    "\n",
    "    axs[0].hist(bootstrap_rewards, bins=\"auto\", alpha=0.7, density=True, label=key,) # color=\"tab:blue\"\n",
    "    axs[1].hist(bootstrap_lengths, bins=\"auto\", alpha=0.7, density=True, label=key) # color=\"tab:blue\"\n",
    "\n",
    "axs[0].set_xlabel(\"Bootstrapped Mean Episode Reward\")\n",
    "axs[0].set_ylabel(\"Probability Density\")\n",
    "axs[0].legend()\n",
    "#axs[0].set_title('Bootstrapped Episode Rewards Histogram')\n",
    "axs[0].grid(True, alpha=0.2)\n",
    "\n",
    "axs[1].set_xlabel(\"Bootstrapped Mean Episode Length\")\n",
    "axs[1].set_ylabel(\"Probability Density\")\n",
    "axs[1].legend()\n",
    "#axs[1].set_title('Bootstrapped Episode Lengths Histogram')\n",
    "axs[1].grid(True, alpha=0.2)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figs/Bootstrapped Episode Reward and Length.pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a7ab9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fed419",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0f4775",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f06bc3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dcf39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_config = {\n",
    " \"exe_path\" : \"/home/till/Desktop/Thesis/donkeycar_sim/DonkeySimLinux/donkey_sim.x86_64\",\n",
    " \"port\" : 9091,\n",
    "}\n",
    "env = gym.make(\n",
    "    \"GymV21Environment-v0\",\n",
    "    env_id=env_id,\n",
    "    max_episode_steps=1500,\n",
    "    make_kwargs={\n",
    "     \"conf\": sim_config\n",
    "    }\n",
    ")\n",
    "\n",
    "# create the agent\n",
    "eval_agent = PPO(\n",
    "    \"CnnPolicy\", \n",
    "    env,\n",
    "    #buffer_size=0,\n",
    "    verbose=1, \n",
    "    # tensorboard_log=\"baseline_logs/\"\n",
    ")\n",
    "\n",
    "# load the agent\n",
    "eval_agent.load(\"baseline_weights/PPO_500k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81185e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_agent = PPO(\n",
    "    \"CnnPolicy\", \n",
    "    env,\n",
    "    #buffer_size=0,\n",
    "    verbose=1, \n",
    "    # tensorboard_log=\"baseline_logs/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516bec83",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, info = env.reset()\n",
    "\n",
    "done = False\n",
    "while not done:\n",
    "    action = eval_agent.predict(obs)\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    episode_reward += reward\n",
    "    episode_length += 1\n",
    "    done = terminated or truncated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fa1302",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90aa4469",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3486ae7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10cb6cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af87ba1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d6238d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63de19b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_rewards, eval_lengths = evaluate_policy(eval_agent, env, n_eval_episodes=100, return_episode_rewards=True, deterministic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc804d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(\"eval_rewards\", np.array(eval_rewards))\n",
    "# np.save(\"eval_lengths\", np.array(eval_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2abda3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent = SAC(\n",
    "#     \"CnnPolicy\", \n",
    "#     env,\n",
    "#     buffer_size=20_000,\n",
    "#     verbose=1, \n",
    "#     tensorboard_log=\"logs/\")\n",
    "# \n",
    "# eval_callback = EvalCallback(\n",
    "#     env, \n",
    "#     best_model_save_path='weights/', \n",
    "#     log_path='logs/', \n",
    "#     eval_freq=500,\n",
    "#     n_eval_episodes=1)\n",
    "#\n",
    "# agent.learn(total_timesteps=30_000, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dac790a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c421a68c",
   "metadata": {},
   "source": [
    "## Plot the training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb07e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    \"rollout/ep_rew_mean\",     # SAC: ✅, PPO: ✅, A2C: ✅\n",
    "    \"rollout/ep_len_mean\",     # SAC: ✅, PPO: ✅, A2C: ✅\n",
    "    \"train/critic_loss\",       # SAC: critic_loss, PPO: value_loss, A2C: value_loss\n",
    "    \"train/actor_loss\",        # SAC: actor_loss, PPO: policy_gradient_loss, A2C: policy_loss\n",
    "    \"train/entropy_loss\",     # SAC: ent_coef_loss, PPO: entropy_loss, A2C: entropy_loss\n",
    "    \"time/fps\" # SAC: ✅, PPO: ✅, A2C: ✅\n",
    "]\n",
    "\n",
    "baselines = {\n",
    "    \"A2C_500k\": \"baseline_logs/A2C_500k/events.out.tfevents.1685255857.z.54420.0\",\n",
    "    \"SAC_500k\": \"baseline_logs/SAC_500k/events.out.tfevents.1685211019.z.35749.0\",\n",
    "    \"PPO_500k\": \"baseline_logs/PPO_500k/events.out.tfevents.1685229886.z.44451.0\",\n",
    "}\n",
    "\n",
    "dataframes = {}\n",
    "\n",
    "for key, log_file in baselines.items():\n",
    "    event_acc = EventAccumulator(log_file)\n",
    "    event_acc.Reload()\n",
    "\n",
    "    rows = []\n",
    "    for metric in metrics:\n",
    "        \n",
    "        if metric == \"train/critic_loss\":\n",
    "            if \"PPO\" in key or \"A2C\" in key:\n",
    "                metric = \"train/value_loss\"\n",
    "        \n",
    "        if metric == \"train/actor_loss\":\n",
    "            if \"PPO\" in key:\n",
    "                metric = \"train/policy_gradient_loss\"\n",
    "            elif \"A2C\" in key:\n",
    "                metric = \"train/policy_loss\"\n",
    "        \n",
    "        if metric == \"train/entropy_loss\":\n",
    "            if \"SAC\" in key:\n",
    "                metric = \"train/ent_coef_loss\"        \n",
    "        \n",
    "        steps = []\n",
    "        values = []\n",
    "        for event in event_acc.Scalars(metric):\n",
    "            steps.append(event.step)\n",
    "            values.append(event.value)\n",
    "        rows.append(values)\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=steps, index=metrics)\n",
    "    dataframes[key] = df\n",
    "\n",
    "print(\"Created dataframes:\", list(dataframes.keys()))\n",
    "    \n",
    "sac_500k_df = dataframes[\"SAC_500k\"].T\n",
    "ppo_500k_df = dataframes[\"PPO_500k\"].T\n",
    "a2c_500k_df = dataframes[\"A2C_500k\"].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695e2e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "sac_500k_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889890f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_500k_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52387cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a2c_500k_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ac06c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, df in dataframes.items():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91db6643",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "title_dict = {\n",
    "    \"rollout/ep_rew_mean\": \"Mean Episode Reward\",\n",
    "    \"rollout/ep_len_mean\": \"Mean Episode Length\",\n",
    "    \"train/critic_loss\": \"Critic Loss\",\n",
    "    \"train/actor_loss\": \"Actor Loss\",\n",
    "    \"train/entropy_loss\": \"Entropy Loss\",\n",
    "    \"time/fps\": \"FPS\",\n",
    "}\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(12, 8))\n",
    "# fig.suptitle(\"Training Metrics with a CNN Policy\", fontsize=14)\n",
    "\n",
    "colors = [\"tab:blue\", \"tab:orange\", \"tab:green\"]\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    row = i // 3\n",
    "    col = i % 3\n",
    "    ax = axs[row, col]\n",
    "\n",
    "    ax.set_title(title_dict[metric])\n",
    "    ax.set_ylabel(title_dict[metric])\n",
    "    ax.set_xlabel('Environment Step')\n",
    "\n",
    "    for j, (key, df) in enumerate(dataframes.items()):\n",
    "        steps = df.columns\n",
    "        values = df.loc[metric]\n",
    "        \n",
    "        label = key.split(\"_\")[0] # cut of everything after the first underscore\n",
    "        \n",
    "        if \"actor_loss\" in metric and \"A2C\" in key:\n",
    "            smoothed_values = gaussian_filter1d(values, sigma=4) \n",
    "        else:\n",
    "            smoothed_values = gaussian_filter1d(values, sigma=2)\n",
    "        \n",
    "        ax.plot(steps, smoothed_values, label=label, alpha=1.0, color=colors[j % len(colors)])\n",
    "        ax.plot(steps, values, alpha=0.25, color=colors[j % len(colors)])\n",
    "        \n",
    "        ax.legend(loc=\"upper right\")\n",
    "\n",
    "    ax.xaxis.set_major_locator(plt.MaxNLocator(4))\n",
    "    ax.yaxis.set_major_locator(plt.MaxNLocator(8))\n",
    "\n",
    "    if \"critic_loss\" in metric or \"actor_loss\" in metric:\n",
    "        ax.set_yscale(\"symlog\")\n",
    "        ax.get_yaxis().set_major_formatter(plt.FuncFormatter(lambda x, pos: \"{:.0e}\".format(x) if x != 0 else None))\n",
    "        \n",
    "    ax.grid(True, linestyle='--', linewidth=0.5, color='lightgray')\n",
    "    ax.set_facecolor('white')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figs/Training Metrics with a CNN Policy.pdf\")  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5dcbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# add a plot for the explained variance for A2C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0daf65a",
   "metadata": {},
   "source": [
    "## Plot the Explained Variance for A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f330a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    \"train/explained_variance\", # A2C\n",
    "]\n",
    "\n",
    "baselines = {\n",
    "    \"A2C_500k\": \"baseline_logs/A2C_500k/events.out.tfevents.1685255857.z.54420.0\",\n",
    "}\n",
    "\n",
    "dataframes = {}\n",
    "\n",
    "for key, log_file in baselines.items():\n",
    "    event_acc = EventAccumulator(log_file)\n",
    "    event_acc.Reload()\n",
    "\n",
    "    rows = []\n",
    "    for metric in metrics:\n",
    "        \n",
    "        steps = []\n",
    "        values = []\n",
    "        for event in event_acc.Scalars(metric):\n",
    "            steps.append(event.step)\n",
    "            values.append(event.value)\n",
    "        rows.append(values)\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=steps, index=metrics)\n",
    "    dataframes[key] = df\n",
    "\n",
    "print(\"Created dataframes:\", list(dataframes.keys()))\n",
    "\n",
    "explvar_a2c_500k_df = dataframes[\"A2C_500k\"].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c34d50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "explvar_a2c_500k_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b303dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(explvar_a2c_500k_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54df6b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_dict = {\n",
    "    \"train/explained_variance\": \"Explained Variance\"\n",
    "}\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize=(8, 6))\n",
    "\n",
    "colors = [\"tab:blue\", \"tab:orange\", \"tab:green\"]\n",
    "\n",
    "metric = \"train/explained_variance\"\n",
    "ax = axs\n",
    "\n",
    "# ax.set_title(title_dict[metric])\n",
    "ax.set_ylabel(title_dict[metric])\n",
    "ax.set_xlabel('Environment Step')\n",
    "\n",
    "for j, (key, df) in enumerate(dataframes.items()):\n",
    "    steps = df.columns\n",
    "    values = df.loc[metric]\n",
    "\n",
    "    label = key.split(\"_\")[0]  # Cut off everything after the first underscore\n",
    "\n",
    "    if \"A2C\" in key:\n",
    "        smoothed_values = gaussian_filter1d(values, sigma=2)\n",
    "\n",
    "    ax.plot(steps, smoothed_values, label=label, alpha=1.0, color=colors[j % len(colors)])\n",
    "    ax.plot(steps, values, alpha=0.25, color=colors[j % len(colors)])\n",
    "\n",
    "    ax.legend(loc=\"upper right\")\n",
    "\n",
    "ax.xaxis.set_major_locator(plt.MaxNLocator(4))\n",
    "ax.yaxis.set_major_locator(plt.MaxNLocator(8))\n",
    "\n",
    "ax.set_yscale(\"symlog\")\n",
    "ax.get_yaxis().set_major_formatter(plt.FuncFormatter(lambda x, pos: '{:.0e}'.format(x) if x != 0 else None))\n",
    "\n",
    "ax.grid(True, linestyle='--', linewidth=0.5, color='lightgray')\n",
    "ax.set_facecolor('white')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figs/Explained Variance of A2C.pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3630968",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb50f96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
