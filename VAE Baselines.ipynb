{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43db25de",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d80a4c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "from collections import deque\n",
    "from operator import itemgetter\n",
    "\n",
    "import gym_donkeycar\n",
    "import gymnasium as gym\n",
    "import imageio\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from IPython.display import display\n",
    "from ipywidgets import HBox, VBox\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from ruamel.yaml import YAML\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.stats import norm\n",
    "from tensorboard import notebook\n",
    "from tensorboard.backend.event_processing.event_accumulator import \\\n",
    "    EventAccumulator\n",
    "from torch import distributions as dist\n",
    "from torch.distributions import Categorical, Normal\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "# suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"gymnasium\")\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ[\"IMAGEIO_IGNORE_WARNINGS\"] = \"True\"\n",
    "\n",
    "import gym.spaces as gym_spaces\n",
    "import gymnasium as gym  # overwrite OpenAI gym\n",
    "import stable_baselines3 as sb3\n",
    "from gym_donkeycar.envs.donkey_env import DonkeyEnv\n",
    "from gymnasium import spaces\n",
    "from gymnasium.spaces import Box\n",
    "from gymnasium.experimental.wrappers import RescaleActionV0\n",
    "from stable_baselines3 import A2C, PPO, SAC\n",
    "from stable_baselines3.common import env_checker\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.results_plotter import load_results, ts2xy\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "\n",
    "from src.actor_critic import ContinuousActorCritic\n",
    "from src.blocks import CategoricalStraightThrough, ConvBlock\n",
    "from src.categorical_vae import CategoricalVAE\n",
    "from src.imagination_env import ImaginationEnv\n",
    "from src.mlp import MLP\n",
    "from src.preprocessing import grayscale_transform as transform\n",
    "from src.replay_buffer import ReplayBuffer\n",
    "from src.rssm import RSSM\n",
    "from src.utils import (load_config, make_env, save_image_and_reconstruction,\n",
    "                       to_np)\n",
    "from src.vae import VAE\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Load the config\n",
    "config = load_config()\n",
    "for key in config:\n",
    "    locals()[key] = config[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1daa9ad2",
   "metadata": {},
   "source": [
    "## Create the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a47fc19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making a toy env.\n",
      "Making 1 vectorized envs.\n",
      "Adding a Gymnasium RecordEpisodeStatistics wrapper.\n",
      "Adding a TimeLimit wrapper with 1000 max episode steps.\n",
      "Adding an AutoReset wrapper.\n",
      "Adding a RescaleActionV0 wrapper to have an effective action space [-1,1].\n",
      "Note: Clip actions at 1.0 => The agent can take agents from:\n",
      "Low: [-1. -1. -1.] to High: [1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "env = make_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7a3cb003",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing encoder:\n",
      "- adding ConvBlock((3, 64))                   ==> output shape: (64, 32, 32) ==> prod: 65536\n",
      "- adding ConvBlock((64, 128))                   ==> output shape: (128, 16, 16) ==> prod: 32768\n",
      "- adding ConvBlock((128, 256))                   ==> output shape: (256, 8, 8) ==> prod: 16384\n",
      "- adding ConvBlock((256, 512))                   ==> output shape: (512, 4, 4) ==> prod: 8192\n",
      "- adding ConvBlock((512, 256))                   ==> output shape: (256, 2, 2) ==> prod: 1024\n",
      "- adding Flatten()\n",
      "- adding Linear() for Mu: 1024 and Logvar: 1024\n",
      "\n",
      "Initializing decoder:\n",
      "- adding Reshape: (*,1024) => (*,256,2,2)\n",
      "- adding transpose ConvBlock(256, 256)                   ==> output shape: (256, 4, 4) ==> prod: 4096\n",
      "- adding transpose ConvBlock(256, 512)                   ==> output shape: (512, 8, 8) ==> prod: 32768\n",
      "- adding transpose ConvBlock(512, 256)                   ==> output shape: (256, 16, 16) ==> prod: 65536\n",
      "- adding transpose ConvBlock(256, 128)                   ==> output shape: (128, 32, 32) ==> prod: 131072\n",
      "- adding transpose ConvBlock(128, 3)                   ==> output shape: (3, 64, 64) ==> prod: 12288\n",
      "Set VAE to evaluation mode.\n"
     ]
    }
   ],
   "source": [
    "vae = VAE().to(device)\n",
    "vae.load_weights(\"weights/VAE_1\")\n",
    "vae.optim = optim.Adam(vae.parameters(), lr=1e-4, weight_decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "15e3503e",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ContinuousActorCritic().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dad6541a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▎                                                                               | 1028/20000 [10:34<3:15:15,  1.62it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [73], line 56\u001b[0m\n\u001b[1;32m     52\u001b[0m action, log_prob, actor_entropy \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mget_action(z)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# if sample_phase % config[\"log_interval\"] == 0:\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m#     if step % 10 == 0:\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m#         print(action)\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m obs, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_np\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# Collect the necessary data for an agent update\u001b[39;00m\n\u001b[1;32m     59\u001b[0m batch_rewards\u001b[38;5;241m.\u001b[39mappend(reward)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gymnasium/core.py:538\u001b[0m, in \u001b[0;36mActionWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\n\u001b[1;32m    535\u001b[0m     \u001b[38;5;28mself\u001b[39m, action: WrapperActType\n\u001b[1;32m    536\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[ObsType, SupportsFloat, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;124;03m\"\"\"Runs the :attr:`env` :meth:`env.step` using the modified ``action`` from :meth:`self.action`.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gymnasium/wrappers/autoreset.py:55\u001b[0m, in \u001b[0;36mAutoResetWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;124;03m\"\"\"Steps through the environment with action and resets the environment if a terminated or truncated signal is encountered.\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;124;03m        The autoreset environment :meth:`step`\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m     obs, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated:\n\u001b[1;32m     57\u001b[0m         new_obs, new_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mreset()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gymnasium/wrappers/time_limit.py:57\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;124;03m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m \n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m     observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_episode_steps:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gymnasium/wrappers/record_episode_statistics.py:89\u001b[0m, in \u001b[0;36mRecordEpisodeStatistics.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;124;03m\"\"\"Steps through the environment, recording the episode statistics.\"\"\"\u001b[39;00m\n\u001b[1;32m     83\u001b[0m     (\n\u001b[1;32m     84\u001b[0m         observations,\n\u001b[1;32m     85\u001b[0m         rewards,\n\u001b[1;32m     86\u001b[0m         terminations,\n\u001b[1;32m     87\u001b[0m         truncations,\n\u001b[1;32m     88\u001b[0m         infos,\n\u001b[0;32m---> 89\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m     91\u001b[0m         infos, \u001b[38;5;28mdict\u001b[39m\n\u001b[1;32m     92\u001b[0m     ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`info` dtype is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(infos)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m while supported dtype is `dict`. This may be due to usage of other wrappers in the wrong order.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepisode_returns \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m rewards\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gymnasium/wrappers/time_limit.py:57\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;124;03m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m \n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m     observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_episode_steps:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gymnasium/wrappers/order_enforcing.py:56\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gymnasium/wrappers/env_checker.py:49\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_step_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, action)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gymnasium/envs/box2d/car_racing.py:553\u001b[0m, in \u001b[0;36mCarRacing.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworld\u001b[38;5;241m.\u001b[39mStep(\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m FPS, \u001b[38;5;241m6\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m30\u001b[39m)\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m FPS\n\u001b[0;32m--> 553\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_render\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstate_pixels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    555\u001b[0m step_reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    556\u001b[0m terminated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gymnasium/envs/box2d/car_racing.py:617\u001b[0m, in \u001b[0;36mCarRacing._render\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    614\u001b[0m trans \u001b[38;5;241m=\u001b[39m pygame\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mVector2((scroll_x, scroll_y))\u001b[38;5;241m.\u001b[39mrotate_rad(angle)\n\u001b[1;32m    615\u001b[0m trans \u001b[38;5;241m=\u001b[39m (WINDOW_W \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m trans[\u001b[38;5;241m0\u001b[39m], WINDOW_H \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m4\u001b[39m \u001b[38;5;241m+\u001b[39m trans[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m--> 617\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_render_road\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzoom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrans\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mangle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcar\u001b[38;5;241m.\u001b[39mdraw(\n\u001b[1;32m    619\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msurf,\n\u001b[1;32m    620\u001b[0m     zoom,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    623\u001b[0m     mode \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate_pixels_list\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate_pixels\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    624\u001b[0m )\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msurf \u001b[38;5;241m=\u001b[39m pygame\u001b[38;5;241m.\u001b[39mtransform\u001b[38;5;241m.\u001b[39mflip(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msurf, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gymnasium/envs/box2d/car_racing.py:685\u001b[0m, in \u001b[0;36mCarRacing._render_road\u001b[0;34m(self, zoom, translation, angle)\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;66;03m# draw road\u001b[39;00m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m poly, color \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroad_poly:\n\u001b[1;32m    684\u001b[0m     \u001b[38;5;66;03m# converting to pixel coordinates\u001b[39;00m\n\u001b[0;32m--> 685\u001b[0m     poly \u001b[38;5;241m=\u001b[39m [(p[\u001b[38;5;241m0\u001b[39m], p[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m poly]\n\u001b[1;32m    686\u001b[0m     color \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mint\u001b[39m(c) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m color]\n\u001b[1;32m    687\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_draw_colored_polygon(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msurf, poly, color, zoom, translation, angle)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gymnasium/envs/box2d/car_racing.py:685\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;66;03m# draw road\u001b[39;00m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m poly, color \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroad_poly:\n\u001b[1;32m    684\u001b[0m     \u001b[38;5;66;03m# converting to pixel coordinates\u001b[39;00m\n\u001b[0;32m--> 685\u001b[0m     poly \u001b[38;5;241m=\u001b[39m [(p[\u001b[38;5;241m0\u001b[39m], p[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m poly]\n\u001b[1;32m    686\u001b[0m     color \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mint\u001b[39m(c) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m color]\n\u001b[1;32m    687\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_draw_colored_polygon(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msurf, poly, color, zoom, translation, angle)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# New training loop with batches\n",
    "\n",
    "losses = {\n",
    "    \"vae_loss\": [],\n",
    "    \"reconstruction_loss\": [],\n",
    "    \"KLD_loss\": [],\n",
    "    \"critic_loss\": [],\n",
    "    \"actor_loss\": [],\n",
    "}\n",
    "\n",
    "# Logging\n",
    "writer = SummaryWriter(log_dir)\n",
    "if config[\"show_inline_tensorboard\"]:\n",
    "    notebook.start(f\"--logdir={log_dir}\")\n",
    "\n",
    "for sample_phase in tqdm(range(n_updates)):\n",
    "    \n",
    "    batch_observations = []\n",
    "    batch_reconstructions = []\n",
    "    batch_mu = []\n",
    "    batch_logvar = []\n",
    "    \n",
    "    # NEW\n",
    "    batch_rewards = []\n",
    "    batch_log_probs = []\n",
    "    batch_value_preds = []\n",
    "    batch_entropies = []\n",
    "    batch_masks = []\n",
    "    \n",
    "    if sample_phase == 0:\n",
    "        obs, info = env.reset(seed=42)\n",
    "\n",
    "    for step in range(n_steps_per_update):\n",
    "        if len(obs.shape) == 4:\n",
    "            obs = obs[0]\n",
    "\n",
    "        # Get the observation and encode it\n",
    "        obs = transform(obs)\n",
    "        z, reconstruction, mu, logvar = vae(obs)\n",
    "        \n",
    "        if sample_phase % 100 == 0:\n",
    "            save_image_and_reconstruction(obs, reconstruction, sample_phase)\n",
    "        \n",
    "        # Add the observation, reconstruction, mu, and logvar to the respective batches\n",
    "        batch_observations.append(obs)\n",
    "        batch_reconstructions.append(reconstruction)\n",
    "        batch_mu.append(mu)\n",
    "        batch_logvar.append(logvar)\n",
    "\n",
    "        # Get an action and take an environment step\n",
    "        # action = np.random.rand(A)\n",
    "        action, log_prob, actor_entropy = agent.get_action(z)\n",
    "        # if sample_phase % config[\"log_interval\"] == 0:\n",
    "        #     if step % 10 == 0:\n",
    "        #         print(action)\n",
    "        obs, reward, terminated, truncated, info = env.step(to_np(action))\n",
    "        \n",
    "        # Collect the necessary data for an agent update\n",
    "        batch_rewards.append(reward)\n",
    "        batch_log_probs.append(log_prob)\n",
    "        batch_entropies.append(actor_entropy)\n",
    "        mask = torch.tensor(0.0 if terminated else 1.0)\n",
    "        batch_masks.append(mask)\n",
    "        value_pred = agent.critic(torch.Tensor(z))\n",
    "        batch_value_preds.append(value_pred)\n",
    "\n",
    "    # Convert the batch tensors to tensors\n",
    "    batch_observations = torch.stack(batch_observations).to(device)  # [n_steps_per_update, *obs_shape]\n",
    "    batch_reconstructions = torch.stack(batch_reconstructions).to(device)  # [n_steps_per_update, *obs_shape]\n",
    "    batch_mu = torch.stack(batch_mu).to(device)  # [n_steps_per_update, latent_dim]\n",
    "    batch_logvar = torch.stack(batch_logvar).to(device)  # [n_steps_per_update, latent_dim]\n",
    "    batch_rewards = torch.tensor(batch_rewards).to(device)  # [n_steps_per_update]\n",
    "    batch_log_probs = torch.stack(batch_log_probs).to(device)  # [n_steps_per_update]\n",
    "    batch_value_preds = torch.stack(batch_value_preds).to(device)  # [n_steps_per_update]\n",
    "    last_value_pred = agent.critic(torch.Tensor(z)).to(device)  # last value prediction for GAE\n",
    "    batch_entropies = torch.stack(batch_entropies).to(device)  # [n_steps_per_update]\n",
    "    batch_masks = torch.stack(batch_masks).to(device)  # [n_steps_per_update]\n",
    "\n",
    "    # Update the agent's parameters\n",
    "    critic_loss, actor_loss = agent.get_loss(\n",
    "        batch_rewards, batch_log_probs, batch_value_preds, last_value_pred, batch_entropies, batch_masks\n",
    "    )\n",
    "    agent.update_parameters(critic_loss, actor_loss)\n",
    "\n",
    "    # Update the VAE's parameters\n",
    "    vae_loss, reconstruction_loss, KLD_loss = vae.get_loss(batch_observations, batch_reconstructions, batch_mu, batch_logvar)\n",
    "    vae.optim.zero_grad()\n",
    "    vae_loss.backward()\n",
    "    vae.optim.step()\n",
    "\n",
    "    if sample_phase % config[\"log_interval\"] == 0:\n",
    "        \n",
    "        # Log the losses\n",
    "        losses[\"vae_loss\"].append(to_np(vae_loss))\n",
    "        losses[\"reconstruction_loss\"].append(to_np(reconstruction_loss))\n",
    "        losses[\"KLD_loss\"].append(to_np(KLD_loss))\n",
    "        losses[\"critic_loss\"].append(to_np(critic_loss))\n",
    "        losses[\"actor_loss\"].append(to_np(actor_loss))\n",
    "\n",
    "        # Log the episode return\n",
    "        writer.add_scalar(\"Mean reward\", np.mean(to_np(batch_rewards)), global_step=sample_phase)\n",
    "\n",
    "        # Detach the losses to save memory and log them in TensorBoard\n",
    "        writer.add_scalar(\"vae_loss\", to_np(vae_loss), global_step=sample_phase)\n",
    "        writer.add_scalar(\"reconstruction_loss\", to_np(reconstruction_loss), global_step=sample_phase)\n",
    "        writer.add_scalar(\"KLD_loss\", to_np(KLD_loss), global_step=sample_phase)\n",
    "        writer.add_scalar(\"critic_loss\", to_np(critic_loss), global_step=sample_phase)\n",
    "        writer.add_scalar(\"actor_loss\", to_np(actor_loss), global_step=sample_phase)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b4bbfa15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vae.save_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ad75f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-1., -1., -1.], device='cuda:0', grad_fn=<TanhBackward0>),\n",
       " tensor([2.2562e-09, 1.0139e-09, 8.2383e-10], device='cuda:0',\n",
       "        grad_fn=<SigmoidBackward0>))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.actor(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9c0420",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "77525412",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, var = agent.actor(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "24d87b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.0000, -1.0001, -1.0000], device='cuda:0')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_pd = dist.MultivariateNormal(mu, var * torch.eye(mu.shape[0], device=agent.device))\n",
    "action = action_pd.sample()\n",
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "15044a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(25.1843, device='cuda:0', grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_pd.log_prob(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ac0320cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 1.]], device='cuda:0')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fc9d20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf801b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "299a749b",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_return = 0.0\n",
    "returns = []\n",
    "\n",
    "for r in reversed(batch_rewards):\n",
    "    future_return = r + config[\"gamma\"] * future_return\n",
    "    returns.insert(0, future_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a539b8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = torch.tensor(returns)\n",
    "returns = (returns - returns.mean()) / (returns.std() + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7092c6a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.6396, -1.5699, -1.5000, -1.4299, -1.3595, -1.2890, -1.2183, -1.1473,\n",
       "        -1.0761, -1.0047, -0.9331, -0.8613, -0.7893, -0.7170, -0.6446, -0.5719,\n",
       "        -0.4990, -0.4258, -0.3525, -0.2789, -0.2052, -0.1311, -0.0569,  0.0175,\n",
       "         0.0922,  0.1671,  0.2422,  0.3176,  0.3932,  0.4690,  0.5450,  0.6213,\n",
       "         0.6978,  0.7745,  0.8515,  0.9287,  1.0061,  1.0837,  1.1616,  1.2397,\n",
       "         1.3181,  1.3967,  1.4755,  1.5546,  1.6339,  1.7134])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "39783e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.9608, device='cuda:0', grad_fn=<MeanBackward0>) tensor([-32.6531], device='cuda:0', grad_fn=<AddBackward0>) tensor(-1.6396)\n",
      "tensor(7.8397, device='cuda:0', grad_fn=<MeanBackward0>) tensor([-32.6498], device='cuda:0', grad_fn=<AddBackward0>) tensor(-1.5699)\n",
      "tensor(6.8291, device='cuda:0', grad_fn=<MeanBackward0>) tensor([-32.6525], device='cuda:0', grad_fn=<AddBackward0>) tensor(-1.5000)\n",
      "tensor(7.7620, device='cuda:0', grad_fn=<MeanBackward0>) tensor([-32.6520], device='cuda:0', grad_fn=<AddBackward0>) tensor(-1.4299)\n",
      "tensor(8.2424, device='cuda:0', grad_fn=<MeanBackward0>) tensor([-32.6579], device='cuda:0', grad_fn=<AddBackward0>) tensor(-1.3595)\n",
      "tensor(8.2347, device='cuda:0', grad_fn=<MeanBackward0>) tensor([-32.6581], device='cuda:0', grad_fn=<AddBackward0>) tensor(-1.2890)\n",
      "tensor(7.9923, device='cuda:0', grad_fn=<MeanBackward0>) tensor([-32.6581], device='cuda:0', grad_fn=<AddBackward0>) tensor(-1.2183)\n",
      "tensor(7.9663, device='cuda:0', grad_fn=<MeanBackward0>) tensor([-32.6521], device='cuda:0', grad_fn=<AddBackward0>) tensor(-1.1473)\n",
      "tensor(8.2914, device='cuda:0', grad_fn=<MeanBackward0>) tensor([-32.6493], device='cuda:0', grad_fn=<AddBackward0>) tensor(-1.0761)\n",
      "tensor(8.1162, device='cuda:0', grad_fn=<MeanBackward0>) tensor([-32.6545], device='cuda:0', grad_fn=<AddBackward0>) tensor(-1.0047)\n",
      "tensor(8.2914, device='cuda:0', grad_fn=<MeanBackward0>) tensor([-32.6499], device='cuda:0', grad_fn=<AddBackward0>) tensor(-0.9331)\n",
      "tensor(7.8738, device='cuda:0', grad_fn=<MeanBackward0>) tensor([-32.6510], device='cuda:0', grad_fn=<AddBackward0>) tensor(-0.8613)\n",
      "tensor(8.2819, device='cuda:0', grad_fn=<MeanBackward0>) tensor([-32.6552], device='cuda:0', grad_fn=<AddBackward0>) tensor(-0.7893)\n",
      "tensor(7.4919, device='cuda:0', grad_fn=<MeanBackward0>) tensor([-32.6591], device='cuda:0', grad_fn=<AddBackward0>) tensor(-0.7170)\n",
      "tensor(8.2361, device='cuda:0', grad_fn=<MeanBackward0>) tensor([-32.6444], device='cuda:0', grad_fn=<AddBackward0>) tensor(-0.6446)\n",
      "tensor(7.9885, device='cuda:0', grad_fn=<MeanBackward0>) tensor([-32.6422], device='cuda:0', grad_fn=<AddBackward0>) tensor(-0.5719)\n",
      "tensor(8.2914, device='cuda:0', grad_fn=<MeanBackward0>) tensor([-32.6629], device='cuda:0', grad_fn=<AddBackward0>) tensor(-0.4990)\n",
      "tensor(8.0303, device='cuda:0', grad_fn=<MeanBackward0>) tensor([-32.6500], device='cuda:0', grad_fn=<AddBackward0>) tensor(-0.4258)\n",
      "tensor(7.8354, device='cuda:0', grad_fn=<MeanBackward0>) tensor([-32.6532], device='cuda:0', grad_fn=<AddBackward0>) tensor(-0.3525)\n",
      "tensor(7.8765, device='cuda:0', grad_fn=<MeanBackward0>) tensor([-32.6606], device='cuda:0', grad_fn=<AddBackward0>) tensor(-0.2789)\n",
      "tensor(7.8805, device='cuda:0', grad_fn=<MeanBackward0>) tensor([-32.6573], device='cuda:0', grad_fn=<AddBackward0>) tensor(-0.2052)\n",
      "tensor(8.2861, device='cuda:0', grad_fn=<MeanBackward0>) tensor([-32.6606], device='cuda:0', grad_fn=<AddBackward0>) tensor(-0.1311)\n",
      "tensor(8.2282, device='cuda:0', grad_fn=<MeanBackward0>) tensor([-32.6536], device='cuda:0', grad_fn=<AddBackward0>) tensor(-0.0569)\n",
      "tensor(8.2914, device='cuda:0', grad_fn=<MeanBackward0>) tensor([-32.6528], device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0175)\n",
      "tensor(8.2554, device='cuda:0', grad_fn=<MeanBackward0>) tensor([-32.6512], device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0922)\n",
      "tensor(8.1598, device='cuda:0', grad_fn=<MeanBackward0>) tensor([-32.6550], device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1671)\n",
      "tensor(8.2348, device='cuda:0', grad_fn=<MeanBackward0>) tensor([-32.6622], device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2422)\n",
      "tensor(8.2863, device='cuda:0', grad_fn=<MeanBackward0>) tensor([-32.6532], device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3176)\n",
      "tensor(8.2837, device='cuda:0', grad_fn=<MeanBackward0>) tensor([-32.6565], device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3932)\n",
      "tensor(6.9738, device='cuda:0', grad_fn=<MeanBackward0>) tensor([-32.6549], device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4690)\n",
      "tensor(8.2217, device='cuda:0', grad_fn=<MeanBackward0>) tensor([-32.6522], device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5450)\n",
      "tensor(8.1649, device='cuda:0', grad_fn=<MeanBackward0>) tensor([-32.6419], device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6213)\n",
      "tensor(7.5106, device='cuda:0', grad_fn=<MeanBackward0>) tensor([-32.6532], device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6978)\n",
      "tensor(7.9651, device='cuda:0', grad_fn=<MeanBackward0>) tensor([-32.6512], device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7745)\n",
      "tensor(7.8851, device='cuda:0', grad_fn=<MeanBackward0>) tensor([-32.6637], device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8515)\n",
      "tensor(8.2772, device='cuda:0', grad_fn=<MeanBackward0>) tensor([-32.6455], device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9287)\n",
      "tensor(8.2131, device='cuda:0', grad_fn=<MeanBackward0>) tensor([-32.6562], device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0061)\n",
      "tensor(7.9375, device='cuda:0', grad_fn=<MeanBackward0>) tensor([-32.6597], device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0837)\n",
      "tensor(8.1509, device='cuda:0', grad_fn=<MeanBackward0>) tensor([-32.6504], device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1616)\n",
      "tensor(8.1092, device='cuda:0', grad_fn=<MeanBackward0>) tensor([-32.6549], device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2397)\n",
      "tensor(7.8220, device='cuda:0', grad_fn=<MeanBackward0>) tensor([-32.6524], device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3181)\n",
      "tensor(8.2911, device='cuda:0', grad_fn=<MeanBackward0>) tensor([-32.6547], device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3967)\n",
      "tensor(6.5835, device='cuda:0', grad_fn=<MeanBackward0>) tensor([-32.6575], device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4755)\n",
      "tensor(7.8605, device='cuda:0', grad_fn=<MeanBackward0>) tensor([-32.6535], device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5546)\n",
      "tensor(7.4026, device='cuda:0', grad_fn=<MeanBackward0>) tensor([-32.6558], device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6339)\n",
      "tensor(8.2914, device='cuda:0', grad_fn=<MeanBackward0>) tensor([-32.6615], device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7134)\n"
     ]
    }
   ],
   "source": [
    "for log_prob, value_pred, value in zip(batch_log_probs, batch_value_preds, returns):\n",
    "    print(log_prob, value_pred, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef954a82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b47743",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776b6054",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d1463e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f34c35c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "861ca4a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.2914, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6756ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589cc4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "    losses[\"vae_loss\"].append(to_np(vae_loss))\n",
    "    losses[\"reconstruction_loss\"].append(to_np(reconstruction_loss))\n",
    "    losses[\"KLD_loss\"].append(to_np(KLD_loss))\n",
    "    losses[\"critic_loss\"].append(to_np(critic_loss))\n",
    "    losses[\"actor_loss\"].append(to_np(actor_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df577239",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming `losses` is a dictionary containing the loss values\n",
    "\n",
    "# Create a figure and subplots\n",
    "smoothing_factor = 40\n",
    "fig, axs = plt.subplots(2, 3, figsize=(12, 8))\n",
    "\n",
    "# Plot VAE loss\n",
    "smoothed = gaussian_filter1d(losses[\"vae_loss\"], sigma=smoothing_factor)\n",
    "axs[0, 0].plot(losses[\"vae_loss\"], alpha=0.8)\n",
    "axs[0, 0].plot(smoothed)\n",
    "axs[0, 0].set_title(\"VAE Loss\")\n",
    "\n",
    "# Plot Reconstruction loss\n",
    "smoothed = gaussian_filter1d(losses[\"reconstruction_loss\"], sigma=smoothing_factor)\n",
    "axs[0, 1].plot(losses[\"reconstruction_loss\"], alpha=0.8)\n",
    "axs[0, 1].plot(smoothed)\n",
    "axs[0, 1].set_title(\"Reconstruction Loss\")\n",
    "\n",
    "# Plot KLD loss\n",
    "smoothed = gaussian_filter1d(losses[\"KLD_loss\"], sigma=smoothing_factor)\n",
    "axs[0, 2].plot(losses[\"KLD_loss\"], alpha=0.8)\n",
    "axs[0, 2].plot(smoothed)\n",
    "axs[0, 2].set_title(\"KLD Loss\")\n",
    "\n",
    "# Plot Critic loss\n",
    "smoothed = gaussian_filter1d(losses[\"critic_loss\"], sigma=smoothing_factor)\n",
    "axs[1, 0].plot(losses[\"critic_loss\"], alpha=0.8)\n",
    "axs[1, 0].plot(smoothed)\n",
    "axs[1, 0].set_title(\"Critic Loss\")\n",
    "\n",
    "# Plot Actor loss\n",
    "smoothed = gaussian_filter1d(losses[\"actor_loss\"], sigma=smoothing_factor)\n",
    "axs[1, 1].plot(losses[\"actor_loss\"], alpha=0.8)\n",
    "axs[1, 1].plot(smoothed)\n",
    "axs[1, 1].set_title(\"Actor Loss\")\n",
    "\n",
    "# Remove empty subplot\n",
    "fig.delaxes(axs[1, 2])\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6f6a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_observations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fc79c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_reconstructions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660a2286",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_mu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebea80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_logvar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5653d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_rewards.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b64d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_log_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c934fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_value_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c02466",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_value_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93013cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_entropies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059c1dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b470c76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9da46a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672cf06a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817374ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c97e95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384cb9ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec03a130",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71fad09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd83b09c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c611fe4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_episode_steps, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9463c42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses[\"vae_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb76a5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses[\"reconstruction_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bc2c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses[\"KLD_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aacb773",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, info = env.reset(seed=42)\n",
    "\n",
    "if len(obs.shape) == 4:\n",
    "    obs = obs[0]\n",
    "\n",
    "obs = transform(obs)\n",
    "\n",
    "plt.imshow(to_np(torch.permute(obs, (1,2,0))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49001398",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction, mu, logvar = vae(torch.randn(obs.shape).to(device))\n",
    "plt.imshow(to_np(torch.permute(reconstruction, (1,2,0))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefcc45f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
