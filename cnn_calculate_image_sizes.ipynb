{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32e52c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.distributions import Normal, Categorical\n",
    "\n",
    "from models.blocks import ConvBlock, TransposeConvBlock, ResConvBlock, CategoricalStraightThrough\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9cc156c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "height = 128\n",
    "width = 128\n",
    "\n",
    "kernel_size = 4\n",
    "padding = 1\n",
    "stride = 2\n",
    "\n",
    "height = (height + 2 * padding - kernel_size) // stride + 1\n",
    "width = (width + 2 * padding - kernel_size) // stride + 1\n",
    "\n",
    "height, width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ef80313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding ConvBlock((1, 16)) ==> output shape:(16, 64, 64) ==> prod: 65536\n",
      "adding ConvBlock((16, 32)) ==> output shape:(32, 32, 32) ==> prod: 32768\n",
      "adding ConvBlock((32, 64)) ==> output shape:(64, 16, 16) ==> prod: 16384\n",
      "adding ConvBlock((64, 128)) ==> output shape:(128, 8, 8) ==> prod: 8192\n",
      "adding ConvBlock((128, 256)) ==> output shape:(256, 4, 4) ==> prod: 4096\n",
      "adding ConvBlock((256, 512)) ==> output shape:(512, 2, 2) ==> prod: 2048\n",
      "adding ConvBlock((512, 1024)) ==> output shape:(1024, 1, 1) ==> prod: 1024\n"
     ]
    }
   ],
   "source": [
    "# image size\n",
    "height = 128\n",
    "width = 128\n",
    "\n",
    "# settings\n",
    "kernel_size = 3\n",
    "padding = 1\n",
    "stride = 2\n",
    "\n",
    "# channels\n",
    "input_channels = 1\n",
    "channels = [16, 32, 64, 128, 256, 512, 1024]\n",
    "blocks = len(channels)\n",
    "\n",
    "for i in range(blocks):\n",
    "    height = (height + 2 * padding - kernel_size) // stride + 1\n",
    "    width = (width + 2 * padding - kernel_size) // stride + 1\n",
    "\n",
    "    print(f\"adding ConvBlock({input_channels, channels[i]}) ==> output shape:{(channels[i], height, width)} ==> prod: {channels[i] * height * width}\")\n",
    "    input_channels = channels[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb5c7b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = [16, 32, 64, 128, 256, 512, 1024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55b41e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1024\n",
      "1 512\n",
      "2 256\n",
      "3 128\n",
      "4 64\n",
      "5 32\n",
      "6 16\n"
     ]
    }
   ],
   "source": [
    "for i, c in enumerate(reversed(channels)):\n",
    "    print(i,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87965f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bced8ae6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e24e3790",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalVAE(nn.Module):\n",
    "    def __init__(self, grayscale=True, vae_ent_coeff=0.0):\n",
    "        super(CategoricalVAE, self).__init__()\n",
    "\n",
    "        if grayscale:\n",
    "            self.input_channels = 1\n",
    "        else:\n",
    "            self.input_channels = 3\n",
    "        self.vae_ent_coeff = vae_ent_coeff\n",
    "        \n",
    "        self.encoder = nn.Sequential()\n",
    "        self.decoder = nn.Sequential()\n",
    "        self.categorical = CategoricalStraightThrough(num_classes=32)\n",
    "\n",
    "        # settings\n",
    "        kernel_size = 3\n",
    "        stride = 2\n",
    "        padding = 1\n",
    "\n",
    "        # channels\n",
    "        input_channels = self.input_channels\n",
    "        channels = [16, 32, 64, 128, 256, 512, 1024]\n",
    "\n",
    "        print(\"Initializing encoder:\")\n",
    "        height, width = 128, 128\n",
    "        for i, out_channels in enumerate(channels):\n",
    "            \n",
    "            height = (height + 2*padding - kernel_size) // stride + 1\n",
    "            width = (width + 2*padding - kernel_size) // stride + 1\n",
    "\n",
    "            print(f\"- adding ConvBlock({input_channels, out_channels}) \\\n",
    "                  ==> output shape: ({out_channels}, {height}, {width}) ==> prod: {out_channels * height * width}\")\n",
    "            conv_block = ConvBlock(input_channels, out_channels, kernel_size, stride, \n",
    "                                   padding, height, width)\n",
    "            self.encoder.add_module(f\"conv_block_{i}\", conv_block)\n",
    "            \n",
    "            input_channels = out_channels\n",
    "        \n",
    "        print(\"\\nInitializing decoder:\")\n",
    "        height, width = 1, 1\n",
    "        padding=1\n",
    "        for i, out_channels in enumerate(reversed(channels)):\n",
    "            \n",
    "            height = (height - 1)*stride - 2*padding + kernel_size + 1\n",
    "            width = (width - 1)*stride - 2*padding + kernel_size + 1\n",
    "            \n",
    "            # last layer\n",
    "            if i == len(channels)-1:\n",
    "                out_channels = self.input_channels\n",
    "            \n",
    "            print(f\"- adding transpose ConvBlock({input_channels}, {out_channels}) \\\n",
    "                  ==> output shape: ({out_channels}, {height}, {width}) ==> prod: {out_channels * height * width}\")\n",
    "            transpose_conv_block = ConvBlock(input_channels, out_channels, kernel_size, stride, \n",
    "                                             padding, height, width, transpose_conv=True)\n",
    "            self.decoder.add_module(f\"transpose_conv_block_{i}\", transpose_conv_block)\n",
    "            \n",
    "            input_channels = out_channels\n",
    "\n",
    "        self.decoder.add_module(\"output_activation\", nn.Sigmoid())\n",
    "\n",
    "\n",
    "    def encode(self, x):\n",
    "        logits = self.encoder(x).view(-1, 32, 32)\n",
    "        z = self.categorical(logits)\n",
    "        return z\n",
    "    \n",
    "    def decode(self, z):\n",
    "        x = self.decoder(z.view(-1, 32*32, 1, 1))\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encode(x).view(-1, 32, 32)\n",
    "        x_hat = self.decode(z)\n",
    "        return x_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e6282001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing encoder:\n",
      "- adding ConvBlock((1, 16))                   ==> output shape: (16, 64, 64) ==> prod: 65536\n",
      "- adding ConvBlock((16, 32))                   ==> output shape: (32, 32, 32) ==> prod: 32768\n",
      "- adding ConvBlock((32, 64))                   ==> output shape: (64, 16, 16) ==> prod: 16384\n",
      "- adding ConvBlock((64, 128))                   ==> output shape: (128, 8, 8) ==> prod: 8192\n",
      "- adding ConvBlock((128, 256))                   ==> output shape: (256, 4, 4) ==> prod: 4096\n",
      "- adding ConvBlock((256, 512))                   ==> output shape: (512, 2, 2) ==> prod: 2048\n",
      "- adding ConvBlock((512, 1024))                   ==> output shape: (1024, 1, 1) ==> prod: 1024\n",
      "\n",
      "Initializing decoder:\n",
      "- adding transpose ConvBlock(1024, 1024)                   ==> output shape: (1024, 2, 2) ==> prod: 4096\n",
      "- adding transpose ConvBlock(1024, 512)                   ==> output shape: (512, 4, 4) ==> prod: 8192\n",
      "- adding transpose ConvBlock(512, 256)                   ==> output shape: (256, 8, 8) ==> prod: 16384\n",
      "- adding transpose ConvBlock(256, 128)                   ==> output shape: (128, 16, 16) ==> prod: 32768\n",
      "- adding transpose ConvBlock(128, 64)                   ==> output shape: (64, 32, 32) ==> prod: 65536\n",
      "- adding transpose ConvBlock(64, 32)                   ==> output shape: (32, 64, 64) ==> prod: 131072\n",
      "- adding transpose ConvBlock(32, 1)                   ==> output shape: (1, 128, 128) ==> prod: 16384\n"
     ]
    }
   ],
   "source": [
    "vae = CategoricalVAE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "049c0496",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(8, 1, 1, 1)\n",
    "upsample = nn.ConvTranspose2d(1,1,kernel_size,stride,padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dea03491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([8, 16, 64, 64])\n",
      "Output shape: torch.Size([8, 32, 32, 32])\n",
      "Output shape: torch.Size([8, 64, 16, 16])\n",
      "Output shape: torch.Size([8, 128, 8, 8])\n",
      "Output shape: torch.Size([8, 256, 4, 4])\n",
      "Output shape: torch.Size([8, 512, 2, 2])\n",
      "Output shape: torch.Size([8, 1024, 1, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 32, 32])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.encode(torch.rand(8, 1, 128, 128)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5c74efb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([8, 16, 64, 64])\n",
      "Output shape: torch.Size([8, 32, 32, 32])\n",
      "Output shape: torch.Size([8, 64, 16, 16])\n",
      "Output shape: torch.Size([8, 128, 8, 8])\n",
      "Output shape: torch.Size([8, 256, 4, 4])\n",
      "Output shape: torch.Size([8, 512, 2, 2])\n",
      "Output shape: torch.Size([8, 1024, 1, 1])\n",
      "Output shape: torch.Size([8, 1024, 2, 2])\n",
      "Output shape: torch.Size([8, 512, 4, 4])\n",
      "Output shape: torch.Size([8, 256, 8, 8])\n",
      "Output shape: torch.Size([8, 128, 16, 16])\n",
      "Output shape: torch.Size([8, 64, 32, 32])\n",
      "Output shape: torch.Size([8, 32, 64, 64])\n",
      "Output shape: torch.Size([8, 1, 128, 128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1, 128, 128])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae(torch.rand(8, 1, 128, 128)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f10e5ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c02cce2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
